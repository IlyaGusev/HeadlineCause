{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "DeprecatedTitles.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "85e64aedcbd44f7daba63e94a81c9e1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9d4417c0e3584042a686d4c848d94f49",
              "IPY_MODEL_c2d8dd7540064898b8c142175786bf70"
            ],
            "layout": "IPY_MODEL_f958cec91e904d5c9caf315b42a388ed"
          }
        },
        "9d4417c0e3584042a686d4c848d94f49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "100%",
            "description_tooltip": null,
            "layout": "IPY_MODEL_317e3bf1475a4660936f1c8e0f8ad5da",
            "max": 55535,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_678b99192bf34feaa3591281cf4c9385",
            "value": 55535
          }
        },
        "c2d8dd7540064898b8c142175786bf70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f1f5cb3c0d2463f8774b83bcf243822",
            "placeholder": "​",
            "style": "IPY_MODEL_b95d69cae6404d46963c015e18ebbbf9",
            "value": " 55535/55535 [31:23&lt;00:00, 29.48it/s]"
          }
        },
        "f958cec91e904d5c9caf315b42a388ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "317e3bf1475a4660936f1c8e0f8ad5da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "678b99192bf34feaa3591281cf4c9385": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          }
        },
        "7f1f5cb3c0d2463f8774b83bcf243822": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b95d69cae6404d46963c015e18ebbbf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaUfkeh4woWU"
      },
      "source": [
        "# Requirements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cmvj-Jh4QgQN",
        "outputId": "59d162da-06b2-4772-9206-f166343415c0"
      },
      "source": [
        "!pip install --upgrade transformers bertviz checklist"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.9.1-py3-none-any.whl (2.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.6 MB 4.9 MB/s \n",
            "\u001b[?25hCollecting bertviz\n",
            "  Downloading bertviz-1.2.0-py3-none-any.whl (156 kB)\n",
            "\u001b[K     |████████████████████████████████| 156 kB 69.6 MB/s \n",
            "\u001b[?25hCollecting checklist\n",
            "  Downloading checklist-0.0.11.tar.gz (12.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.1 MB 33.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 56.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 68.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Collecting huggingface-hub==0.0.12\n",
            "  Downloading huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 68.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: torch>=1.0 in /usr/local/lib/python3.7/dist-packages (from bertviz) (1.9.0+cu102)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 64.0 MB/s \n",
            "\u001b[?25hCollecting boto3\n",
            "  Downloading boto3-1.18.16-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 73.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2 in /usr/local/lib/python3.7/dist-packages (from checklist) (2.2.4)\n",
            "Collecting munch>=2.5\n",
            "  Downloading munch-2.5.0-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: dill>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from checklist) (0.3.4)\n",
            "Requirement already satisfied: jupyter>=1.0 in /usr/local/lib/python3.7/dist-packages (from checklist) (1.0.0)\n",
            "Requirement already satisfied: ipywidgets>=7.5 in /usr/local/lib/python3.7/dist-packages (from checklist) (7.6.3)\n",
            "Collecting patternfork-nosql\n",
            "  Downloading patternfork_nosql-3.6.tar.gz (22.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 22.3 MB 1.2 MB/s \n",
            "\u001b[?25hCollecting iso-639\n",
            "  Downloading iso-639-0.4.5.tar.gz (167 kB)\n",
            "\u001b[K     |████████████████████████████████| 167 kB 56.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.5->checklist) (5.0.5)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.5->checklist) (4.10.1)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.5->checklist) (5.5.0)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.5->checklist) (5.1.3)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.5->checklist) (3.5.1)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.5->checklist) (1.0.0)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.5->checklist) (5.1.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.5->checklist) (5.3.5)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5->checklist) (2.6.1)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5->checklist) (0.8.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5->checklist) (4.4.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5->checklist) (57.2.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5->checklist) (0.7.5)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5->checklist) (4.8.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5->checklist) (1.0.18)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.7/dist-packages (from jupyter>=1.0->checklist) (5.2.0)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.7/dist-packages (from jupyter>=1.0->checklist) (5.3.1)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from jupyter>=1.0->checklist) (5.6.1)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.7/dist-packages (from jupyter>=1.0->checklist) (5.1.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from munch>=2.5->checklist) (1.15.0)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets>=7.5->checklist) (2.6.0)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets>=7.5->checklist) (4.7.1)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets>=7.5->checklist) (0.2.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipywidgets>=7.5->checklist) (0.2.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2->checklist) (7.4.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2->checklist) (1.0.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2->checklist) (1.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2->checklist) (0.8.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2->checklist) (3.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2->checklist) (1.1.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2->checklist) (2.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2->checklist) (1.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2->checklist) (0.4.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter>=1.0->checklist) (0.10.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter>=1.0->checklist) (2.11.3)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter>=1.0->checklist) (1.7.1)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets>=7.5->checklist) (22.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets>=7.5->checklist) (2.8.1)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook->jupyter>=1.0->checklist) (0.7.0)\n",
            "Collecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting s3transfer<0.6.0,>=0.5.0\n",
            "  Downloading s3transfer-0.5.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 11.0 MB/s \n",
            "\u001b[?25hCollecting botocore<1.22.0,>=1.21.16\n",
            "  Downloading botocore-1.21.16-py3-none-any.whl (7.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.8 MB 61.4 MB/s \n",
            "\u001b[?25hCollecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 9.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook->jupyter>=1.0->checklist) (2.0.1)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter>=1.0->checklist) (0.5.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter>=1.0->checklist) (1.4.3)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter>=1.0->checklist) (0.8.4)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter>=1.0->checklist) (0.7.1)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter>=1.0->checklist) (3.3.0)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter>=1.0->checklist) (0.3)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter>=1.0->checklist) (0.5.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from patternfork-nosql->checklist) (0.16.0)\n",
            "Collecting backports.csv\n",
            "  Downloading backports.csv-1.0.7-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from patternfork-nosql->checklist) (4.6.3)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from patternfork-nosql->checklist) (4.2.6)\n",
            "Collecting feedparser\n",
            "  Downloading feedparser-6.0.8-py3-none-any.whl (81 kB)\n",
            "\u001b[K     |████████████████████████████████| 81 kB 11.2 MB/s \n",
            "\u001b[?25hCollecting pdfminer.six\n",
            "  Downloading pdfminer.six-20201018-py3-none-any.whl (5.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 29.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from patternfork-nosql->checklist) (1.4.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from patternfork-nosql->checklist) (3.2.5)\n",
            "Collecting python-docx\n",
            "  Downloading python-docx-0.8.11.tar.gz (5.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 20.6 MB/s \n",
            "\u001b[?25hCollecting cherrypy\n",
            "  Downloading CherryPy-18.6.1-py2.py3-none-any.whl (419 kB)\n",
            "\u001b[K     |████████████████████████████████| 419 kB 50.2 MB/s \n",
            "\u001b[?25hCollecting portend>=2.1.1\n",
            "  Downloading portend-2.7.1-py3-none-any.whl (5.3 kB)\n",
            "Collecting cheroot>=8.2.1\n",
            "  Downloading cheroot-8.5.2-py2.py3-none-any.whl (97 kB)\n",
            "\u001b[K     |████████████████████████████████| 97 kB 8.4 MB/s \n",
            "\u001b[?25hCollecting zc.lockfile\n",
            "  Downloading zc.lockfile-2.0-py2.py3-none-any.whl (9.7 kB)\n",
            "Collecting jaraco.collections\n",
            "  Downloading jaraco.collections-3.3.0-py3-none-any.whl (9.9 kB)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.7/dist-packages (from cherrypy->patternfork-nosql->checklist) (8.8.0)\n",
            "Collecting jaraco.functools\n",
            "  Downloading jaraco.functools-3.3.0-py3-none-any.whl (6.8 kB)\n",
            "Collecting tempora>=1.8\n",
            "  Downloading tempora-4.1.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from tempora>=1.8->portend>=2.1.1->cherrypy->patternfork-nosql->checklist) (2018.9)\n",
            "Collecting sgmllib3k\n",
            "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
            "Collecting jaraco.classes\n",
            "  Downloading jaraco.classes-3.2.1-py3-none-any.whl (5.6 kB)\n",
            "Collecting jaraco.text\n",
            "  Downloading jaraco.text-3.5.1-py3-none-any.whl (8.1 kB)\n",
            "Collecting cryptography\n",
            "  Downloading cryptography-3.4.7-cp36-abi3-manylinux2014_x86_64.whl (3.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2 MB 55.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: sortedcontainers in /usr/local/lib/python3.7/dist-packages (from pdfminer.six->patternfork-nosql->checklist) (2.4.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography->pdfminer.six->patternfork-nosql->checklist) (1.14.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography->pdfminer.six->patternfork-nosql->checklist) (2.20)\n",
            "Requirement already satisfied: qtpy in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter>=1.0->checklist) (1.9.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Building wheels for collected packages: checklist, iso-639, patternfork-nosql, python-docx, sgmllib3k\n",
            "  Building wheel for checklist (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for checklist: filename=checklist-0.0.11-py3-none-any.whl size=12165634 sha256=4b519f862a756f0106cb8747952e309ad861187fcdd9f30b742684f62d1c7b45\n",
            "  Stored in directory: /root/.cache/pip/wheels/6a/8a/07/6446879be434879c27671c83443727d74cecf6b630c8a24d03\n",
            "  Building wheel for iso-639 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for iso-639: filename=iso_639-0.4.5-py3-none-any.whl size=169062 sha256=c8c383e42c22e92278e0c976c14020bafef7b958b7fd38dd7d2609e1a060c38b\n",
            "  Stored in directory: /root/.cache/pip/wheels/47/60/19/6d020fc92138ed1b113a18271e83ea4b5525fe770cb45b9a2e\n",
            "  Building wheel for patternfork-nosql (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for patternfork-nosql: filename=patternfork_nosql-3.6-py3-none-any.whl size=22332805 sha256=bd8428251118d5a9a7df29f59e32becb597ae2cd625622f8ad813e3f63eebd62\n",
            "  Stored in directory: /root/.cache/pip/wheels/97/72/8f/5305fe28168f93b658da9ed433b9a1d3ec90594faa0c9aaf4b\n",
            "  Building wheel for python-docx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-docx: filename=python_docx-0.8.11-py3-none-any.whl size=184507 sha256=fa6c90fd7aa3e2a5d40b0bb83f143fdd1474614479f3949a0df5e29c3d49d1d4\n",
            "  Stored in directory: /root/.cache/pip/wheels/f6/6f/b9/d798122a8b55b74ad30b5f52b01482169b445fbb84a11797a6\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6065 sha256=2e8ce03b2f11e763b964ccdf458c58726730fc221d57e1bf6b728d263a5cd8bf\n",
            "  Stored in directory: /root/.cache/pip/wheels/73/ad/a4/0dff4a6ef231fc0dfa12ffbac2a36cebfdddfe059f50e019aa\n",
            "Successfully built checklist iso-639 patternfork-nosql python-docx sgmllib3k\n",
            "Installing collected packages: jaraco.functools, urllib3, tempora, jmespath, jaraco.text, jaraco.classes, zc.lockfile, sgmllib3k, portend, jaraco.collections, cryptography, cheroot, botocore, tokenizers, sacremoses, s3transfer, pyyaml, python-docx, pdfminer.six, huggingface-hub, feedparser, cherrypy, backports.csv, transformers, sentencepiece, patternfork-nosql, munch, iso-639, boto3, checklist, bertviz\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed backports.csv-1.0.7 bertviz-1.2.0 boto3-1.18.16 botocore-1.21.16 checklist-0.0.11 cheroot-8.5.2 cherrypy-18.6.1 cryptography-3.4.7 feedparser-6.0.8 huggingface-hub-0.0.12 iso-639-0.4.5 jaraco.classes-3.2.1 jaraco.collections-3.3.0 jaraco.functools-3.3.0 jaraco.text-3.5.1 jmespath-0.10.0 munch-2.5.0 patternfork-nosql-3.6 pdfminer.six-20201018 portend-2.7.1 python-docx-0.8.11 pyyaml-5.4.1 s3transfer-0.5.0 sacremoses-0.0.45 sentencepiece-0.1.96 sgmllib3k-1.0.0 tempora-4.1.1 tokenizers-0.10.3 transformers-4.9.1 urllib3-1.25.11 zc.lockfile-2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmmy8-VA3__6"
      },
      "source": [
        "# Data loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pm5jSAP0No_j",
        "outputId": "2dea3ae4-1dca-430a-d256-e20b29b99a68"
      },
      "source": [
        "!rm -rf ru_news_cause_v2.tsv*\n",
        "!wget https://www.dropbox.com/s/m1kb0dn6q5mcb6v/ru_news_cause_v2.tsv.tar.gz\n",
        "!tar -xzvf ru_news_cause_v2.tsv.tar.gz\n",
        "\n",
        "!rm -rf en_news_cause_v0.tsv*\n",
        "!wget https://www.dropbox.com/s/7w4zf8ogqonwb8i/en_news_cause_v0.tsv.tar.gz\n",
        "!tar -xzvf en_news_cause_v0.tsv.tar.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-08-07 16:06:34--  https://www.dropbox.com/s/m1kb0dn6q5mcb6v/ru_news_cause_v2.tsv.tar.gz\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.5.18, 2620:100:601d:18::a27d:512\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.5.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/m1kb0dn6q5mcb6v/ru_news_cause_v2.tsv.tar.gz [following]\n",
            "--2021-08-07 16:06:34--  https://www.dropbox.com/s/raw/m1kb0dn6q5mcb6v/ru_news_cause_v2.tsv.tar.gz\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ucb4c590fe4d9a68acc0d3534cc6.dl.dropboxusercontent.com/cd/0/inline/BTywhfHb3gYGROEsjBPcw9PkovW5sDjPaq-yrM1okWIrUdF-T-Yz4QBMGk7_N5tMuE1epr-19XiN01KkgVB7jFOOjgXYoBDbX9FX_o3h4NJBjR-hQ1j7LUDSgysGvPxvZphYAaqS46HPhdwRhyT0YxgX/file# [following]\n",
            "--2021-08-07 16:06:35--  https://ucb4c590fe4d9a68acc0d3534cc6.dl.dropboxusercontent.com/cd/0/inline/BTywhfHb3gYGROEsjBPcw9PkovW5sDjPaq-yrM1okWIrUdF-T-Yz4QBMGk7_N5tMuE1epr-19XiN01KkgVB7jFOOjgXYoBDbX9FX_o3h4NJBjR-hQ1j7LUDSgysGvPxvZphYAaqS46HPhdwRhyT0YxgX/file\n",
            "Resolving ucb4c590fe4d9a68acc0d3534cc6.dl.dropboxusercontent.com (ucb4c590fe4d9a68acc0d3534cc6.dl.dropboxusercontent.com)... 162.125.5.15, 2620:100:601d:15::a27d:50f\n",
            "Connecting to ucb4c590fe4d9a68acc0d3534cc6.dl.dropboxusercontent.com (ucb4c590fe4d9a68acc0d3534cc6.dl.dropboxusercontent.com)|162.125.5.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/BTyKgWGf-m-y2A_aHUwPhtdPDlg86ic3Y19q8njRYhQru_gIKkvm-tSYlQ8h2UAUfPnSIca-jLmqSrU1Pc-egml_hDMKoaewhbkMPmrDlrNus8RIsGMGUvv5Fct5L4ZtBw01rDSB7Pu-etrCVP520qD6EdbzD2MQXdGqSiKd_0JNZJrN-dC668heNsJ4HYeT3SPuM8LKUFL7BF-dd57OZladW2XJEQYVn0w0Rzh9m12v2ORdiK4ABAngVidp52HkP0s9VZAmuXbrDZ32IcvsFnzjGvnKU2qoLQ6HrCGsZNv7MVZS-xYWZ3LQxgzYTecIHvY2m_jgxpHzte2rkussW1HOUwSToXyF_UANxKgsSEfAFGarFqOyNRi34IfMsg1havo/file [following]\n",
            "--2021-08-07 16:06:35--  https://ucb4c590fe4d9a68acc0d3534cc6.dl.dropboxusercontent.com/cd/0/inline2/BTyKgWGf-m-y2A_aHUwPhtdPDlg86ic3Y19q8njRYhQru_gIKkvm-tSYlQ8h2UAUfPnSIca-jLmqSrU1Pc-egml_hDMKoaewhbkMPmrDlrNus8RIsGMGUvv5Fct5L4ZtBw01rDSB7Pu-etrCVP520qD6EdbzD2MQXdGqSiKd_0JNZJrN-dC668heNsJ4HYeT3SPuM8LKUFL7BF-dd57OZladW2XJEQYVn0w0Rzh9m12v2ORdiK4ABAngVidp52HkP0s9VZAmuXbrDZ32IcvsFnzjGvnKU2qoLQ6HrCGsZNv7MVZS-xYWZ3LQxgzYTecIHvY2m_jgxpHzte2rkussW1HOUwSToXyF_UANxKgsSEfAFGarFqOyNRi34IfMsg1havo/file\n",
            "Reusing existing connection to ucb4c590fe4d9a68acc0d3534cc6.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 598643 (585K) [application/octet-stream]\n",
            "Saving to: ‘ru_news_cause_v2.tsv.tar.gz’\n",
            "\n",
            "ru_news_cause_v2.ts 100%[===================>] 584.61K  --.-KB/s    in 0.08s   \n",
            "\n",
            "2021-08-07 16:06:35 (6.73 MB/s) - ‘ru_news_cause_v2.tsv.tar.gz’ saved [598643/598643]\n",
            "\n",
            "ru_news_cause_v2.tsv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bV6i0sRfN3NH",
        "outputId": "aa3e3630-1107-4ed2-e834-1e093f9b7c4c"
      },
      "source": [
        "!cat ru_news_cause_v2.tsv | wc -l\n",
        "!head ru_news_cause_v2.tsv\n",
        "\n",
        "!cat en_news_cause_v0.tsv | wc -l\n",
        "!head en_news_cause_v0.tsv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5406\n",
            "id\tleft_title\tright_title\tleft_url\tright_url\tleft_timestamp\tright_timestamp\tconfidence\tresult\toverlap\tmv_part\n",
            "tg_9993\tРабочие устроили бунт на базе «Газпрома» для «Силы Сибири»\t«Газпром» ответил на сообщения о бунте вахтовиков\thttps://lenta.ru/news/2020/04/28/bund/\thttps://lenta.ru/news/2020/04/28/gazprom_protest/\t1588032000\t1588032000\t1.0\tleft_right_cause\t10\t1.0\n",
            "tg_99296\tТрехлетняя девочка выжила после падения с восьмого этажа в Электростали\tТрехлетняя девочка выпала с восьмого этажа и выжила в Электростали\thttps://iz.ru/1008987/2020-05-08/trekhletniaia-devochka-vyzhila-posle-padeniia-s-vosmogo-etazha-v-elektrostali\thttps://mosregtoday.ru/sec/trehletnyaya-devochka-vypala-s-vosmogo-etazha-i-vyzhila-v-elektrostali/\t1588928652\t1588921081\t1.0\tsame\t10\t1.0\n",
            "tg_99290\tМВД: В результате стрельбы на улице Павла Андреева никто не пострадал\tНеизвестные устроили стрельбу в центре Москвы\thttps://www.mskagency.ru/materials/3001509\thttps://iz.ru/1008984/2020-05-08/neizvestnye-ustroili-strelbu-v-tcentre-moskvy\t1588936800\t1588928584\t1.0\tright_left_cause\t10\t0.7\n",
            "tg_97937\tОфициально: Зеленский издал указ о назначении Саакашвили\tСаакашвили признался, чем будет заниматься на новой должности при Зеленскому\thttps://www.obozrevatel.com/politics/saakashvili-poluchil-dolzhnost-v-pravitelstve.htm\thttps://www.obozrevatel.com/politics/saakashvili-priznalsya-chem-budet-zanimatsya-na-novoj-dolzhnosti-pri-zelenskomu.htm\t1588871880\t1588922640\t1.0\tleft_right_cause\t10\t0.9\n",
            "tg_97812\tПутин и Нетаньяху провели телефонные переговоры\tТелефонный разговор с Премьер-министром Израиля Биньямином Нетаньяху\thttps://russian.rt.com/world/news/744834-putin-netanyahu-peregovory\thttp://kremlin.ru/events/president/news/63317\t1588922040\t1588931100\t1.0\tsame\t10\t1.0\n",
            "tg_97366\tБанки не воспользовались разрешением ЦБ удаленно открывать счета\tКрупнейшие банки решили не позволять открывать счета удаленно\thttps://www.rbc.ru/finances/08/05/2020/5eb40e6e9a794717c29c4803\thttps://rspectr.com/novosti/59102/krupnejshie-banki-reshili-ne-pozvolyat-otkryvat-scheta-udalenno\t1588899615\t1588920000\t1.0\tsame\t10\t0.8\n",
            "tg_9643\tЭкс-советник Путина назвал неожиданную причину ''разработки'' COVID-19 в лабораториях Китая\tКитай подловили на вранье о происхождении коронавируса: что не сходится\thttps://www.obozrevatel.com/abroad/illarionov-nazval-neozhidannuyu-prichinu-razrabotki-covid-19-v-laboratoriyah-kitaya.htm\thttps://www.obozrevatel.com/abroad/kitaj-podlovili-na-vrane-o-proishozhdenii-koronavirusa-chto-ne-shoditsya.htm\t1588080420\t1588064880\t1.0\trel\t10\t0.9\n",
            "tg_96387\tReuters: эксперимент в московской больнице показал, что российские тесты на коронавирус «крайне неточны»\tМэрия Москвы закупила сотни тысяч китайских тестов на антитела к коронавирусу под видом голландских\thttps://zona.media/news/2020/05/08/tests\thttps://zona.media/news/2020/05/06/nttl\t1588914300\t1588748040\t1.0\trel\t10\t0.7\n",
            "tg_96271\tВ Татарстане скончался пятый человек с коронавирусом\tВ Татарстане скончался четвертый человек с коронавирусом\thttps://inkazan.ru/news/society/08-05-2020/v-tatarstane-skonchalsya-pyatyy-chelovek-s-koronavirusom\thttps://inkazan.ru/news/society/06-05-2020/v-tatarstane-skonchalsya-chetvertyy-chelovek-s-koronavirusom\t1588913659\t1588740759\t1.0\tright_left_cancel\t10\t1.0\n",
            "814\n",
            "id\tleft_title\tright_title\tleft_url\tright_url\tleft_timestamp\tright_timestamp\tconfidence\tresult\toverlap\tmv_part\n",
            "tg_97069\tMay 2020 week two fuel price – no change in pricing\tMay 2020 week one fuel price – no change in pricing\thttps://paultan.org/2020/05/08/may-2020-week-two-fuel-price-no-change-in-pricing/\thttps://paultan.org/2020/05/01/may-2020-week-one-fuel-price-no-change-in-pricing/\t1588918238\t1588316205\t1.0\tright_left_cancel\t10\t0.7\n",
            "tg_93946\tSmall businesses shun JobKeeper over cash flow concerns\tCash-strapped small businesses shun JobKeeper\thttps://www.macrobusiness.com.au/2020/04/small-businesses-shun-jobkeeper-over-cash-flow-concerns/\thttps://www.macrobusiness.com.au/2020/05/cash-strapped-small-businesses-shun-jobkeeper/\t1588024810\t1588885248\t1.0\tsame\t10\t1.0\n",
            "tg_93357\tJustice moves to drop case against Flynn\tDemocrats renew calls for Barr to resign after DOJ drops Flynn case\thttps://thehill.com/homenews/administration/496640-justice-drops-case-against-flynn\thttps://thehill.com/homenews/news/496726-democrats-renew-calls-for-barr-to-resign-after-doj-drops-flynn-case\t1588865997\t1588883417\t1.0\tleft_right_cause\t10\t1.0\n",
            "tg_91057\tWATCH | Cape Town man speaks out as cops hunt pair who torched his car\tWATCH | Car of man feeding homeless in upmarket Mouille Point torched\thttps://www.news24.com/SouthAfrica/News/watch-cape-town-man-speaks-out-as-cops-hunt-pair-who-torched-his-car-20200507\thttps://www.news24.com/SouthAfrica/News/watch-car-of-man-feeding-homeless-in-upmarket-mouille-point-torched-20200506\t1588863900\t1588779900\t1.0\tright_left_cause\t10\t0.7\n",
            "tg_88434\tWatch Microsoft's Xbox Series X gameplay stream here at 11AM ET\tMicrosoft will show off Xbox Series X gameplay next week\thttps://www.engadget.com/watch-inside-xbox-143421721.html\thttps://www.engadget.com/inside-xbox-series-x-gameplay-171945902.html\t1588851261\t1588256385\t1.0\tright_left_cancel\t10\t0.7\n",
            "tg_85607\tPassengers from abroad to undergo 2 screenings at IGIA\tOnly paid quarantine facility for passengers landing at Delhi airport\thttps://www.thehindu.com/news/cities/Delhi/passengers-from-abroad-to-undergo-2-screenings-at-igia/article31521545.ece\thttps://www.thehindu.com/news/cities/Delhi/only-paid-quarantine-facility-for-passengers-landing-at-delhi-airport/article31525683.ece\t1588777410\t1588836647\t1.0\tbad\t10\t0.8\n",
            "tg_82757\tThat Rumoured HD Remaster Of The Mass Effect Trilogy Might Be Coming To Switch\tEA Play Live Goes Digital This June - Expect World Premieres, News And Much More\thttp://www.nintendolife.com/news/2020/05/that_rumoured_hd_remaster_of_the_mass_effect_trilogy_might_be_coming_to_switch\thttp://www.nintendolife.com/news/2020/05/ea_play_live_goes_digital_this_june_-_expect_world_premieres_news_and_much_more\t1588815900\t1588643100\t1.0\tbad\t10\t1.0\n",
            "tg_76381\tPolice called to massive queues outside KFC after branch reopens in Mansfield\tA second KFC re-opens drive-thru in Notts\thttps://www.nottinghampost.com/news/local-news/police-called-massive-queues-outside-4108869\thttps://www.nottinghampost.com/whats-on/food-drink/second-kfc-re-opens-drive-4109760\t1588752960\t1588764000\t1.0\trel\t10\t0.6\n",
            "tg_75107\t47 new cases of Coronavirus in Kenya, total rises to 582\tKenya records 45 new cases of Coronavirus, total hits 535\thttps://www.pulselive.co.ke/news/47-new-cases-of-coronavirus-in-kenya-total-at-582/753g3k9\thttps://www.pulselive.co.ke/news/kenya-records-45-new-cases-of-coronavirus-total-hits-536/g524efr\t1588758036\t1588668500\t1.0\tright_left_cancel\t10\t0.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEhRCkSOwsGj"
      },
      "source": [
        "# BertCause"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqyfs3dw4Dmu"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlYo1CIaQLY7"
      },
      "source": [
        "import random\n",
        "import torch\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def set_random_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:2\"\n",
        "    os.environ[\"PL_GLOBAL_SEED\"] = str(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "set_random_seed(1337)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAZ3HW8iN9-h"
      },
      "source": [
        "import csv\n",
        "\n",
        "def read_records(file_name):\n",
        "    records = []\n",
        "    with open(file_name, \"r\") as r:\n",
        "        reader = csv.reader(r, delimiter=\"\\t\")\n",
        "        header = next(reader)\n",
        "        for row in reader:\n",
        "            r = dict(zip(header, row))\n",
        "            result = r[\"result\"]\n",
        "            mapping = {\n",
        "                \"bad\": 0,\n",
        "                \"rel\": 0,\n",
        "                \"same\": 0,\n",
        "                \"left_right_cause\": 1,\n",
        "                \"left_right_cancel\": 1,\n",
        "                \"right_left_cause\": 2,\n",
        "                \"right_left_cancel\": 2\n",
        "            }\n",
        "            if result not in mapping:\n",
        "                continue\n",
        "            r[\"label\"] = mapping[result]\n",
        "            records.append(r)\n",
        "    return records\n",
        "\n",
        "ru_records = read_records(\"ru_news_cause_v2.tsv\")\n",
        "en_records = read_records(\"en_news_cause_v0.tsv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WN65SEFpOOmI",
        "outputId": "979bff58-4bb4-4d51-82b7-ddf871cf6b28"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "ru_labels_counter = Counter([r[\"label\"] for r in ru_records])\n",
        "print(ru_labels_counter)\n",
        "en_labels_counter = Counter([r[\"label\"] for r in en_records])\n",
        "print(en_labels_counter)\n",
        "labels_count = len(ru_labels_counter + en_labels_counter)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counter({0: 3605, 2: 925, 1: 875})\n",
            "Counter({0: 457, 1: 190, 2: 166})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFjhL0bWQRov"
      },
      "source": [
        "import json\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "class NewsPairsDataset(Dataset):\n",
        "    def __init__(self, records, tokenizer, max_tokens, labels_count):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_tokens = max_tokens\n",
        "        self.records = records\n",
        "        self.labels_count = labels_count\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.records)\n",
        "    \n",
        "    def embed_record(self, record):\n",
        "        inputs = self.tokenizer(\n",
        "            text=record[\"left_title\"],\n",
        "            text_pair=record[\"right_title\"],\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_tokens,\n",
        "            padding=\"max_length\",\n",
        "            truncation=\"longest_first\",\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        for key, value in inputs.items():\n",
        "            value.squeeze_(0)\n",
        "        return inputs\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        record = self.records[index]\n",
        "        output = self.embed_record(record)\n",
        "        label = record.get(\"label\", None)\n",
        "        if label is not None:\n",
        "            output[\"labels\"] = torch.tensor(label)\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RkHClonSW6p",
        "outputId": "199a9246-dcc5-4435-aa4d-131f912397ac"
      },
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "def split_with_source(records, val_border=0.8, test_border=0.9):\n",
        "    records_by_source = defaultdict(list)\n",
        "    for r in records:\n",
        "        source = r[\"id\"].split(\"_\")[0]\n",
        "        records_by_source[source].append(r)\n",
        "\n",
        "    train_records, val_records, test_records = [], [], []\n",
        "    for _, source_records in records_by_source.items():\n",
        "        source_records.sort(key=lambda x: min(x[\"left_timestamp\"], x[\"right_timestamp\"]))\n",
        "        val_border = int(0.8 * len(source_records))\n",
        "        test_border = int(0.9 * len(source_records))\n",
        "        train_records.extend(source_records[:val_border])\n",
        "        val_records.extend(source_records[val_border:test_border])\n",
        "        test_records.extend(source_records[test_border:])\n",
        "    return train_records, val_records, test_records\n",
        "\n",
        "ru_train_records, ru_val_records, ru_test_records = split_with_source(ru_records)\n",
        "print(\"RU:\")\n",
        "print(len(ru_train_records))\n",
        "print(len(ru_val_records))\n",
        "print(len(ru_test_records))\n",
        "print()\n",
        "\n",
        "en_train_records, en_val_records, en_test_records = split_with_source(en_records)\n",
        "print(\"EN:\")\n",
        "print(len(en_train_records))\n",
        "print(len(en_val_records))\n",
        "print(len(en_test_records))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RU:\n",
            "4323\n",
            "540\n",
            "542\n",
            "\n",
            "EN:\n",
            "650\n",
            "81\n",
            "82\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2MH-5BGCpVO"
      },
      "source": [
        "# MODEL_NAME = \"DeepPavlov/rubert-base-cased\"\n",
        "MODEL_NAME = \"xlm-roberta-large\"\n",
        "TOKENIZER_NAME = MODEL_NAME\n",
        "MAX_TOKENS = 80"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQJNA6XPScDJ"
      },
      "source": [
        "import random\n",
        "\n",
        "train_records = ru_train_records + en_train_records\n",
        "val_records = ru_val_records + en_val_records\n",
        "random.shuffle(train_records)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_NAME, do_lower_case=False)\n",
        "train_data = NewsPairsDataset(train_records, tokenizer, MAX_TOKENS, labels_count)\n",
        "val_data = NewsPairsDataset(val_records, tokenizer, MAX_TOKENS, labels_count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_JPSreIS04O",
        "outputId": "b82137dc-26d9-49e0-ef2d-e09187961839"
      },
      "source": [
        "for item in train_data:\n",
        "    print(item)\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'input_ids': tensor([     0, 181599,   3737, 122387,  28832, 129334, 174056,  92890,  11981,\n",
            "        211247,  82626,  20017,    419,     49,   8568,      2,      2, 119123,\n",
            "         44308,  93958,     59,  45472,  63062,    476, 122387,  53871, 129334,\n",
            "         60637,     89,  30462,   1993, 211247,  82626,  20017,     59,      2,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), 'labels': tensor(0)}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMYTxiJuS8yV",
        "outputId": "df22e3e2-8265-4038-b5a4-4c427a6201d4"
      },
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=labels_count)\n",
        "model = model.to(\"cuda\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at xlm-roberta-large were not used when initializing XLMRobertaForSequenceClassification: ['lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.bias', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias', 'lm_head.layer_norm.weight']\n",
            "- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FloOjGTgj9V_"
      },
      "source": [
        "!rm -rf checkpoints"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tG2C771mdRP2"
      },
      "source": [
        "#@title Training params\n",
        "EPOCHS = 6#@param {type:\"number\"}\n",
        "EVAL_STEPS = 16#@param {type:\"number\"}\n",
        "WARMUP_STEPS = 8#@param {type:\"number\"}\n",
        "LR = 0.00003#@param {type:\"number\"}\n",
        "BATCH_SIZE = 32#@param {type:\"number\"}\n",
        "GRAD_ACCUM_STEPS = 4#@param {type:\"number\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wIxaG3SBS9z-",
        "outputId": "5276783e-896e-4059-9633-32cef4ebdecb"
      },
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"checkpoints\",\n",
        "    evaluation_strategy=\"steps\",\n",
        "    save_strategy=\"steps\",\n",
        "    per_device_train_batch_size=BATCH_SIZE,\n",
        "    per_device_eval_batch_size=BATCH_SIZE,\n",
        "    logging_steps=EVAL_STEPS,\n",
        "    save_steps=EVAL_STEPS,\n",
        "    warmup_steps=WARMUP_STEPS,\n",
        "    learning_rate=LR,\n",
        "    num_train_epochs=EPOCHS,\n",
        "    gradient_accumulation_steps=GRAD_ACCUM_STEPS,\n",
        "    report_to=\"none\",\n",
        "    load_best_model_at_end=True\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_data,\n",
        "    eval_dataset=val_data\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 4973\n",
            "  Num Epochs = 6\n",
            "  Instantaneous batch size per device = 32\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
            "  Gradient Accumulation steps = 4\n",
            "  Total optimization steps = 234\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='234' max='234' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [234/234 28:48, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.964700</td>\n",
              "      <td>0.922024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>0.841200</td>\n",
              "      <td>0.808545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>0.678400</td>\n",
              "      <td>0.707206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>64</td>\n",
              "      <td>0.618600</td>\n",
              "      <td>0.684942</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>0.594100</td>\n",
              "      <td>0.640631</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>96</td>\n",
              "      <td>0.513900</td>\n",
              "      <td>0.684243</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>112</td>\n",
              "      <td>0.461900</td>\n",
              "      <td>0.435086</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>128</td>\n",
              "      <td>0.296700</td>\n",
              "      <td>0.370078</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>144</td>\n",
              "      <td>0.251200</td>\n",
              "      <td>0.352107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>0.230900</td>\n",
              "      <td>0.297958</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>176</td>\n",
              "      <td>0.149600</td>\n",
              "      <td>0.338981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>192</td>\n",
              "      <td>0.161200</td>\n",
              "      <td>0.325869</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>208</td>\n",
              "      <td>0.118800</td>\n",
              "      <td>0.309291</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>224</td>\n",
              "      <td>0.093600</td>\n",
              "      <td>0.313824</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 621\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to checkpoints/checkpoint-16\n",
            "Configuration saved in checkpoints/checkpoint-16/config.json\n",
            "Model weights saved in checkpoints/checkpoint-16/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 621\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to checkpoints/checkpoint-32\n",
            "Configuration saved in checkpoints/checkpoint-32/config.json\n",
            "Model weights saved in checkpoints/checkpoint-32/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 621\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to checkpoints/checkpoint-48\n",
            "Configuration saved in checkpoints/checkpoint-48/config.json\n",
            "Model weights saved in checkpoints/checkpoint-48/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 621\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to checkpoints/checkpoint-64\n",
            "Configuration saved in checkpoints/checkpoint-64/config.json\n",
            "Model weights saved in checkpoints/checkpoint-64/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 621\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to checkpoints/checkpoint-80\n",
            "Configuration saved in checkpoints/checkpoint-80/config.json\n",
            "Model weights saved in checkpoints/checkpoint-80/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 621\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to checkpoints/checkpoint-96\n",
            "Configuration saved in checkpoints/checkpoint-96/config.json\n",
            "Model weights saved in checkpoints/checkpoint-96/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 621\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to checkpoints/checkpoint-112\n",
            "Configuration saved in checkpoints/checkpoint-112/config.json\n",
            "Model weights saved in checkpoints/checkpoint-112/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 621\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to checkpoints/checkpoint-128\n",
            "Configuration saved in checkpoints/checkpoint-128/config.json\n",
            "Model weights saved in checkpoints/checkpoint-128/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 621\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to checkpoints/checkpoint-144\n",
            "Configuration saved in checkpoints/checkpoint-144/config.json\n",
            "Model weights saved in checkpoints/checkpoint-144/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 621\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to checkpoints/checkpoint-160\n",
            "Configuration saved in checkpoints/checkpoint-160/config.json\n",
            "Model weights saved in checkpoints/checkpoint-160/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 621\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to checkpoints/checkpoint-176\n",
            "Configuration saved in checkpoints/checkpoint-176/config.json\n",
            "Model weights saved in checkpoints/checkpoint-176/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 621\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to checkpoints/checkpoint-192\n",
            "Configuration saved in checkpoints/checkpoint-192/config.json\n",
            "Model weights saved in checkpoints/checkpoint-192/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 621\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to checkpoints/checkpoint-208\n",
            "Configuration saved in checkpoints/checkpoint-208/config.json\n",
            "Model weights saved in checkpoints/checkpoint-208/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 621\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to checkpoints/checkpoint-224\n",
            "Configuration saved in checkpoints/checkpoint-224/config.json\n",
            "Model weights saved in checkpoints/checkpoint-224/pytorch_model.bin\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from checkpoints/checkpoint-160 (score: 0.29795804619789124).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=234, training_loss=0.412297681101367, metrics={'train_runtime': 1731.7585, 'train_samples_per_second': 17.23, 'train_steps_per_second': 0.135, 'total_flos': 4344853433261760.0, 'train_loss': 0.412297681101367, 'epoch': 6.0})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igp38wLG38vq"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JCwfMpNCDiD"
      },
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "model.eval()\n",
        "pipe = pipeline(\"text-classification\", model=model, tokenizer=tokenizer, framework=\"pt\", device=0, return_all_scores=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sV9t43vBCevH",
        "outputId": "2a391929-5b89-469f-9d54-15297c236a5b"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "ru_y_true = np.array([r[\"label\"] for r in ru_test_records], dtype=np.int32)\n",
        "en_y_true = np.array([r[\"label\"] for r in en_test_records], dtype=np.int32)\n",
        "print(ru_y_true)\n",
        "print(en_y_true)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2 1 0 1 0 0 0 0 2 1 2 1 0 1 1 1 2 1 0 0 0 0 0 1 0 0 2 1 0 0 0 1 0 1 0 0 0\n",
            " 0 0 0 0 0 0 2 0 0 1 0 0 0 0 0 0 2 1 0 1 1 0 2 0 0 0 0 0 0 0 0 0 1 0 0 1 0\n",
            " 0 1 2 0 0 0 1 0 1 0 0 0 2 0 2 0 0 0 1 0 0 0 0 2 0 0 0 2 0 1 1 0 0 0 0 0 0\n",
            " 2 0 1 1 0 1 1 2 0 0 1 0 0 0 0 1 1 0 0 0 2 0 1 0 2 0 0 0 2 0 2 2 1 0 1 0 0\n",
            " 0 0 2 1 0 0 0 2 0 0 0 0 1 2 1 2 1 2 0 0 0 1 0 1 1 0 1 0 2 0 2 2 1 0 2 2 0\n",
            " 0 0 0 1 1 2 0 0 0 2 0 1 1 0 1 2 2 0 1 0 2 0 1 2 1 1 1 2 0 2 2 0 0 0 0 0 0\n",
            " 0 0 2 1 0 1 0 0 0 0 2 0 0 0 1 0 2 0 0 0 1 0 1 1 0 0 0 0 0 2 1 0 0 2 1 0 0\n",
            " 1 2 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 0 0 2 2 2 1 1 2 0 0 0 0 0 1 0 0 1 1\n",
            " 0 1 0 1 0 0 1 1 0 0 0 0 0 0 2 0 0 2 0 0 0 0 1 0 1 2 1 0 0 1 0 2 0 0 1 2 1\n",
            " 1 0 0 0 1 1 0 2 2 1 2 1 1 1 0 1 1 0 0 0 1 2 1 2 0 1 2 0 2 2 0 2 0 0 2 0 2\n",
            " 0 0 0 1 2 2 0 0 0 0 2 2 1 0 0 1 1 2 0 1 0 0 0 0 0 1 0 0 0 2 0 2 0 1 2 2 1\n",
            " 2 0 1 1 1 1 0 1 1 0 0 0 0 0 1 0 1 0 0 0 0 1 0 1 2 1 0 2 0 1 2 2 0 0 2 0 0\n",
            " 0 2 0 0 2 0 0 0 0 0 0 0 0 0 0 0 1 2 1 1 2 0 0 1 2 0 2 2 0 1 0 0 0 1 1 0 2\n",
            " 1 1 1 1 2 1 1 2 1 1 1 1 0 1 0 0 1 2 1 2 1 1 0 0 0 1 1 2 1 0 0 1 1 2 2 0 0\n",
            " 2 1 2 2 1 1 0 0 1 1 2 0 2 1 1 2 0 1 1 2 0 1 0 0]\n",
            "[0 0 0 0 1 0 1 1 0 0 1 1 0 2 0 0 0 0 2 0 0 1 2 1 0 0 0 2 0 2 2 0 1 0 1 0 1\n",
            " 0 0 0 1 0 2 0 0 1 0 1 0 0 0 1 0 2 0 0 0 0 2 0 0 0 2 1 2 2 1 2 0 1 2 1 2 0\n",
            " 2 2 0 0 0 1 1 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAU_PwzoCYBr",
        "outputId": "94e431c8-e0a0-47ff-bd08-f3382307f314"
      },
      "source": [
        "def pipe_predict(data, batch_size=64):\n",
        "    raw_preds = pipe(data, batch_size=batch_size)\n",
        "    preds = np.array([int(max(labels, key=lambda x: x[\"score\"])[\"label\"][-1]) for labels in raw_preds])\n",
        "    pp = np.array([[l[\"score\"] for l in labels] for labels in raw_preds])\n",
        "    return preds, pp\n",
        "\n",
        "ru_test_pairs = [(r[\"left_title\"], r[\"right_title\"]) for r in ru_test_records]\n",
        "en_test_pairs = [(r[\"left_title\"], r[\"right_title\"]) for r in en_test_records]\n",
        "ru_y_pred = pipe_predict(ru_test_pairs)[0]\n",
        "en_y_pred = pipe_predict(en_test_pairs)[0]\n",
        "for p, r in zip(ru_y_pred, ru_test_records):\n",
        "    r[\"prediction\"] = p\n",
        "for p, r in zip(en_y_pred, en_test_records):\n",
        "    r[\"prediction\"] = p\n",
        "print(ru_y_pred)\n",
        "print(en_y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2 1 0 1 0 0 0 0 2 1 0 0 0 2 1 1 2 1 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 1 0 0 0\n",
            " 0 0 0 0 0 0 0 2 1 1 0 0 0 0 0 0 2 1 0 1 1 0 2 0 0 0 0 0 0 0 0 1 1 0 0 1 0\n",
            " 1 1 2 0 0 0 1 0 1 0 2 0 0 1 2 0 0 0 1 2 0 0 0 2 0 0 0 0 0 1 1 0 1 0 1 0 0\n",
            " 2 0 1 1 0 1 1 2 0 0 1 0 0 0 0 1 1 0 0 0 2 0 1 0 0 0 0 0 0 0 2 2 0 0 1 0 0\n",
            " 0 0 2 1 0 0 0 2 0 1 0 0 1 0 1 2 1 2 0 0 0 0 0 1 1 0 1 0 2 0 2 0 1 0 2 2 0\n",
            " 0 0 0 1 2 2 0 0 0 0 0 1 1 0 1 2 2 0 1 0 0 0 1 2 1 1 1 0 1 0 2 0 0 0 0 0 0\n",
            " 0 0 2 1 0 1 0 0 2 0 2 0 0 0 1 0 2 0 0 0 1 0 1 1 0 0 0 0 0 2 1 0 0 2 1 0 0\n",
            " 1 2 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 2 2 1 1 2 0 0 0 0 2 1 0 0 1 1\n",
            " 0 1 0 0 0 0 1 1 0 0 0 0 0 0 2 0 0 2 0 2 0 0 1 0 1 2 1 0 0 0 0 2 0 0 2 0 1\n",
            " 1 0 0 0 1 0 0 2 2 1 2 1 1 0 0 1 1 0 0 0 0 2 0 2 0 0 2 0 2 2 0 2 0 0 2 0 2\n",
            " 0 2 0 1 2 2 0 0 0 0 2 2 0 1 0 0 0 2 0 0 0 0 0 0 0 1 0 0 0 2 0 2 0 1 2 2 1\n",
            " 2 0 1 0 1 1 0 1 1 0 0 0 0 0 1 0 1 0 0 0 0 1 0 1 2 1 0 2 0 1 2 2 0 0 2 0 0\n",
            " 0 2 1 0 2 0 0 2 0 0 0 0 0 0 0 0 1 2 1 1 0 2 2 1 2 0 2 2 0 1 0 0 0 1 0 0 2\n",
            " 1 1 1 1 2 1 1 2 1 1 1 0 0 0 0 0 1 0 1 2 1 1 1 1 2 1 1 2 1 0 0 1 1 2 2 0 0\n",
            " 2 1 2 2 1 1 0 0 1 1 2 0 0 1 1 2 0 1 1 0 0 1 2 0]\n",
            "[0 0 0 0 0 0 0 1 0 1 1 0 0 2 1 0 0 0 2 0 0 1 2 1 0 0 0 0 0 1 2 0 1 0 1 0 1\n",
            " 0 0 0 1 1 2 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 2 0 0 0 2 0 0 2 1 0 0 1 1 1 2 0\n",
            " 2 2 0 0 0 2 1 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XsGC0E_-4Hz2",
        "outputId": "1606a7fa-b5ca-44e2-9932-894eb931bf20"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(ru_y_true, ru_y_pred))\n",
        "print(classification_report(en_y_true, en_y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.91      0.89       291\n",
            "           1       0.91      0.85      0.88       148\n",
            "           2       0.85      0.81      0.83       103\n",
            "\n",
            "    accuracy                           0.88       542\n",
            "   macro avg       0.88      0.86      0.87       542\n",
            "weighted avg       0.88      0.88      0.88       542\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.91      0.86        44\n",
            "           1       0.70      0.70      0.70        20\n",
            "           2       0.92      0.67      0.77        18\n",
            "\n",
            "    accuracy                           0.80        82\n",
            "   macro avg       0.81      0.76      0.78        82\n",
            "weighted avg       0.81      0.80      0.80        82\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7tAc2-UmQsn"
      },
      "source": [
        "## Interpretation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdOBPcftt5mA"
      },
      "source": [
        "### Errors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fs9yc9euTg8s",
        "outputId": "d3232c9a-5d61-46a5-bb87-e27fd6593198"
      },
      "source": [
        "for i, r in enumerate(ru_test_records):\n",
        "    mapping = {\n",
        "        0: \"not_cause\",\n",
        "        1: \"left_right\",\n",
        "        2: \"right_left\"\n",
        "    }\n",
        "    if ru_y_true[i] != ru_y_pred[i]:\n",
        "        print(\"LEFT:\", r[\"left_title\"])\n",
        "        print(\"RIGHT:\", r[\"right_title\"])\n",
        "        print(\"LABELS: true:{}, pred:{}\".format(mapping[ru_y_true[i]], mapping[ru_y_pred[i]]))\n",
        "        print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LEFT: В Бурятии не подтвердился случай повторного заболевания коронавирусом\n",
            "RIGHT: Жительница Бурятии, возможно, повторно заболела коронавирусом\n",
            "LABELS: true:right_left, pred:not_cause\n",
            "\n",
            "LEFT: Жительница Бурятии, возможно, повторно заболела коронавирусом\n",
            "RIGHT: В Бурятии не подтвердился случай повторного заболевания коронавирусом\n",
            "LABELS: true:left_right, pred:not_cause\n",
            "\n",
            "LEFT: Уфимцы могут помочь с поисками пропавшего мужчины\n",
            "RIGHT: В Уфе нашли живым 35-летнего Станислава Суркова\n",
            "LABELS: true:left_right, pred:right_left\n",
            "\n",
            "LEFT: Портников: Зеленский должен объяснить, почему снял санкции с внучки Муссолини, поддерживающей оккупацию Донбасса\n",
            "RIGHT: Зеленский снял санкции с наблюдателей на «выборах ЛДНР». Среди них внучка диктатора Муссолини\n",
            "LABELS: true:right_left, pred:not_cause\n",
            "\n",
            "LEFT: Главврач больницы в Гудермесе сменился после протеста врачей\n",
            "RIGHT: Даудов оправдал протест сотрудников Гудермесской больницы ошибками главврача\n",
            "LABELS: true:not_cause, pred:left_right\n",
            "\n",
            "LEFT: Украинские полярники 24-й антарктической экспедиции вернутся домой на следующей неделе\n",
            "RIGHT: В Украину вернулись участники 24-й антарктической экспедиции\n",
            "LABELS: true:left_right, pred:not_cause\n",
            "\n",
            "LEFT: \"Полиция убедила разойтись мигрантов, собравшихся около рынка \"\"Фуд Сити\"\"\"\n",
            "RIGHT: \"Торговцы устроили акцию протеста у московского рынка \"\"Фуд Сити\"\" на Калужском шоссе\"\n",
            "LABELS: true:right_left, pred:not_cause\n",
            "\n",
            "LEFT: Проверку по факту нападения собаки на ребенка проводят в Ставрополе\n",
            "RIGHT: Змея напала на девятилетнего мальчика в Свердловской области\n",
            "LABELS: true:not_cause, pred:right_left\n",
            "\n",
            "LEFT: В ресторане Киева задержали рэкетиров, вымогавших $20 тысяч\n",
            "RIGHT: Нацполиция провела задержание рэкетиров в ресторане Киева\n",
            "LABELS: true:not_cause, pred:left_right\n",
            "\n",
            "LEFT: Владимир Путин дал поручения по ситуации с коронавирусом\n",
            "RIGHT: Новые поручения Владимир Путина и свежие данные по заболеваемости коронавирусом: главное к этому часу\n",
            "LABELS: true:not_cause, pred:left_right\n",
            "\n",
            "LEFT: США предлагают разместить ядерное оружие на границах Украины\n",
            "RIGHT: США допустили возможность размещения на границах Украины ядерного оружия\n",
            "LABELS: true:not_cause, pred:left_right\n",
            "\n",
            "LEFT: Умерли двое заболевших коронавирусом в Хабаровском крае\n",
            "RIGHT: Дети и подростки заболели коронавирусом в Хабаровском крае\n",
            "LABELS: true:not_cause, pred:right_left\n",
            "\n",
            "LEFT: Конфликт между охранниками больницы Святой Марии Магдалины потянул на уголовное дело\n",
            "RIGHT: Охранник больницы Святой Марии Магдалины ударил ножом коллегу\n",
            "LABELS: true:right_left, pred:not_cause\n",
            "\n",
            "LEFT: Зеленский поставил Саакашвили две задачи\n",
            "RIGHT: Саакашвили назвал задачи от Зеленского\n",
            "LABELS: true:not_cause, pred:left_right\n",
            "\n",
            "LEFT: Россия отреагировала на обвинения Европы в распространении «теорий заговоров»\n",
            "RIGHT: Россия обвинила Европу в ведении информационной войны\n",
            "LABELS: true:not_cause, pred:right_left\n",
            "\n",
            "LEFT: На Филевской линии метро восстановили движение поездов\n",
            "RIGHT: Упавшее дерево перервало движение на Филевской линии столичного метро\n",
            "LABELS: true:right_left, pred:not_cause\n",
            "\n",
            "LEFT: США запустили в космос секретный военный космоплан\n",
            "RIGHT: Ракета с секретным американским космопланом стартовала с мыса Канаверал\n",
            "LABELS: true:not_cause, pred:left_right\n",
            "\n",
            "LEFT: Премьер Бельгии проехала в больницу по «коридору позора», организованному врачами\n",
            "RIGHT: \"Бельгийские медики организовали \"\"коридор позора\"\" для премьера, приехавшей в больницу\"\n",
            "LABELS: true:not_cause, pred:left_right\n",
            "\n",
            "LEFT: На главного вора в законе Белоруссии завели дело за нападение на бойца спецназа\n",
            "RIGHT: Главный белорусский вор в законе отбивался от спецназа ножом при задержании\n",
            "LABELS: true:right_left, pred:not_cause\n",
            "\n",
            "LEFT: Дефицит цветов в России опровергли\n",
            "RIGHT: России предсказали подорожание цветов из-за Белоруссии\n",
            "LABELS: true:right_left, pred:not_cause\n",
            "\n",
            "LEFT: Вяльбе пожаловалась на несправедливость FIS к России по сравнению с Норвегией\n",
            "RIGHT: WADA отреагировало на слова Вяльбе о лазейке норвежцев для побед\n",
            "LABELS: true:left_right, pred:not_cause\n",
            "\n",
            "LEFT: Жириновский назвал свой вес после предложения увольнять чиновников с ожирением\n",
            "RIGHT: Жириновский объяснил предложение ограничить вес чиновников\n",
            "LABELS: true:not_cause, pred:left_right\n",
            "\n",
            "LEFT: Jeep задумался о смене названия из-за индейцев\n",
            "RIGHT: Индейцы чероки попросили Jeep отказаться от названия их племени\n",
            "LABELS: true:right_left, pred:not_cause\n",
            "\n",
            "LEFT: Туктамышева снялась для Maxim в прозрачном нижнем белье\n",
            "RIGHT: Туктамышева рассказала о страхе из-за съемок для Maxim\n",
            "LABELS: true:left_right, pred:not_cause\n",
            "\n",
            "LEFT: Отказ Ирана от встречи по ядерной сделке разочаровал Белый дом\n",
            "RIGHT: WSJ узнал об отказе Ирана от прямых переговоров с ЕС и США по ядерной сделке\n",
            "LABELS: true:right_left, pred:not_cause\n",
            "\n",
            "LEFT: Появились подробности разрыва первой женатой пары трансгендеров в России\n",
            "RIGHT: Первая в России женатая пара трансгендеров снова сошлась после разрыва\n",
            "LABELS: true:left_right, pred:right_left\n",
            "\n",
            "LEFT: В Кремле отреагировали на увеличение числа финансово пострадавших россиян\n",
            "RIGHT: Доля пострадавших от кризиса россиян оказалась больше среднемировой\n",
            "LABELS: true:right_left, pred:not_cause\n",
            "\n",
            "LEFT: Раскрыты подробности расправы российского школьника над своей семьей\n",
            "RIGHT: Подозреваемый в жестоком убийстве российской семьи подросток задержан\n",
            "LABELS: true:right_left, pred:not_cause\n",
            "\n",
            "LEFT: Власти пообещали сохранить россиянам домашний интернет\n",
            "RIGHT: У части россиян отключат домашний интернет\n",
            "LABELS: true:right_left, pred:not_cause\n",
            "\n",
            "LEFT: Россиянам отказались отключать домашний интернет\n",
            "RIGHT: Глава Минцифры опроверг отключение домашнего интернета россиянам\n",
            "LABELS: true:not_cause, pred:left_right\n",
            "\n",
            "LEFT: Литва снова отказалась выдать Тихановскую Белоруссии\n",
            "RIGHT: Белоруссия попросила Литву выдать Тихановскую\n",
            "LABELS: true:right_left, pred:not_cause\n",
            "\n",
            "LEFT: Пожар на Оби сняли на видео\n",
            "RIGHT: В результате взрыва на реке Оби пострадал человек\n",
            "LABELS: true:not_cause, pred:right_left\n",
            "\n",
            "LEFT: Партия Меркель показала худший результат на региональных выборах\n",
            "RIGHT: Обнародованы предварительные результаты выборов в Германии\n",
            "LABELS: true:right_left, pred:not_cause\n",
            "\n",
            "LEFT: Российский добытчик золота опять отложил выход на биржу\n",
            "RIGHT: Российский добытчик золота выйдет на биржу\n",
            "LABELS: true:right_left, pred:not_cause\n",
            "\n",
            "LEFT: Уволившее скандального ведущего телешоу потеряло почти половину зрителей\n",
            "RIGHT: Увольнение скандального ведущего обрушило рейтинги телешоу\n",
            "LABELS: true:not_cause, pred:right_left\n",
            "\n",
            "LEFT: Назван «самый опасный период» для рубля\n",
            "RIGHT: В России оценили «опасный для рубля период»\n",
            "LABELS: true:left_right, pred:not_cause\n",
            "\n",
            "LEFT: Число погибших от взрыва в жилом доме в Подмосковье увеличилось до трех\n",
            "RIGHT: После взрыва в жилом доме в Подмосковье возбудили уголовное дело\n",
            "LABELS: true:not_cause, pred:right_left\n",
            "\n",
            "LEFT: Российский баскетболист-чемпион разозлил таксиста и проехал на капоте его машины\n",
            "RIGHT: Российский баскетболист-чемпион раскрыл подробности ДТП\n",
            "LABELS: true:left_right, pred:not_cause\n",
            "\n",
            "LEFT: После гибели ребенка под лавиной в Мурманской области возбудили уголовное дело\n",
            "RIGHT: Объявленная погибшей под лавиной в Мурманской области девочка оказалась жива\n",
            "LABELS: true:left_right, pred:right_left\n",
            "\n",
            "LEFT: Ургант вернулся на ТВ и рассказал о последствиях коронавируса\n",
            "RIGHT: Первый канал изменит формат вечернего шоу из-за болезни Урганта\n",
            "LABELS: true:right_left, pred:not_cause\n",
            "\n",
            "LEFT: Объявленная погибшей под лавиной в Мурманской области девочка оказалась жива\n",
            "RIGHT: Раскрыто состояние выжившей после схода лавины в Мурманской области девочки\n",
            "LABELS: true:left_right, pred:not_cause\n",
            "\n",
            "LEFT: Цены на нефть взлетели после блокировки Суэцкого канала\n",
            "RIGHT: Нефть резко подешевела из-за освобождения Суэцкого канала\n",
            "LABELS: true:left_right, pred:not_cause\n",
            "\n",
            "LEFT: Китайский конкурент Apple приготовился собирать электромобили\n",
            "RIGHT: Xiaomi показала первый электромобиль\n",
            "LABELS: true:left_right, pred:not_cause\n",
            "\n",
            "LEFT: МВД решило изменить паспорта россиян\n",
            "RIGHT: Россиянам описали внешний вид новых электронных паспортов\n",
            "LABELS: true:left_right, pred:not_cause\n",
            "\n",
            "LEFT: В России сообщили о возможности отмены рейсов в ОАЭ из-за разногласий стран\n",
            "RIGHT: Стало известно о выдаче разрешений на полеты между Россией и ОАЭ\n",
            "LABELS: true:left_right, pred:not_cause\n",
            "\n",
            "LEFT: Украина отвергла переговоры Путина, Макрона и Меркель без Зеленского\n",
            "RIGHT: Зеленский захотел поговорить о Донбассе с Макроном и Меркель без Путина\n",
            "LABELS: true:not_cause, pred:right_left\n",
            "\n",
            "LEFT: У дома стрелка из Мытищ завязался бой\n",
            "RIGHT: Силовики задержали стрелка из Мытищ после штурма\n",
            "LABELS: true:left_right, pred:not_cause\n",
            "\n",
            "LEFT: Оперштаб опроверг данные о третьей волне коронавируса в России\n",
            "RIGHT: Песков прокомментировал сообщения о третьей волне коронавируса в России\n",
            "LABELS: true:not_cause, pred:left_right\n",
            "\n",
            "LEFT: На устроившего аварию блогера Эдварда Била завели уголовное дело\n",
            "RIGHT: В квартире устроившего аварию блогера Эдварда Била пройдут обыски\n",
            "LABELS: true:left_right, pred:not_cause\n",
            "\n",
            "LEFT: Суд запретил продажу «Обуви сатаны»\n",
            "RIGHT: Производитель кроссовок с человеческой кровью согласился отозвать их из продажи\n",
            "LABELS: true:left_right, pred:not_cause\n",
            "\n",
            "LEFT: Главный нефролог Петербурга признался в убийстве пропавшей жены\n",
            "RIGHT: Главный нефролог Петербурга оправдался за убийство своей супруги\n",
            "LABELS: true:left_right, pred:not_cause\n",
            "\n",
            "LEFT: Павел Дуров оказался самым богатым жителем Дубая\n",
            "RIGHT: Дурова убрали из списка арабских миллиардеров\n",
            "LABELS: true:left_right, pred:not_cause\n",
            "\n",
            "LEFT: Редакторам студенческого журнала DOXA избрали меру пресечения\n",
            "RIGHT: В Кремле прокомментировали обыски и задержания в студенческом журнале DOXA\n",
            "LABELS: true:not_cause, pred:left_right\n",
            "\n",
            "LEFT: Пожар в российском частном доме с погибшими детьми попал на видео\n",
            "RIGHT: Число погибших в пожаре в частном доме на Урале детей достигло пяти\n",
            "LABELS: true:not_cause, pred:right_left\n",
            "\n",
            "LEFT: Суд вынес приговор Тиме Белорусских\n",
            "RIGHT: Тима Белорусских признался в суде в употреблении наркотиков с 16 лет\n",
            "LABELS: true:right_left, pred:not_cause\n",
            "\n",
            "LEFT: Послу США объяснили в Кремле ответ России на американские санкции\n",
            "RIGHT: Россия посоветовала американскому послу поехать в США\n",
            "LABELS: true:not_cause, pred:right_left\n",
            "\n",
            "LEFT: На похоронах принца Филиппа прозвучала русская молитва\n",
            "RIGHT: Принца Филиппа временно похоронили в Виндзорском замке\n",
            "LABELS: true:not_cause, pred:right_left\n",
            "\n",
            "LEFT: Посол США в Москве отказался покидать Россию\n",
            "RIGHT: Посол США в России вернулся в Вашингтон\n",
            "LABELS: true:left_right, pred:not_cause\n",
            "\n",
            "LEFT: Чехия сократит число сотрудников российского посольства в Праге\n",
            "RIGHT: Россия пообещала ответить на меры Чехии\n",
            "LABELS: true:left_right, pred:not_cause\n",
            "\n",
            "LEFT: В Минтруде рассказали о возможности продления майских праздников\n",
            "RIGHT: В Госдуме оценили продление майских выходных фразой о «летающей в Куршавель элите»\n",
            "LABELS: true:left_right, pred:not_cause\n",
            "\n",
            "LEFT: В Госдуме отреагировали на сообщения о возможном запрете импорта пива из Чехии\n",
            "RIGHT: В России задумались об ограничении импорта пива из Чехии\n",
            "LABELS: true:right_left, pred:not_cause\n",
            "\n",
            "LEFT: Появились фото избитого актером Палем хоккеиста\n",
            "RIGHT: Александр Паль объяснил конфликт с избитым хоккеистом\n",
            "LABELS: true:not_cause, pred:left_right\n",
            "\n",
            "LEFT: Глава МИД Ирана в непубличной речи пожаловался на поведение России и военных\n",
            "RIGHT: Захарова прокомментировала утечку разговора главы МИД Ирана о ядерной сделке\n",
            "LABELS: true:not_cause, pred:left_right\n",
            "\n",
            "LEFT: МИД Ирана прокомментировал слова Зарифа о России и Сулеймани\n",
            "RIGHT: Глава МИД Ирана в непубличной речи пожаловался на поведение России и военных\n",
            "LABELS: true:not_cause, pred:right_left\n",
            "\n",
            "LEFT: Британия оставит военные корабли в Ла-Манше после угроз Франции\n",
            "RIGHT: Британия направит два корабля в Ла-Манш после угроз Франции\n",
            "LABELS: true:right_left, pred:not_cause\n",
            "\n",
            "LEFT: В секторе Газа погибли 20 человек после атаки со стороны Израиля\n",
            "RIGHT: Девять человек погибли в секторе Газа после атаки со стороны Израиля\n",
            "LABELS: true:right_left, pred:not_cause\n",
            "\n",
            "LEFT: Появилось видео эвакуации детей после стрельбы в российской школе\n",
            "RIGHT: В результате стрельбы в школе Казани погибли девять человек\n",
            "LABELS: true:not_cause, pred:right_left\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebfXmPjot8D9"
      },
      "source": [
        "### BertViz"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQvd2FTSbFAt"
      },
      "source": [
        "# from bertviz import head_view\n",
        "# with torch.no_grad():\n",
        "#     for r in ru_test_records:\n",
        "#         if r[\"label\"] == 2:\n",
        "#             inputs = tokenizer.encode_plus(r[\"left_title\"], r[\"right_title\"], return_tensors='pt', add_special_tokens=True)\n",
        "#             input_ids = inputs[\"input_ids\"].cuda()\n",
        "#             outputs = model(input_ids, return_dict=True, output_attentions=True)\n",
        "#             attention = outputs.attentions\n",
        "#             tokens = tokenizer.convert_ids_to_tokens(input_ids[0].tolist())\n",
        "#             head_view(attention, tokens)\n",
        "#             break"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dyRwJlZt-zC"
      },
      "source": [
        "### Checklist"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m71CnxaEyN1k",
        "outputId": "1ce13b7e-3451-4ec0-ea31-a8dd13ed6f16"
      },
      "source": [
        "%%writefile ru_lexicons.json\n",
        "{\n",
        "    \"lexicons\": {\n",
        "        \"famous_male_last_name\": [\"Путин\", \"Песков\", \"Меладзе\", \"Мясников\", \"Макрон\", \"Порошенко\", \"Зеленский\", \"Медведев\", \"Алибасов\", \"Трамп\", \"Байден\"],\n",
        "        \"location_city\": [\"в Москве\", \"в Самаре\", \"в Париже\", \"в Дзержинске\", \"во Владимире\", \"в Стамбуле\", \"в Санкт-Петербурге\", \"в Сочи\", \"в Чикаго\", \"в Косово\", \"в Токио\"],\n",
        "        \"location_country\": [\"в России\", \"во Франции\", \"в США\", \"в Казахстане\", \"в Японии\", \"в Германии\", \"в Китае\", \"в Украине\", \"в Великобритании\", \"в Испании\", \"в РФ\"],\n",
        "        \"past_male_tell_verb\": [\"сообщил\", \"рассказал\", \"заявил\"],\n",
        "        \"future_male_tell_verb\": [\"сообщит\", \"расскажет\", \"заявит\"],\n",
        "        \"present_male_refute_verb\": [\"опроверг\", \"отрицает\"],\n",
        "        \"local_bad_event_gent\": [\"пожара\", \"взрыва\", \"ДТП\", \"аварии\", \"задержания террористов\"],\n",
        "        \"local_bad_event_loct\": [\"пожаре\", \"взрыве\", \"ДТП\", \"аварии\", \"задержании террористов\"],\n",
        "        \"global_bad_event_loct\": [\"вводе военного положения\", \"подорожании продуктов\"],\n",
        "        \"bad_event_loct\": [\"пожаре\", \"взрыве\", \"ДТП\", \"аварии\", \"задержании террористов\", \"вводе военного положения\", \"подорожании продуктов\"],\n",
        "        \"bad_reason\": [\"из-за коронавируса\", \"из-за гриппа\", \"из-за погоды\", \"из-за проблем\", \"из-за войны\", \"из-за жары\", \"из-за болезни\", \"из-за Путина\", \"из-за Китая\"],\n",
        "        \"regulation\": [\"карантин\", \"комендантский час\", \"запрет\"],\n",
        "        \"regulation_loct\": [\"карантине\", \"комендантском часе\", \"запрете\"],\n",
        "        \"date_future_duration\": [\"до 2023 года\", \"до 1 марта 2026 года\", \"до 31 декабря\"],\n",
        "        \"date_future_year\": [\"в 2021 году\", \"в следующем году\"],\n",
        "        \"date_future\": [\"до 2023 года\", \"до 1 марта 2026 года\", \"до 31 декабря\", \"в 2021 году\", \"в следующем году\"]\n",
        "    }\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing ru_lexicons.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jG1drXjybjt"
      },
      "source": [
        "from checklist.editor import Editor\n",
        "from checklist.test_types import MFT, INV, DIR\n",
        "from checklist.test_suite import TestSuite\n",
        "from checklist.perturb import Perturb\n",
        "from checklist.expect import Expect\n",
        "\n",
        "def pair_capitalize(template):\n",
        "    new_data = []\n",
        "    for left, right in template.data:\n",
        "        new_data.append((left[0].upper() + left[1:], right[0].upper() + right[1:]))\n",
        "    template.data = new_data\n",
        "    return template\n",
        "\n",
        "editor = Editor(language=\"russian\", model_name=\"xlm-roberta-large\")\n",
        "with open(\"ru_lexicons.json\", \"r\") as r:\n",
        "    lexicons = json.load(r)[\"lexicons\"]\n",
        "for key, words in lexicons.items():\n",
        "    editor.add_lexicon(key, words)\n",
        "    editor.add_lexicon(key + \"_capitalize\", [s[0].upper() + s[1:] for s in words])\n",
        "suite = TestSuite()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYb1CQhWtUih"
      },
      "source": [
        "#### Robustness"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfBhg8rlDtJc"
      },
      "source": [
        "suite.add(MFT(\n",
        "    **pair_capitalize(editor.template(\n",
        "        (\n",
        "            \"{location_city} {future_introduce} {regulation}\",\n",
        "            \"{expert}: {location_city} {future_introduce} {regulation}\"\n",
        "        ),\n",
        "        expert=(\"эксперт\", \"власти\", \"кремль\"),\n",
        "        future_introduce=(\"введут\", \"установят\"),\n",
        "        remove_duplicates=True,\n",
        "        nsamples=200,\n",
        "    )), labels=0,\n",
        "    name=\"Robustness to 'expert' and 'governement' additions\",\n",
        "    capability=\"Robustness\",\n",
        "    description=\"'Expert:' or 'Government:' in the beginning should not change model outputs\"\n",
        "))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ww7Al8jQtRKY"
      },
      "source": [
        "#### Temporal understanding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mgei5_s9FBrg"
      },
      "source": [
        "suite.add(MFT(\n",
        "    **pair_capitalize(editor.template(\n",
        "        (\n",
        "            \"В работе операторов начались сбои {bad_reason}\",\n",
        "            \"{famous_male_last_name} опроверг данные о сбоях в работе операторов {bad_reason}\"\n",
        "        ),\n",
        "        remove_duplicates=True,\n",
        "        nsamples=200,\n",
        "    )), labels=1,\n",
        "    name=\"Explicit refutations: person names and bad reasons\",\n",
        "    capability=\"Temporal understanding\",\n",
        "    description=\"The cause should not be changed by different persons or reasons\"\n",
        "))\n",
        "\n",
        "suite.add(MFT(\n",
        "    **pair_capitalize(editor.template(\n",
        "        (\n",
        "            \"В результате стрельбы {location_city} никто не пострадал\",\n",
        "            \"Неизвестные устроили стрельбу {location_city}\"\n",
        "        ),\n",
        "        remove_duplicates=True,\n",
        "        nsamples=200,\n",
        "    )), labels=2,\n",
        "    name=\"Implicit refutations: locations\",\n",
        "    capability=\"Temporal understanding\",\n",
        "    description=\"The cause should not be changed by different locations\"\n",
        "))\n",
        "\n",
        "suite.add(MFT(\n",
        "    **pair_capitalize(editor.template(\n",
        "        (\n",
        "            \"{famous_male_last_name1} {present_male_refute_verb} {news} о {bad_event_loct} {location_city}\",\n",
        "            \"{famous_male_last_name1} {past_male_tell_verb} о {bad_event_loct} {location_city}\"\n",
        "        ),\n",
        "        news=(\"информацию\", \"новость\", \"сообщение\"),\n",
        "        remove_duplicates=True,\n",
        "        nsamples=200,\n",
        "    )), labels=2,\n",
        "    name=\"Explicit refutations: same person\",\n",
        "    capability=\"Temporal understanding\",\n",
        "    description=\"The same person event refutation\"\n",
        "))\n",
        "\n",
        "suite.add(MFT(\n",
        "    **pair_capitalize(editor.template(\n",
        "        (\n",
        "            \"{location_city} {past_introduce} {regulation}\",\n",
        "            \"{regulation} {location_city} перестал действовать\"\n",
        "        ),\n",
        "        past_introduce=(\"ввели\", \"установили\"),\n",
        "        remove_duplicates=True,\n",
        "        nsamples=200,\n",
        "    )), labels=1,\n",
        "    name=\"Explicit refutations: impersonal past verb\",\n",
        "    capability=\"Temporal understanding\",\n",
        "    description=\"Impersonal past verb refutation\"\n",
        "))\n",
        "\n",
        "suite.add(MFT(\n",
        "    **pair_capitalize(editor.template(\n",
        "        (\n",
        "            \"{location_city} {future_introduce} {regulation}\",\n",
        "            \"{regulation} {location_city} перестал действовать\"\n",
        "        ),\n",
        "        future_introduce=(\"введут\", \"установят\"),\n",
        "        remove_duplicates=True,\n",
        "        nsamples=200,\n",
        "    )), labels=1,\n",
        "    name=\"Explicit refutations: impersonal future verb\",\n",
        "    capability=\"Temporal understanding\",\n",
        "    description=\"Impersonal future verb refutation\"\n",
        "))\n",
        "\n",
        "suite.add(MFT(\n",
        "    **pair_capitalize(editor.template(\n",
        "        (\n",
        "            \"{location_city1} {past_introduce} {regulation}\",\n",
        "            \"{regulation} {location_city2} перестал действовать\"\n",
        "        ),\n",
        "        past_introduce=(\"ввели\", \"установили\"),\n",
        "        remove_duplicates=True,\n",
        "        nsamples=200,\n",
        "    )), labels=0,\n",
        "    name=\"Explicit refutations: different locations\",\n",
        "    capability=\"Temporal understanding\",\n",
        "    description=\"Bad refutation: different locations\"\n",
        "))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8t9vHULnyI1x"
      },
      "source": [
        "#### Logic"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69S7NbXuyqep"
      },
      "source": [
        "test_zeros = [(r[\"left_title\"], r[\"right_title\"]) for r in ru_test_records if r[\"prediction\"] == 0]\n",
        "test_directional = [(r[\"left_title\"], r[\"right_title\"]) for r in ru_test_records if r[\"prediction\"] in (1, 2)]\n",
        "\n",
        "def change_order(x, *args, **kwargs):\n",
        "    left, right = x\n",
        "    return (right, left)\n",
        "\n",
        "suite.add(INV(\n",
        "    **Perturb.perturb(test_zeros, change_order, keep_original=True),\n",
        "    name=\"Zero invariant to swap order\",\n",
        "    capability=\"Logic\",\n",
        "    description=\"\"\n",
        "))\n",
        "\n",
        "\n",
        "def changed_pred_nonzero(orig_pred, pred, orig_conf, conf, labels=None, meta=None):\n",
        "    return pred != orig_pred and pred != 0 and orig_pred != 0\n",
        "\n",
        "suite.add(DIR(\n",
        "    **Perturb.perturb(test_directional, change_order, keep_original=True),\n",
        "    name=\"Directional change invariant\",\n",
        "    capability=\"Logic\",\n",
        "    description=\"\",\n",
        "    expect=Expect.pairwise(changed_pred_nonzero)\n",
        "))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFmpQ0Q53Nye"
      },
      "source": [
        "#### Run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2NpqhAj8Z9F",
        "outputId": "be56ffed-fc20-46a3-889a-e9a61a14a84b"
      },
      "source": [
        "suite.run(pipe_predict, overwrite=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running Robustness to 'expert' and 'governement' additions\n",
            "Predicting 200 examples\n",
            "Running Explicit refutations: person names and bad reasons\n",
            "Predicting 200 examples\n",
            "Running Implicit refutations: locations\n",
            "Predicting 200 examples\n",
            "Running Explicit refutations: same person\n",
            "Predicting 200 examples\n",
            "Running Explicit refutations: impersonal past verb\n",
            "Predicting 200 examples\n",
            "Running Explicit refutations: impersonal future verb\n",
            "Predicting 200 examples\n",
            "Running Explicit refutations: different locations\n",
            "Predicting 180 examples\n",
            "Running Zero invariant to swap order\n",
            "Predicting 610 examples\n",
            "Running Directional change invariant\n",
            "Predicting 474 examples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8iAitpS9PMh",
        "outputId": "246983dd-db0a-453c-9159-0ffb53d8881d"
      },
      "source": [
        "suite.summary()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Robustness\n",
            "\n",
            "Robustness to 'expert' and 'governement' additions\n",
            "Test cases:      200\n",
            "Fails (rate):    0 (0.0%)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Logic\n",
            "\n",
            "Zero invariant to swap order\n",
            "Test cases:      305\n",
            "Fails (rate):    18 (5.9%)\n",
            "\n",
            "Example fails:\n",
            "1.0 0.0 0.0 ('Дефицит цветов в России опровергли', 'России предсказали подорожание цветов из-за Белоруссии')\n",
            "0.2 0.7 0.0 ('России предсказали подорожание цветов из-за Белоруссии', 'Дефицит цветов в России опровергли')\n",
            "\n",
            "----\n",
            "0.5 0.0 0.5 ('\"Полиция убедила разойтись мигрантов, собравшихся около рынка \"\"Фуд Сити\"\"\"', '\"Торговцы устроили акцию протеста у московского рынка \"\"Фуд Сити\"\" на Калужском шоссе\"')\n",
            "0.3 0.6 0.1 ('\"Торговцы устроили акцию протеста у московского рынка \"\"Фуд Сити\"\" на Калужском шоссе\"', '\"Полиция убедила разойтись мигрантов, собравшихся около рынка \"\"Фуд Сити\"\"\"')\n",
            "\n",
            "----\n",
            "0.8 0.0 0.2 ('Отказ Ирана от встречи по ядерной сделке разочаровал Белый дом', 'WSJ узнал об отказе Ирана от прямых переговоров с ЕС и США по ядерной сделке')\n",
            "0.1 0.9 0.0 ('WSJ узнал об отказе Ирана от прямых переговоров с ЕС и США по ядерной сделке', 'Отказ Ирана от встречи по ядерной сделке разочаровал Белый дом')\n",
            "\n",
            "----\n",
            "\n",
            "\n",
            "Directional change invariant\n",
            "Test cases:      237\n",
            "Fails (rate):    17 (7.2%)\n",
            "\n",
            "Example fails:\n",
            "0.3 0.0 0.7 ('Уволившее скандального ведущего телешоу потеряло почти половину зрителей', 'Увольнение скандального ведущего обрушило рейтинги телешоу')\n",
            "0.5 0.4 0.1 ('Увольнение скандального ведущего обрушило рейтинги телешоу', 'Уволившее скандального ведущего телешоу потеряло почти половину зрителей')\n",
            "\n",
            "----\n",
            "0.1 0.9 0.0 ('Возле метро в Нижнем Новгороде прогремел взрыв', 'После взрыва в Нижнем Новгороде загорелся жилой дом')\n",
            "0.9 0.0 0.1 ('После взрыва в Нижнем Новгороде загорелся жилой дом', 'Возле метро в Нижнем Новгороде прогремел взрыв')\n",
            "\n",
            "----\n",
            "0.3 0.6 0.0 ('Российский гимнаст выиграл золото чемпионата Европы', 'Выигравший ЧЕ российский гимнаст объяснил придуманный им элемент коронавирусом')\n",
            "1.0 0.0 0.0 ('Выигравший ЧЕ российский гимнаст объяснил придуманный им элемент коронавирусом', 'Российский гимнаст выиграл золото чемпионата Европы')\n",
            "\n",
            "----\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Temporal understanding\n",
            "\n",
            "Explicit refutations: person names and bad reasons\n",
            "Test cases:      200\n",
            "Fails (rate):    0 (0.0%)\n",
            "\n",
            "\n",
            "Implicit refutations: locations\n",
            "Test cases:      200\n",
            "Fails (rate):    0 (0.0%)\n",
            "\n",
            "\n",
            "Explicit refutations: same person\n",
            "Test cases:      200\n",
            "Fails (rate):    0 (0.0%)\n",
            "\n",
            "\n",
            "Explicit refutations: impersonal past verb\n",
            "Test cases:      200\n",
            "Fails (rate):    0 (0.0%)\n",
            "\n",
            "\n",
            "Explicit refutations: impersonal future verb\n",
            "Test cases:      200\n",
            "Fails (rate):    12 (6.0%)\n",
            "\n",
            "Example fails:\n",
            "0.5 0.4 0.1 ('В Сочи введут комендантский час', 'Комендантский час в Сочи перестал действовать')\n",
            "----\n",
            "0.6 0.3 0.1 ('В Санкт-Петербурге введут комендантский час', 'Комендантский час в Санкт-Петербурге перестал действовать')\n",
            "----\n",
            "0.5 0.4 0.1 ('В Сочи введут комендантский час', 'Комендантский час в Сочи перестал действовать')\n",
            "----\n",
            "\n",
            "\n",
            "Explicit refutations: different locations\n",
            "Test cases:      180\n",
            "Fails (rate):    2 (1.1%)\n",
            "\n",
            "Example fails:\n",
            "0.4 0.6 0.0 ('В Токио ввели карантин', 'Карантин в Чикаго перестал действовать')\n",
            "----\n",
            "0.5 0.5 0.0 ('В Париже установили карантин', 'Карантин в Токио перестал действовать')\n",
            "----\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zw3PppGXZXxA"
      },
      "source": [
        "# Saving"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wcb6sICCZXmB"
      },
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "OUT_DIR = \"ru_bert_cause\"\n",
        "if os.path.isdir(OUT_DIR):\n",
        "    shutil.rmtree(OUT_DIR) \n",
        "model.save_pretrained(OUT_DIR)\n",
        "train_data.tokenizer.save_pretrained(OUT_DIR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jW5glaDjZd-U"
      },
      "source": [
        "!cd ru_bert_cause && tar -czvf ru_bert_cause.tar.gz ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAyhVYo2g2WR"
      },
      "source": [
        "# Telegram pairs inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMq92WVPg6QC",
        "outputId": "bfb95971-2015-42b8-c413-0715cb0232bd"
      },
      "source": [
        "!wget https://www.dropbox.com/s/u1f8zjgyuwvh4rr/tg_pairs.jsonl.tar.gz\n",
        "!tar -xzvf tg_pairs.jsonl.tar.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-07-31 14:38:07--  https://www.dropbox.com/s/u1f8zjgyuwvh4rr/tg_pairs.jsonl.tar.gz\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.82.18, 2620:100:6032:18::a27d:5212\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.82.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/u1f8zjgyuwvh4rr/tg_pairs.jsonl.tar.gz [following]\n",
            "--2021-07-31 14:38:08--  https://www.dropbox.com/s/raw/u1f8zjgyuwvh4rr/tg_pairs.jsonl.tar.gz\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uca9926be17b5b6caeab18871b26.dl.dropboxusercontent.com/cd/0/inline/BTVRc4UBpZTDpuk-v9WeTTsb-qnmwz53q6UUug3BGcsBRfgebqo6qWT6tSnhg2_06jCnTM1Mfi_nggaEHS8gfDGBBn3ajasQ5uVQ3aHhZys1TTwR1fmjdIFzX4SCYcJT7EIWzrWQXGodiph5nGaOaG_N/file# [following]\n",
            "--2021-07-31 14:38:08--  https://uca9926be17b5b6caeab18871b26.dl.dropboxusercontent.com/cd/0/inline/BTVRc4UBpZTDpuk-v9WeTTsb-qnmwz53q6UUug3BGcsBRfgebqo6qWT6tSnhg2_06jCnTM1Mfi_nggaEHS8gfDGBBn3ajasQ5uVQ3aHhZys1TTwR1fmjdIFzX4SCYcJT7EIWzrWQXGodiph5nGaOaG_N/file\n",
            "Resolving uca9926be17b5b6caeab18871b26.dl.dropboxusercontent.com (uca9926be17b5b6caeab18871b26.dl.dropboxusercontent.com)... 162.125.82.15, 2620:100:6032:15::a27d:520f\n",
            "Connecting to uca9926be17b5b6caeab18871b26.dl.dropboxusercontent.com (uca9926be17b5b6caeab18871b26.dl.dropboxusercontent.com)|162.125.82.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/BTUbEz20LU9CpGiM_oUWMSCkZFR3VxS53pBYqrC1JL8G9VR3-_sEtFrhKagRPevG8K4L8fdqrCMvJnPB-DmNoXJHiof1rRXh2q8Jvuvdd26HseqFFOrL22Xmqk_gxbwat48fz35UWbwEdbjKWRmHSnL-6cIBA_D1KLYfPgdIbRNJ9ipOuvwaRBDtxCZ-bn3oHbzSlY5XyqmudKWa7Z52I-e1KmFpwoxmM_sVybfJldK5Upv3VHCK6aJVFd8MF7XXlL4DPFu8TZNxCjuAIjA4vKFSIhBATLYiK6Fuae30EKQu8d6j1TSoUEiaLOLouj4oKt0ZXgGkPED-Lpc1EiNe5vQZkiZyxPKOqz_WSjwUbK5sN9kDvgaDhAiJc9jFZBHiBcs/file [following]\n",
            "--2021-07-31 14:38:09--  https://uca9926be17b5b6caeab18871b26.dl.dropboxusercontent.com/cd/0/inline2/BTUbEz20LU9CpGiM_oUWMSCkZFR3VxS53pBYqrC1JL8G9VR3-_sEtFrhKagRPevG8K4L8fdqrCMvJnPB-DmNoXJHiof1rRXh2q8Jvuvdd26HseqFFOrL22Xmqk_gxbwat48fz35UWbwEdbjKWRmHSnL-6cIBA_D1KLYfPgdIbRNJ9ipOuvwaRBDtxCZ-bn3oHbzSlY5XyqmudKWa7Z52I-e1KmFpwoxmM_sVybfJldK5Upv3VHCK6aJVFd8MF7XXlL4DPFu8TZNxCjuAIjA4vKFSIhBATLYiK6Fuae30EKQu8d6j1TSoUEiaLOLouj4oKt0ZXgGkPED-Lpc1EiNe5vQZkiZyxPKOqz_WSjwUbK5sN9kDvgaDhAiJc9jFZBHiBcs/file\n",
            "Reusing existing connection to uca9926be17b5b6caeab18871b26.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 15592447 (15M) [application/octet-stream]\n",
            "Saving to: ‘tg_pairs.jsonl.tar.gz’\n",
            "\n",
            "tg_pairs.jsonl.tar. 100%[===================>]  14.87M  11.1MB/s    in 1.3s    \n",
            "\n",
            "2021-07-31 14:38:10 (11.1 MB/s) - ‘tg_pairs.jsonl.tar.gz’ saved [15592447/15592447]\n",
            "\n",
            "tg_pairs.jsonl\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECI1spgihGpX",
        "outputId": "efb7506d-cd3c-4c00-f6f6-44423f4e6b41"
      },
      "source": [
        "!head -n 1 tg_pairs.jsonl"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\"from_language\": \"en\", \"to_language\": \"en\", \"from_timestamp\": 1587934800, \"to_timestamp\": 1587934800, \"from_title\": \"Government Calls for Return of Premier League as Soon as Possible to Boost National Spirit\", \"to_title\": \"Premier League 'Project Restart': When Could the 19/20 Season Restart & Finish?\", \"from_url\": \"https://www.90min.com/posts/government-calls-for-return-of-premier-league-as-soon-as-possible-to-boost-national-spirit-01e6yc3w8ptr\", \"to_url\": \"https://www.90min.com/posts/premier-league-project-restart-when-could-the-19-20-season-restart-finish-01e6xwh1gp8v\", \"distance\": 0.23587880211712153, \"id\": 2}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zByPi2XXg_Sb"
      },
      "source": [
        "tg_records = []\n",
        "with open(\"tg_pairs.jsonl\", \"r\") as r:\n",
        "    for line in r:\n",
        "        r = json.loads(line)\n",
        "        if not (r[\"from_language\"] == r[\"to_language\"] == \"ru\"):\n",
        "            continue\n",
        "        r[\"left_title\"] = r.pop(\"from_title\")\n",
        "        r[\"right_title\"] = r.pop(\"to_title\")\n",
        "        r[\"left_url\"] = r.pop(\"from_url\")\n",
        "        r[\"right_url\"] = r.pop(\"to_url\")\n",
        "        tg_records.append(r)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "85e64aedcbd44f7daba63e94a81c9e1f",
            "9d4417c0e3584042a686d4c848d94f49",
            "c2d8dd7540064898b8c142175786bf70",
            "f958cec91e904d5c9caf315b42a388ed",
            "317e3bf1475a4660936f1c8e0f8ad5da",
            "678b99192bf34feaa3591281cf4c9385",
            "7f1f5cb3c0d2463f8774b83bcf243822",
            "b95d69cae6404d46963c015e18ebbbf9"
          ]
        },
        "id": "CJMP95nwhmqx",
        "outputId": "810afe2e-220e-4649-c83b-48186e732382"
      },
      "source": [
        "from tqdm.notebook import tqdm\n",
        "from collections import Counter\n",
        "\n",
        "tg_pairs_data = NewsPairsDataset(tg_records, MAX_TOKENS, TOKENIZER_NAME, labels_count)\n",
        "\n",
        "tg_labels = []\n",
        "with torch.no_grad(): \n",
        "    for item in tqdm(tg_pairs_data):\n",
        "        for key, value in item.items():\n",
        "            item[key] = value.unsqueeze_(0).cuda()\n",
        "        outputs = model(**item, return_dict=True)\n",
        "        logits = outputs.logits.squeeze(0)\n",
        "        label = torch.argmax(logits).item()\n",
        "        prob = torch.sigmoid(logits[label]).item()\n",
        "        tg_labels.append((label, prob))\n",
        "\n",
        "labels_cntr = Counter()\n",
        "for (label, prob), r in zip(tg_labels, tg_records):\n",
        "    r[\"bert_label\"] = label\n",
        "    labels_cntr[label] += 1\n",
        "    r[\"bert_confidence\"] = prob"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading configuration file https://huggingface.co/DeepPavlov/rubert-base-cased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/a43261a78bd9edbbf43584c6b00aa94c032301840e532839cb5989362562a5d5.e8f15c5aad2f4653e46ceeba0bb32c02a629d106a902c964bce60523d290ac8f\n",
            "Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertModel\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"directionality\": \"bidi\",\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_fc_size\": 768,\n",
            "  \"pooler_num_attention_heads\": 12,\n",
            "  \"pooler_num_fc_layers\": 3,\n",
            "  \"pooler_size_per_head\": 128,\n",
            "  \"pooler_type\": \"first_token_transform\",\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.9.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 119547\n",
            "}\n",
            "\n",
            "loading file https://huggingface.co/DeepPavlov/rubert-base-cased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/5dd198988cb85bc18d17f196ffae19788abc4fcff7fbe7f8ef02e1322c5ac3cc.018f85b6550237c27386c0ec90a1ff7bdcf74e56a9e2d32131e29c4689192eaa\n",
            "loading file https://huggingface.co/DeepPavlov/rubert-base-cased/resolve/main/tokenizer.json from cache at None\n",
            "loading file https://huggingface.co/DeepPavlov/rubert-base-cased/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/DeepPavlov/rubert-base-cased/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/853440ef3f696efb168918bd6c8489323dfaad3a7b308974fa2669336a00d203.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n",
            "loading file https://huggingface.co/DeepPavlov/rubert-base-cased/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/d9e31304a406bb10bd448caf19da6f894350a8bf96f740aa84e6d291229de7b0.5cc6e825eb228a7a5cfd27cb4d7151e97a79fb962b31aaf1813aa102e746584b\n",
            "loading configuration file https://huggingface.co/DeepPavlov/rubert-base-cased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/a43261a78bd9edbbf43584c6b00aa94c032301840e532839cb5989362562a5d5.e8f15c5aad2f4653e46ceeba0bb32c02a629d106a902c964bce60523d290ac8f\n",
            "Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertModel\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"directionality\": \"bidi\",\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_fc_size\": 768,\n",
            "  \"pooler_num_attention_heads\": 12,\n",
            "  \"pooler_num_fc_layers\": 3,\n",
            "  \"pooler_size_per_head\": 128,\n",
            "  \"pooler_type\": \"first_token_transform\",\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.9.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 119547\n",
            "}\n",
            "\n",
            "loading configuration file https://huggingface.co/DeepPavlov/rubert-base-cased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/a43261a78bd9edbbf43584c6b00aa94c032301840e532839cb5989362562a5d5.e8f15c5aad2f4653e46ceeba0bb32c02a629d106a902c964bce60523d290ac8f\n",
            "Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertModel\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"directionality\": \"bidi\",\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_fc_size\": 768,\n",
            "  \"pooler_num_attention_heads\": 12,\n",
            "  \"pooler_num_fc_layers\": 3,\n",
            "  \"pooler_size_per_head\": 128,\n",
            "  \"pooler_type\": \"first_token_transform\",\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.9.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 119547\n",
            "}\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "85e64aedcbd44f7daba63e94a81c9e1f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=55535.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3-RNpukY7Ki",
        "outputId": "d2807712-b5d5-4c54-c1e1-d192bd3bf885"
      },
      "source": [
        "print(labels_cntr.most_common())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0, 51149), (2, 3505), (1, 881)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MmJkPodiCZ8"
      },
      "source": [
        "with open(\"ru_tg_pairs_with_bert.jsonl\", \"w\") as w:\n",
        "    for r in tg_records:\n",
        "        w.write(json.dumps(r, ensure_ascii=False).strip() + \"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfBpCvNbiMNc",
        "outputId": "20f9f9d5-3030-4e1b-da94-c5304dbda6be"
      },
      "source": [
        "!rm -rf ru_tg_pairs_with_bert.jsonl.tar.gz\n",
        "!tar -czvf ru_tg_pairs_with_bert.jsonl.tar.gz ru_tg_pairs_with_bert.jsonl"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ru_tg_pairs_with_bert.jsonl\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmLdeVSDVuQ6"
      },
      "source": [
        "# Single-sentence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOzEiGXBXTMn"
      },
      "source": [
        "singles = []\n",
        "for r in records:\n",
        "    label = r[\"label\"]\n",
        "    if result == 'left_right_cause':\n",
        "        singles.append({'id':r['id']+'_l', 'title':r['left_title'], 'timestamp':r['left_timestamp'], 'label':0 })\n",
        "        singles.append({'id':r['id']+'_r', 'title':r['right_title'], 'timestamp':r['right_timestamp'], 'label':1 })\n",
        "    elif result == 'right_left_cause':\n",
        "        singles.append({'id':r['id']+'_l', 'title':r['left_title'], 'timestamp':r['left_timestamp'], 'label':1 })\n",
        "        singles.append({'id':r['id']+'_r', 'title':r['right_title'], 'timestamp':r['right_timestamp'], 'label':0 })\n",
        "print(len(singles))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4tj2gutVyOY"
      },
      "source": [
        "import json\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "class NewsSinglesDataset(Dataset):\n",
        "    def __init__(self, records, max_tokens, model_name, labels_count):\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(\n",
        "            model_name,\n",
        "            do_lower_case=False\n",
        "        )\n",
        "        self.max_tokens = max_tokens\n",
        "        self.records = records\n",
        "        self.labels_count = labels_count\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.records)\n",
        "    \n",
        "    def embed_record(self, record):\n",
        "        inputs = self.tokenizer(\n",
        "            text=record[\"title\"],\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_tokens,\n",
        "            padding=\"max_length\",\n",
        "            truncation=\"longest_first\",\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        for key, value in inputs.items():\n",
        "            value.squeeze_(0)\n",
        "        return inputs\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        record = self.records[index]\n",
        "        output = self.embed_record(record)\n",
        "        label = record.get(\"label\", None)\n",
        "        if label is not None:\n",
        "            output[\"labels\"] = torch.tensor(label)\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}