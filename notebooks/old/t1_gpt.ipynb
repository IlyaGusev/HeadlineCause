{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XaUfkeh4woWU"
   },
   "source": [
    "# Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Cmvj-Jh4QgQN",
    "outputId": "b7a875f1-e400-44d7-c53f-d9b072b35027"
   },
   "outputs": [],
   "source": [
    "# !pip install --upgrade transformers bertviz checklist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wmmy8-VA3__6"
   },
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pm5jSAP0No_j",
    "outputId": "4e52957d-d6d0-4581-ae7a-43149e854fc8"
   },
   "outputs": [],
   "source": [
    "# !rm -rf ru_news_cause_v1.tsv*\n",
    "# !wget https://www.dropbox.com/s/kcxnhjzfut4guut/ru_news_cause_v1.tsv.tar.gz\n",
    "# !tar -xzvf ru_news_cause_v1.tsv.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bV6i0sRfN3NH",
    "outputId": "e8444783-9e40-4a3a-daf5-eda3c958131d"
   },
   "outputs": [],
   "source": [
    "# !cat ru_news_cause_v1.tsv | wc -l\n",
    "# !head ru_news_cause_v1.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oEhRCkSOwsGj"
   },
   "source": [
    "# GPT-gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-08 18:50:40.629383: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "/media/altsoph/Volume/_py37/lib/python3.7/site-packages/transformers/models/auto/modeling_auto.py:847: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  FutureWarning,\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelWithLMHead, AutoTokenizer\n",
    "device = 'cuda'\n",
    "model_id = 'sberbank-ai/rugpt3small_based_on_gpt2' \n",
    "cache_dir = '/media/altsoph/Volume/_transformers_cache/'\n",
    " \n",
    "model = AutoModelWithLMHead.from_pretrained(model_id, cache_dir=cache_dir).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, cache_dir=cache_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "records = []\n",
    "with open(\"ru_news_cause_v1.tsv\", \"r\", encoding='utf-8') as r:\n",
    "    reader = csv.reader(r, delimiter=\"\\t\")\n",
    "    header = next(reader)\n",
    "    for row in reader:\n",
    "        r = dict(zip(header, row))\n",
    "        if float(r[\"confidence\"]) < 0.69:\n",
    "            continue\n",
    "        result = r[\"result\"]\n",
    "        mapping = {\n",
    "            \"left_right_cause\": 0,\n",
    "            \"left_right_cancel\": 1,\n",
    "            \"right_left_cause\": 0,\n",
    "            \"right_left_cancel\": 1\n",
    "        }\n",
    "        if result not in mapping:\n",
    "            continue\n",
    "        if result.startswith('right'):\n",
    "            r['left_title'], r['right_title'] = r['right_title'], r['left_title']\n",
    "        r[\"label\"] = mapping[result]\n",
    "        records.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to set a padding token\n",
    "tokenizer.vocab['<|endoftext|>']\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class LineByLineTextDataset(Dataset):\n",
    "    def __init__(self, records, max_tokens, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_tokens = max_tokens\n",
    "        self.records = records\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.records)\n",
    "\n",
    "    def embed_record(self, record):\n",
    "        inputs = self.tokenizer(\n",
    "            text=record[\"left_title\"]+'. '+record[\"right_title\"]+'. <|endoftext|>',\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_tokens,\n",
    "            truncation=\"longest_first\",\n",
    "            padding=\"max_length\",\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        for key, value in inputs.items():\n",
    "            value.squeeze_(0)\n",
    "        return inputs\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        record = self.records[index]\n",
    "        output = self.embed_record(record)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1174\n",
      "147\n",
      "148\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "records_by_source = defaultdict(list)\n",
    "for r in records:\n",
    "    source = r[\"id\"].split(\"_\")[0]\n",
    "    records_by_source[source].append(r)\n",
    "\n",
    "train_records, val_records, test_records = [], [], []\n",
    "for _, source_records in records_by_source.items():\n",
    "    source_records.sort(key=lambda x: min(x[\"left_timestamp\"], x[\"right_timestamp\"]))\n",
    "    val_border = int(0.8 * len(source_records))\n",
    "    test_border = int(0.9 * len(source_records))\n",
    "    train_records.extend(source_records[:val_border])\n",
    "    val_records.extend(source_records[val_border:test_border])\n",
    "    test_records.extend(source_records[test_border:])\n",
    "\n",
    "print(len(train_records))\n",
    "print(len(val_records))\n",
    "print(len(test_records))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler\n",
    "\n",
    "MAX_TOKENS = 80\n",
    "\n",
    "train_data = LineByLineTextDataset(train_records, MAX_TOKENS, tokenizer)\n",
    "val_data = LineByLineTextDataset(val_records, MAX_TOKENS, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([ 4408,  1865,   701, 48450,   783,   281, 29075, 30025, 29111,   354,\n",
      "        20886, 46404, 21291,  9621,  2198, 38639, 46792,    18, 38466, 20886,\n",
      "         4929, 35447,   334,  5083, 48450,   553,    16,   282,  1754, 13731,\n",
      "        30025,   505, 21291,  9621,  2198, 38639, 46792,    18,   225, 50257,\n",
      "        50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
      "        50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
      "        50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
      "        50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])}\n"
     ]
    }
   ],
   "source": [
    "for item in train_data:\n",
    "    print(item)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 1174\n",
      "  Num Epochs = 6\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 8\n",
      "  Total optimization steps = 54\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 01:36, Epoch 5/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3.419600</td>\n",
       "      <td>2.831861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.819100</td>\n",
       "      <td>2.671859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2.567100</td>\n",
       "      <td>2.621898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2.434700</td>\n",
       "      <td>2.596229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.356700</td>\n",
       "      <td>2.593441</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 147\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./gpt2-gen1/checkpoint-10\n",
      "Configuration saved in ./gpt2-gen1/checkpoint-10/config.json\n",
      "Model weights saved in ./gpt2-gen1/checkpoint-10/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 147\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./gpt2-gen1/checkpoint-20\n",
      "Configuration saved in ./gpt2-gen1/checkpoint-20/config.json\n",
      "Model weights saved in ./gpt2-gen1/checkpoint-20/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 147\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./gpt2-gen1/checkpoint-30\n",
      "Configuration saved in ./gpt2-gen1/checkpoint-30/config.json\n",
      "Model weights saved in ./gpt2-gen1/checkpoint-30/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 147\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./gpt2-gen1/checkpoint-40\n",
      "Configuration saved in ./gpt2-gen1/checkpoint-40/config.json\n",
      "Model weights saved in ./gpt2-gen1/checkpoint-40/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 147\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./gpt2-gen1/checkpoint-50\n",
      "Configuration saved in ./gpt2-gen1/checkpoint-50/config.json\n",
      "Model weights saved in ./gpt2-gen1/checkpoint-50/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./gpt2-gen1/checkpoint-50 (score: 2.5934407711029053).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=54, training_loss=2.6876883153562194, metrics={'train_runtime': 97.7637, 'train_samples_per_second': 72.051, 'train_steps_per_second': 0.552, 'total_flos': 422100675624960.0, 'train_loss': 2.6876883153562194, 'epoch': 5.97})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments, DataCollatorForLanguageModeling \n",
    "\n",
    "EPOCHS = 6\n",
    "EVAL_STEPS = 10 #*8\n",
    "WARMUP_STEPS = 5 # *8\n",
    "LR = 3e-05\n",
    "BATCH_SIZE = 128//8 # \n",
    "GRAD_ACCUM_STEPS = 1*8\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./gpt2-gen1\", #The output directory\n",
    "    overwrite_output_dir=True, #overwrite the content of the output directory\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    logging_steps=EVAL_STEPS,\n",
    "    save_steps=EVAL_STEPS,\n",
    "    warmup_steps=WARMUP_STEPS,\n",
    "    learning_rate=LR,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    gradient_accumulation_steps=GRAD_ACCUM_STEPS,\n",
    "    report_to=\"none\",\n",
    "#     report_to=\"wandb\",  # enable logging to W&B\n",
    "#     run_name=\"newscausation_gptgen\",\n",
    "    prediction_loss_only=True,\n",
    "    load_best_model_at_end=True\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "        tokenizer=tokenizer, mlm=False,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,    \n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=val_data\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50264, 768)\n",
       "    (wpe): Embedding(2048, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50264, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118372\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(1337)\n",
    "\n",
    "new_titles = []\n",
    "with open(\"titles.txt\", \"r\", encoding='utf-8') as r:\n",
    "    for line in r:\n",
    "        new_titles.append( line.strip() )\n",
    "print(len(new_titles))\n",
    "\n",
    "np.random.shuffle(new_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сотрудники ФСБ поймали заработавшую на иностранцах 10 миллионов рублей ОПГ\n",
      "[{'generated_text': ' В России объяснили задержа'}]\n",
      "\n",
      "Бывшую жену Грачевского обвинили в ранней смерти режиссера\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': ' Грачевский отреагировал на обвинения в ранней смерти жены'}]\n",
      "\n",
      "В московском роддоме из пациенток «выдавливали» детей\n",
      "[{'generated_text': ' Родственники пациенток'}]\n",
      "\n",
      "Россиянам разъяснили новые правила оформления выплат на детей\n",
      "[{'generated_text': ' В Госдуме прокомментировали нововведение о выплатах'}]\n",
      "\n",
      "Россиянин похитил миллиард рублей и поплатился\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': ' Раскрыты подробности похищения россиянином миллиарда рублей'}]\n",
      "\n",
      "Смертоносная кобра спряталась в кресло и напугала севшего в него мужчину\n",
      "[{'generated_text': ' '}]\n",
      "\n",
      "Описано новое осложнение при коронавирусе\n",
      "[{'generated_text': ' Появились подробности о новом осложнении при корона'}]\n",
      "\n",
      "США пошли на экстренные меры из-за коронавируса\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': ' В России отреагировали на отмену'}]\n",
      "\n",
      "В российском центре по борьбе с алкоголизмом пациентов били и держали на цепи\n",
      "[{'generated_text': ' В российском центре по борьбе'}]\n",
      "\n",
      "Раскрыты правила проживания в одной квартире с зараженным коронавирусом\n",
      "[{'generated_text': ' В России объяснили правила проживания'}]\n",
      "\n",
      "Дизайнер снял в рекламе свою бабушку в пиджаке на голое тело\n",
      "[{'generated_text': ' Раскрыты подробности'}]\n",
      "\n",
      "Роспотребнадзор сообщил о «замедлении снижения» заболеваемости COVID-19 в России\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 22, but ``max_length`` is set to 20.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 20, but ``max_length`` is set to 20.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': ' '}]\n",
      "\n",
      "Глава белорусских католиков назвал изгнание из страны своим крестом\n",
      "[{'generated_text': ' В Беларуси отреагировали на изгнание из'}]\n",
      "\n",
      "Программа «Архитекторы.рф» запустила новый курс по урбанистике\n",
      "[{'generated_text': ' '}]\n",
      "\n",
      "«Ужасную» квартиру Ефремова оценили в 40 миллионов рублей\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': ' В Госдуме оценили квартиру Ефремова'}]\n",
      "\n",
      "Посол России подарил Лукашенко карту Белоруссии в Российской империи\n",
      "[{'generated_text': ' Лукашенко ответил на подарок Белоруссии в России. '}]\n",
      "\n",
      "Россиян задумали избавить от страховых платежей по ипотеке\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 21, but ``max_length`` is set to 20.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 20, but ``max_length`` is set to 20.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': ' В России оценили идею отказаться от выплат'}]\n",
      "\n",
      "ПСБ профинансирует социально значимые проекты Краснодарского края\n",
      "[{'generated_text': ' В Краснодарском крае оценили идею профи'}]\n",
      "\n",
      "Полицейские отобрали деньги у сына главреда Cosmopolitan со словами «Стой, сука»\n",
      "[{'generated_text': ' В'}]\n",
      "\n",
      "206-килограммовая женщина похудела на 138 килограммов и раскрыла секрет успеха\n",
      "[{'generated_text': ' Ра'}]\n",
      "\n",
      "Китайским строителям в России подыскали замену\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': ' В России оценили слова Трампа о «сверст'}]\n",
      "\n",
      "Путин раскрыл суть изменений в Конституции\n",
      "[{'generated_text': ' Путин объяснил слова о «перестройке» в Конституции. '}]\n",
      "\n",
      "Российская учительница исполнила эротический танец в клубе и уволилась из школы\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': ' В школе объяснили увольнение'}]\n",
      "\n",
      "Россиян предупредили о погодных аномалиях в течение недели\n",
      "[{'generated_text': ' В России объяснили опасения россиян о погодных аном'}]\n",
      "\n",
      "На поддержку рыбохозяйств в Подмосковье выделено 22 миллиона рублей\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': ' В Подмосковье оценили помощь рыбохозяй'}]\n",
      "\n",
      "В Раде спрогнозировали будущее Украины на фоне коронавируса\n",
      "[{'generated_text': ' Раскрыты подробности'}]\n",
      "\n",
      "Американцам предложат включить в рацион мясо питонов\n",
      "[{'generated_text': ' В России отреагировали на предложение включить в рацион'}]\n",
      "\n",
      "Подсчитан заработок торгующих на бирже россиян\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': ' В России оценили результаты подсчета заработка торгующих'}]\n",
      "\n",
      "KFC откроет новый вид ресторанов в России\n",
      "[{'generated_text': ' В России объяснили закрытие ресторанов в России.  '}]\n",
      "\n",
      "Минздрав России одобрил еще один препарат от коронавируса\n",
      "[{'generated_text': ' В Минздраве отреагировали на предложение'}]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "# gpt2-gen1/checkpoint-50\n",
    "# chef = pipeline('text-generation',model='./gpt2-gerchef', tokenizer='anonymous-german-nlp/german-gpt2',config={'max_length':800})\n",
    "\n",
    "gen = pipeline('text-generation',model=model, return_full_text=False,\n",
    "                tokenizer=tokenizer,config={'max_length':MAX_TOKENS*2},device=0)\n",
    "\n",
    "for item in new_titles[:30]:\n",
    "    print(item)\n",
    "    print(gen(item+'.'))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ^ standard pipeline performs pourly, ending sentences too fast\n",
    "\n",
    "## let's play with some inference parameters and make a lot of candidates to select from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Бывшую жену Грачевского обвинили в ранней смерти режиссера\n",
      "    =>  Жена режиссера рассказала о своей скорой смерти.\n",
      "    =>  Грачевский ответил на обвинения в ранней смерти.\n",
      "    =>  Раскрыты подробности смерти жены Грачевского.\n",
      "    =>  Раскрыты подробности смерти режиссера Грачевского.\n",
      "    =>  Раскрыта личность бывшего мужа Грачевского.\n",
      "    =>  Раскрыта личность бывшей жены Грачевского.\n",
      "    =>  Грачевский опроверг обвинения в ранней смерти режиссера.\n",
      "    =>  В России назвали причину смерти режиссера Грачевского.\n",
      "    =>  Раскрыто имя бывшей жены Грачевского.\n",
      "\n",
      "Россиянам разъяснили новые правила оформления выплат на детей\n",
      "    =>  В России объяснили новую систему выплат на детей.\n",
      "    =>  У россиян появилась возможность оформить выплаты на детей.\n",
      "    =>  РФ одобрила введение новых правил для россиян.\n",
      "    =>  Появились новые правила оформления выплат на детей.\n",
      "    =>  Власти объяснили новые правила оформления выплат на детей.\n",
      "    =>  В России объяснили правила оформления выплат на детей.\n",
      "\n",
      "Россиянин похитил миллиард рублей и поплатился\n",
      "    =>  В России объяснили похищение миллиона рублей.\n",
      "    =>  Раскрыты детали похищенного в России бизнесмена.\n",
      "    =>  На Курилах нашли вторую машину с оружием.\n",
      "    =>  Нападение на бизнесмена в России объяснили.\n",
      "    =>  Раскрыты подробности похищения Россией миллиарда рублей.\n",
      "    =>  Россиянин назвал сумму похищенного миллиона рублей.\n",
      "    =>  В России заподозрили похитителей миллионера долларов.\n",
      "    =>  О похищении миллион рублей в России заговорили.\n",
      "    =>  В России оценили похищение миллиарда рублей.\n",
      "    =>  В России назвали имена похитивших миллиард рублей россиян.\n",
      "    =>  В Подмосковье поймали мошенника с миллиардными деньгами.\n",
      "    =>  У россиянки нашли миллион рублей.\n",
      "    =>  В России отреагировали на похищение миллиард рублей.\n",
      "    =>  В России вернули похищенного россиянином миллиард рублей.\n",
      "\n",
      "Описано новое осложнение при коронавирусе\n",
      "    =>  В России предложили отмену коронавируса.\n",
      "\n",
      "США пошли на экстренные меры из-за коронавируса\n",
      "    =>  США ответили на новые санкции Евросоюза.\n",
      "    =>  В России объяснили такое поведение США.\n",
      "\n",
      "Глава белорусских католиков назвал изгнание из страны своим крестом\n",
      "    =>  Лукашенко объяснил появление в Беларуси другого креста.\n",
      "    =>  Лукашенко призвал не поддаваться на провокации.\n",
      "    =>  «Это грех» назвали в Беларуси.\n",
      "    =>  В Беларуси назвали клевету на Лукашенко.\n",
      "\n",
      "Посол России подарил Лукашенко карту Белоруссии в Российской империи\n",
      "    =>  Лукашенко объяснил подарок Белоруссии Белоруссии.\n",
      "    =>  Лукашенко ответил на подарок Лукашенко в России.\n",
      "    =>  Белоруссия поблагодарила Лукашенко за подарок.\n",
      "    =>  В Белоруссии отреагировали на подарок Лукашенко.\n",
      "    =>  Лукашенко подарил Лукашенко карту Белоруссии в Россию.\n",
      "    =>  Лукашенко подарил Белоруссии карту Белоруссии в Российской империи.\n",
      "    =>  Лукашенко ответил на подарок посла России.\n",
      "    =>  Лукашенко поблагодарил посла Белоруссии за подарок Белоруссии.\n",
      "    =>  Лукашенко извинился за подарок Белоруссии.\n",
      "    =>  Россия ответила на карту Белоруссии в России.\n",
      "    =>  Лукашенко пошутил над подарком Лукашенко в России.\n",
      "    =>  Лукашенко извинился перед Россией за подарок Лукашенко.\n",
      "    =>  Посол Белоруссии оценил карту Белоруссии в России.\n",
      "    =>  Лукашенко ответил Лукашенко на подарок от России.\n",
      "    =>  Лукашенко подарил России карту Белоруссии в Российской империи.\n",
      "    =>  Лукашенко отреагировал на подарок Белоруссии в российской империи.\n",
      "    =>  Лукашенко подарил карту Белоруссии в России.\n",
      "    =>  Посол Белоруссии оценил подарок белорусского посла.\n",
      "    =>  Лукашенко подарил карту Белоруссии в Российской империи.\n",
      "    =>  Лукашенко ответил Лукашенко на подарок Лукашенко в Белоруссии.\n",
      "    =>  Лукашенко подарил Лукашенко карту Белоруссии в России.\n",
      "    =>  Посол России ответил Лукашенко на подарок Белоруссии.\n",
      "    =>  Лукашенко согласился подарить карту Белоруссии в российской империи.\n",
      "    =>  Лукашенко передал Путину карту Белоруссии в России.\n",
      "    =>  Лукашенко отреагировал на подарок Белоруссии карты Белоруссии.\n",
      "    =>  Россия ответила на подарок Лукашенко в Белоруссии.\n",
      "    =>  Лукашенко поблагодарил президента России за подарок Белоруссии.\n",
      "    =>  Лукашенко ответил на подарок Польши картой.\n",
      "    =>  Лукашенко поблагодарил посла России за подарок Белоруссии.\n",
      "    =>  Лукашенко ответил на подарки от России.\n",
      "    =>  Лукашенко подарил Лукашенко карту Белоруссии в Российской империи.\n",
      "    =>  Белорусский посол пошутил о Белоруссии.\n",
      "    =>  Посол Белоруссии ответил на подарок Лукашенко.\n",
      "    =>  Лукашенко ответил на подарок посла Белоруссии в России.\n",
      "    =>  Лукашенко ответил на подарок Белоруссии.\n",
      "    =>  Лукашенко ответил на подарок Лукашенко.\n",
      "    =>  Лукашенко ответил на подарок Лукашенко картой Белоруссии.\n",
      "    =>  Лукашенко ответил на подарок посла России в Белоруссии.\n",
      "    =>  Лукашенко ответил на подарок Лукашенко Белоруссии в России.\n",
      "\n",
      "Россиян задумали избавить от страховых платежей по ипотеке\n",
      "    =>  Об этом сообщает «Российская газета».\n",
      "\n",
      "ПСБ профинансирует социально значимые проекты Краснодарского края\n",
      "    =>  Об этом сообщается на сайте ведомства.\n",
      "\n",
      "Китайским строителям в России подыскали замену\n",
      "    =>  Появилось видео с новым рабочим.\n",
      "    =>  Стало известно о найденной новой замене.\n",
      "    =>  Появились подробности возвращения китайских строителей в строй.\n",
      "    =>  Власти Киргизии объяснили замену китайских строителей на российских.\n",
      "    =>  Российские строители оценили новую замену.\n",
      "    =>  В России объяснили назначение новой замены.\n",
      "    =>  Китайский производитель представил замену своим конкурентам.\n",
      "    =>  Появилось видео с заменой российских строителей.\n",
      "    =>  В России оценили идею замены российского жилья на российское.\n",
      "    =>  В России оценили замену китайцам замены.\n",
      "    =>  Названа возможная причина смены администрации России.\n",
      "    =>  В России оценили замену китайских строителям.\n",
      "    =>  Китай предложил бойкотировать строительство в России.\n",
      "    =>  Появились подробности о новом строительстве в России.\n",
      "    =>  В России заявили о возможности замены российских построителям.\n",
      "    =>  Раскрыты детали первой очереди строительства в Петербурге.\n",
      "    =>  По новым нормам для строителей в России придумали имя.\n",
      "    =>  Появилось видео с новым президентом России.\n",
      "    =>  Раскрыты сроки замены китайских строителей на российских.\n",
      "    =>  В Петербурге оценили возможность замены асфальта на бетон.\n",
      "    =>  В России предложили ввести в строй российских строителей.\n",
      "    =>  Названа причина массового увольнения китайских строителей.\n",
      "    =>  «Станция метро в России начала работать.\n",
      "    =>  Имена двух бывших строителей в России раскрыты.\n",
      "    =>  Решено искать замену китайцам в России.\n",
      "\n",
      "Путин раскрыл суть изменений в Конституции\n",
      "    =>  Расхождения в Конституции РФ прокомментировал постпред России в ООН.\n",
      "    =>  Появились подробности о новых поправках в Конституцию.\n",
      "    =>  В Конституции РФ приравнены выборы.\n",
      "    =>  Путин объяснил смысл изменений в Конституции.\n",
      "    =>  В Конституцию РФ внесены поправки, позволяющие расширить полномочия Госдумы.\n",
      "    =>  Путин объяснил инициативу о смягчении Конституции.\n",
      "    =>  Россия ответила на уточняющие слова Трампа в кулуарах.\n",
      "    =>  Раскрыты детали поправок в Конституцию.\n",
      "    =>  Песков заявил о введении новых правил в Конституции.\n",
      "    =>  Сенсация раскрыла суть изменений в Конституции России.\n",
      "    =>  В Госдуме ответили на слова о необходимости новой Конституции.\n",
      "    =>   \"Свердловская область ответила на изменения в Конституции.\n",
      "    =>  Усиление пенсионной системы в России объяснили.\n",
      "    =>  В Госдуме объяснили, почему депутаты предложили изменить Конституцию.\n",
      "    =>  По мнению Путина, изменения в Конституции РФ могли бы коснуться всех.\n",
      "    =>  Путин объяснил новые изменения в Конституции России.\n",
      "    =>  Медведев объяснил суть изменений в Конституции.\n",
      "    =>  В России посчитали действующую Конституцию «заменой» действующей.\n",
      "    =>  В Госдуме отреагировали на введение новых поправок в Конституцию.\n",
      "    =>  Названы сроки принятия Конституции РФ в 2019 году.\n",
      "    =>  В Кремле отреагировали на данные о новом проекте Путина.\n",
      "    =>  В России объяснили закрытие Конституции после выборов.\n",
      "    =>  Путин назвал суть изменений в Конституции.\n",
      "    =>  Путин ответил на слова Путина о реформе Конституции.\n",
      "    =>  Медведев объяснил масштаб изменений в Конституции.\n",
      "    =>  Путин прокомментировал изменение Конституции о поправках к Конституции.\n",
      "    =>  Конституционный суд раскрыл суть поправок в Конституцию.\n",
      "    =>  Раскрыты подробности изменения Конституции России.\n",
      "    =>  Названа причина закрытого закона в России.\n",
      "    =>  В Госдуме прокомментировали информацию о закрытии Конституции от имени Путина.\n",
      "    =>  В России объяснили раскрытие смысла изменений в Конституции.\n",
      "    =>  Путин объяснил причину закрытия конституции России.\n",
      "    =>  Озаглавный документ Конституционного суда раскрыли.\n",
      "    =>  Уволенный из правительства Путин прокомментировал изменения в Конституции.\n",
      "    =>  В России объяснили новые санкции против Путина.\n",
      "    =>  В России опровергли слова о реформе Конституции.\n",
      "    =>  Назван виновником раскрытия деталей новой Конституции.\n",
      "    =>  Президент России отреагировал на данные о количестве российских паспортов.\n",
      "    =>  В Госдуме объяснили список изменений к Конституции в новой Конституции.\n",
      "    =>  Путин ответил на предложение Трампа ввести новую Конституцию.\n",
      "    =>  При этом Песков ответил на слова Путина о необходимости менять Конституцию.\n",
      "    =>  В России оценили слова Путина о поправке к Конституции.\n",
      "    =>  Раскрыты подробности изменений в Конституции России.\n",
      "    =>  В Госдуме оценили изменения в Конституции России.\n",
      "    =>  Конституционный суд подтвердил уточнение Конституции.\n",
      "    =>  Путин прокомментировал итоги президентских выборов в России.\n",
      "    =>  Раскрыты детали изменений в Конституцию.\n",
      "    =>  В Госдуме оценили слова Путина о поправках к Конституции.\n",
      "    =>  Глава Конституционного суда объяснил применение поправок в Конституцию.\n",
      "    =>  Конституционный суд разъяснил смысл поправок в Конституцию.\n",
      "    =>  А вот о чем пишет Путин в интервью немецкому изданию.\n",
      "    =>  В России объяснили слова Путина об ужесточении правил коронавируса.\n",
      "    =>  Путин раскрыл суть изменений в Конституции России.\n",
      "    =>  Песков прокомментировал слова Путина о новой Конституции.\n",
      "    =>  Путин ответил на обвинения в «изгнании» Конституции.\n",
      "    =>  В Госдуме предложили провести «сводку из Кремля».\n",
      "    =>  Путин назвал суть изменений в Конституции РФ.\n",
      "    =>  Появились подробности о нововведении в Конституцию.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Россиян предупредили о погодных аномалиях в течение недели\n",
      "    =>  У жителей России выросли тарифы на электричество.\n",
      "\n",
      "На поддержку рыбохозяйств в Подмосковье выделено 22 миллиона рублей\n",
      "    =>  В Подмосковье задержан высокопоставленный чиновник.\n",
      "\n",
      "Американцам предложат включить в рацион мясо питонов\n",
      "    =>  В России объяснили отказ от мяса питонов.\n",
      "    =>  Запрет на мясо питонов объяснили.\n",
      "    =>  Назван новый тип мяса питонов.\n",
      "    =>  Появились подробности отказа от мяса питонов.\n",
      "    =>  В России предложили отказаться от мяса питонов.\n",
      "    =>  Российские ученые объяснили отказ от мяса питонов.\n",
      "    =>  Названа причина запрета на мясо питонов.\n",
      "    =>  США ответили на предложение запретить мясо питонов.\n",
      "\n",
      "Подсчитан заработок торгующих на бирже россиян\n",
      "    =>  Задержаны участники торгов на бирже.\n",
      "    =>   Зарплату россиян назвали обманом.\n",
      "    =>  Заработок россиян на бирже россиян упал.\n",
      "    =>  В России оценили заработки продавцов на бирже.\n",
      "    =>  В Госдуме оценили работу россиян за счет рекламы.\n",
      "    =>  Учителя в России оценили зарплату учителя.\n",
      "    =>  В Госдуме оценили работу сотрудников на бирже.\n",
      "    =>  Власти оценили информацию о доходах россиян за год.\n",
      "\n",
      "KFC откроет новый вид ресторанов в России\n",
      "    =>  В России оценили закрытие ресторана в России.\n",
      "    =>   В России предложили создать новый вид заведений быстрого питания.\n",
      "    =>  В России объяснили появление нового вида ресторанов в России.\n",
      "    =>  Появились подробности открытия нового вида ресторанов в России.\n",
      "    =>  Появились подробности о возможном открытии новых ресторанов в России.\n",
      "    =>  Расходы на открытие новых ресторанов в России вырастут.\n",
      "    =>  В России отреагировали на открытие нового ресторана в России.\n",
      "    =>  В Москве открыли новую сеть ресторанов быстрого питания.\n",
      "    =>  В России объяснили запрет на рестораны в США.\n",
      "    =>  Названа цель открытия нового вида ресторанов в России.\n",
      "    =>  В России объяснили открытие нового ресторана в России.\n",
      "    =>  В России оценили открытие нового ресторана в России.\n",
      "    =>  Открытие новых ресторанов в России объяснили.\n",
      "    =>  В России признали новые границы для ресторанов.\n",
      "    =>  В России объяснили запрет на открытие новых ресторанов.\n",
      "    =>  В России открыли новые рестораны в Москве.\n",
      "    =>  В России планируют открыть новые рестораны в России.\n",
      "    =>  Российский ресторатор объяснил открытие нового вида ресторанов в России.\n",
      "    =>  В России заявили о планах открыть новые рестораны.\n",
      "    =>  В России объяснили запрет на рестораны в России.\n",
      "    =>  В России открылся новый ресторан.\n",
      "    =>  Появится официальное название для нового ресторана в России.\n",
      "    =>  В России назвали число ресторанов, где готовят мясо.\n",
      "    =>   В Москве объяснили планы открытия новых ресторанов.\n",
      "    =>  В России появится сеть ресторанов с живой едой.\n",
      "    =>   В России открыли новые рестораны.\n",
      "    =>  В России объяснили решение о закрытии ресторанов в России.\n",
      "    =>  Появились подробности открытия ресторана в России.\n",
      "    =>  В Москве подтвердили открытие нового ресторана.\n",
      "    =>  В России назвали условия открытия ресторанов в России.\n",
      "    =>  В России оценили идею открыть новые рестораны в России.\n",
      "    =>  В России оценили новые рестораны в России.\n",
      "    =>  В России объяснили открытие новых ресторанов в России.\n",
      "    =>  В России прокомментировали открытие нового ресторана в России.\n",
      "    =>  Появились подробности открытия нового ресторана в Москве.\n",
      "    =>  Появилось фото с открытием новых ресторанов в России.\n",
      "    =>  Появились подробности открытия новых ресторанов в России.\n",
      "    =>  В России отреагировали на открытие новых заведений в России.\n",
      "    =>  В России отреагировали на открытие новых ресторанов в России.\n",
      "    =>  Открытый ресторан быстрого питания в Москве откроется в марте.\n",
      "    =>  В России объяснили закрытие нового вида ресторанов.\n",
      "    =>  Роспотребнадзор предложил ввести ограничения на питание в российских ресторанах.\n",
      "    =>  Появились подробности открытия нового ресторана в России.\n",
      "\n",
      "Минздрав России одобрил еще один препарат от коронавируса\n",
      "    =>  У российского врача обнаружили коронавирус.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "transformers.logging.set_verbosity_error()\n",
    "\n",
    "def sample(model, tokenizer, prefix, n):\n",
    "    prefix_tokens = torch.LongTensor(tokenizer.encode(prefix+'.')).to(device)[None]\n",
    "    preds = model.generate(\n",
    "        prefix_tokens,\n",
    "#         num_beams=5, \n",
    "#         no_repeat_ngram_size=2, \n",
    "#         early_stopping=False\n",
    "#         max_length=50, \n",
    "        num_return_sequences=n, \n",
    "        do_sample=True, \n",
    "        top_k=0,\n",
    "        temperature=0.7,\n",
    "        top_p=0.92,\n",
    "    )\n",
    "    return [tokenizer.decode(preds[r].cpu().numpy()) for r in range(n)]\n",
    "\n",
    "def simple_filter(items):\n",
    "    return list(set([item.split('.')[1]+'.' for item in items if item.count('.')>1 and item.split('.')[1].count(' ')>4]))\n",
    "\n",
    "for item in new_titles[:30]:\n",
    "    if '.' in item: continue\n",
    "    for _ in range(10):\n",
    "        res = simple_filter(sample(model, tokenizer, item, 64))\n",
    "        if res:\n",
    "            print(item)\n",
    "            for r in res:\n",
    "                print(f'    => {r}')\n",
    "            print()\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Состояние итальянского футболиста после кровоизлияния в мозг назвали критическим\n",
      "1000 Пандемия коронавируса вызвала эпидемию психических расстройств\n",
      "2000 Кинокритики выбрали лучший фильм 2019 года\n",
      "3000 Мужчина попытался проникнуть в здание методом Санта-Клауса и застрял\n",
      "4000 ФСБ изъяла более 100 золотых слитков при обысках по делу о хищении медпрепаратов\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6156/2067114843.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'.'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimple_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_6156/605539420.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(model, tokenizer, prefix, n)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mtop_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mtop_p\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.92\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     )\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/altsoph/Volume/_py37/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/altsoph/Volume/_py37/lib/python3.7/site-packages/transformers/generation_utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, input_ids, max_length, min_length, do_sample, early_stopping, num_beams, temperature, top_k, top_p, repetition_penalty, bad_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, max_new_tokens, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   1024\u001b[0m                 \u001b[0mreturn_dict_in_generate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict_in_generate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m                 \u001b[0msynced_gpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynced_gpus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m                 \u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m             )\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/altsoph/Volume/_py37/lib/python3.7/site-packages/transformers/generation_utils.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, logits_warper, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   1533\u001b[0m                 \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m                 \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1535\u001b[0;31m                 \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1536\u001b[0m             )\n\u001b[1;32m   1537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/altsoph/Volume/_py37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/altsoph/Volume/_py37/lib/python3.7/site-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    954\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 956\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    957\u001b[0m         )\n\u001b[1;32m    958\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/altsoph/Volume/_py37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/altsoph/Volume/_py37/lib/python3.7/site-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    797\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m                     \u001b[0muse_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 799\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    800\u001b[0m                 )\n\u001b[1;32m    801\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/altsoph/Volume/_py37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/altsoph/Volume/_py37/lib/python3.7/site-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m         \u001b[0mfeed_forward_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0;31m# residual connection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/altsoph/Volume/_py37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    713\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 715\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    716\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    717\u001b[0m                 \u001b[0m_global_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with open('gpt-gen-raw.tsv', 'a', encoding='utf-8') as ofh:\n",
    "    for idx, item in enumerate(new_titles):\n",
    "        if not idx%1000: print(idx, item)\n",
    "        if '.' in item: continue\n",
    "        for _ in range(10):\n",
    "            res = simple_filter(sample(model, tokenizer, item, 64))\n",
    "            if res:\n",
    "                for r in res:\n",
    "                    print(f'{item}\\t{r}', file=ofh, flush=True)\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I've stopped this after ~5K left titles (but not each of them has any results) \n",
    "#### Now we have ~39K generated pairs with 3K uniq left titles\n",
    "\n",
    "## One of the problems -- sometimes it uses corefs from right side to the left one.\n",
    "## I.e.:\n",
    "#### США пошли на экстренные меры из-за коронавируса  =>  В России объяснили такое поведение США.\n",
    "## The easiest solution for this and other problems -- to train an external filter-discriminator. We'll use only right parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1469\n",
      "39327\n",
      "['Глава ЦБ отреагировал на снижение евро', 'В Свердловской области опровергли информацию о ремонте дорог', 'Россия ответила на запуск поезда в Крым', 'Россия отреагировала на отмену западных санкций', 'Песков отреагировал на слова о частной клинике', 'Россия отреагировала на снижение курса евро до 90 рублей', 'Армия Азербайджана заняла Агдамский район', 'Иран обвинил США в нарушении воздушного пространства', 'В США прокомментировали обращение Мясникова к людям', 'В России оценили рост цен на нефть']\n",
      "2938\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "rights = []\n",
    "with open(\"ru_news_cause_v1.tsv\", \"r\", encoding='utf-8') as r:\n",
    "    reader = csv.reader(r, delimiter=\"\\t\")\n",
    "    header = next(reader)\n",
    "    for row in reader:\n",
    "        r = dict(zip(header, row))\n",
    "        if float(r[\"confidence\"]) < 0.69:\n",
    "            continue\n",
    "        result = r[\"result\"]\n",
    "        if result == 'left_right_cause':\n",
    "            rights.append( {'title':r['right_title'], 'label':1 } )\n",
    "        elif result == 'left_right_cancel':\n",
    "            rights.append( {'title':r['right_title'], 'label':1 } )\n",
    "        elif result == 'right_left_cause':\n",
    "            rights.append( {'title':r['left_title'], 'label':1 } )\n",
    "        elif result == 'right_left_cancel':\n",
    "            rights.append( {'title':r['left_title'], 'label':1 } )\n",
    "print(len(rights))\n",
    "\n",
    "fake_rights = []\n",
    "for line in open('gpt-gen-raw.tsv', encoding='utf-8'):\n",
    "    try:\n",
    "        left, right = line.strip('\\n').split('\\t')\n",
    "    except:\n",
    "        continue\n",
    "    fake_rights.append( right.strip().strip('.') )\n",
    "    \n",
    "np.random.seed(1337)\n",
    "np.random.shuffle(fake_rights)\n",
    "print(len(fake_rights))\n",
    "print(fake_rights[:10])\n",
    "\n",
    "sample_size = len(rights)\n",
    "for item in fake_rights[:sample_size]:\n",
    "    rights.append( {'title':item, 'label':0 } )\n",
    "print(len(rights))\n",
    "np.random.shuffle(rights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class NewsSinglesDataset(Dataset):\n",
    "    def __init__(self, records, max_tokens, model_name, labels_count):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\n",
    "            model_name,\n",
    "            do_lower_case=False\n",
    "        )\n",
    "        self.max_tokens = max_tokens\n",
    "        self.records = records\n",
    "        self.labels_count = labels_count\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.records)\n",
    "    \n",
    "    def embed_record(self, record):\n",
    "        inputs = self.tokenizer(\n",
    "            text=record[\"title\"],\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_tokens,\n",
    "            padding=\"max_length\",\n",
    "            truncation=\"longest_first\",\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        for key, value in inputs.items():\n",
    "            value.squeeze_(0)\n",
    "        return inputs\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        record = self.records[index]\n",
    "        output = self.embed_record(record)\n",
    "        label = record.get(\"label\", None)\n",
    "        if label is not None:\n",
    "            output[\"labels\"] = torch.tensor(label)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2350\n",
      "294\n",
      "294\n"
     ]
    }
   ],
   "source": [
    "rights_train_records, rights_val_records, rights_test_records = [], [], []\n",
    "val_border = int(0.8 * len(rights))\n",
    "test_border = int(0.9 * len(rights))\n",
    "rights_train_records.extend(rights[:val_border])\n",
    "rights_val_records.extend(rights[val_border:test_border])\n",
    "rights_test_records.extend(rights[test_border:])\n",
    "\n",
    "print(len(rights_train_records))\n",
    "print(len(rights_val_records))\n",
    "print(len(rights_test_records))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/DeepPavlov/rubert-base-cased/resolve/main/config.json from cache at /media/altsoph/Volume/_transformers_cache/a43261a78bd9edbbf43584c6b00aa94c032301840e532839cb5989362562a5d5.e8f15c5aad2f4653e46ceeba0bb32c02a629d106a902c964bce60523d290ac8f\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/DeepPavlov/rubert-base-cased/resolve/main/pytorch_model.bin from cache at /media/altsoph/Volume/_transformers_cache/1a4e163b2517b97a0eed0a06dc8ba7627019fed06fb41085ebcf0b777a07e862.a0e9ad8657fb29c68a009fb426ac1dfbefd782eea8b58d5851ae4869ec552fcc\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "DISCR_MODEL_NAME = \"DeepPavlov/rubert-base-cased\"\n",
    "DISCR_TOKENIZER_NAME = DISCR_MODEL_NAME\n",
    "device = 'cuda'\n",
    "cache_dir = '/media/altsoph/Volume/_transformers_cache/'\n",
    "MAX_TOKENS = 80\n",
    "\n",
    "rights_model = AutoModelForSequenceClassification.from_pretrained(DISCR_MODEL_NAME, num_labels=2, cache_dir=cache_dir)\n",
    "rights_model = rights_model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/DeepPavlov/rubert-base-cased/resolve/main/config.json from cache at /home/altsoph/.cache/huggingface/transformers/a43261a78bd9edbbf43584c6b00aa94c032301840e532839cb5989362562a5d5.e8f15c5aad2f4653e46ceeba0bb32c02a629d106a902c964bce60523d290ac8f\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/DeepPavlov/rubert-base-cased/resolve/main/vocab.txt from cache at /home/altsoph/.cache/huggingface/transformers/5dd198988cb85bc18d17f196ffae19788abc4fcff7fbe7f8ef02e1322c5ac3cc.018f85b6550237c27386c0ec90a1ff7bdcf74e56a9e2d32131e29c4689192eaa\n",
      "loading file https://huggingface.co/DeepPavlov/rubert-base-cased/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/DeepPavlov/rubert-base-cased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/DeepPavlov/rubert-base-cased/resolve/main/special_tokens_map.json from cache at /home/altsoph/.cache/huggingface/transformers/853440ef3f696efb168918bd6c8489323dfaad3a7b308974fa2669336a00d203.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n",
      "loading file https://huggingface.co/DeepPavlov/rubert-base-cased/resolve/main/tokenizer_config.json from cache at /home/altsoph/.cache/huggingface/transformers/d9e31304a406bb10bd448caf19da6f894350a8bf96f740aa84e6d291229de7b0.5cc6e825eb228a7a5cfd27cb4d7151e97a79fb962b31aaf1813aa102e746584b\n",
      "loading configuration file https://huggingface.co/DeepPavlov/rubert-base-cased/resolve/main/config.json from cache at /home/altsoph/.cache/huggingface/transformers/a43261a78bd9edbbf43584c6b00aa94c032301840e532839cb5989362562a5d5.e8f15c5aad2f4653e46ceeba0bb32c02a629d106a902c964bce60523d290ac8f\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/DeepPavlov/rubert-base-cased/resolve/main/vocab.txt from cache at /home/altsoph/.cache/huggingface/transformers/5dd198988cb85bc18d17f196ffae19788abc4fcff7fbe7f8ef02e1322c5ac3cc.018f85b6550237c27386c0ec90a1ff7bdcf74e56a9e2d32131e29c4689192eaa\n",
      "loading file https://huggingface.co/DeepPavlov/rubert-base-cased/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/DeepPavlov/rubert-base-cased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/DeepPavlov/rubert-base-cased/resolve/main/special_tokens_map.json from cache at /home/altsoph/.cache/huggingface/transformers/853440ef3f696efb168918bd6c8489323dfaad3a7b308974fa2669336a00d203.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n",
      "loading file https://huggingface.co/DeepPavlov/rubert-base-cased/resolve/main/tokenizer_config.json from cache at /home/altsoph/.cache/huggingface/transformers/d9e31304a406bb10bd448caf19da6f894350a8bf96f740aa84e6d291229de7b0.5cc6e825eb228a7a5cfd27cb4d7151e97a79fb962b31aaf1813aa102e746584b\n"
     ]
    }
   ],
   "source": [
    "rights_train_data = NewsSinglesDataset(rights_train_records, MAX_TOKENS, DISCR_TOKENIZER_NAME, 2)\n",
    "rights_val_data = NewsSinglesDataset(rights_val_records, MAX_TOKENS, DISCR_TOKENIZER_NAME, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "***** Running training *****\n",
      "  Num examples = 2350\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 4\n",
      "  Total optimization steps = 90\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='90' max='90' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [90/90 02:56, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.638200</td>\n",
       "      <td>0.488425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.486100</td>\n",
       "      <td>0.378773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.391600</td>\n",
       "      <td>0.334482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.351600</td>\n",
       "      <td>0.321026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.281300</td>\n",
       "      <td>0.297469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.242200</td>\n",
       "      <td>0.279285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.227000</td>\n",
       "      <td>0.280040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.209600</td>\n",
       "      <td>0.264115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.178100</td>\n",
       "      <td>0.270699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 294\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to rights_discriminator/checkpoint-10\n",
      "Configuration saved in rights_discriminator/checkpoint-10/config.json\n",
      "Model weights saved in rights_discriminator/checkpoint-10/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 294\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to rights_discriminator/checkpoint-20\n",
      "Configuration saved in rights_discriminator/checkpoint-20/config.json\n",
      "Model weights saved in rights_discriminator/checkpoint-20/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 294\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to rights_discriminator/checkpoint-30\n",
      "Configuration saved in rights_discriminator/checkpoint-30/config.json\n",
      "Model weights saved in rights_discriminator/checkpoint-30/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 294\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to rights_discriminator/checkpoint-40\n",
      "Configuration saved in rights_discriminator/checkpoint-40/config.json\n",
      "Model weights saved in rights_discriminator/checkpoint-40/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 294\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to rights_discriminator/checkpoint-50\n",
      "Configuration saved in rights_discriminator/checkpoint-50/config.json\n",
      "Model weights saved in rights_discriminator/checkpoint-50/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 294\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to rights_discriminator/checkpoint-60\n",
      "Configuration saved in rights_discriminator/checkpoint-60/config.json\n",
      "Model weights saved in rights_discriminator/checkpoint-60/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 294\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to rights_discriminator/checkpoint-70\n",
      "Configuration saved in rights_discriminator/checkpoint-70/config.json\n",
      "Model weights saved in rights_discriminator/checkpoint-70/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 294\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to rights_discriminator/checkpoint-80\n",
      "Configuration saved in rights_discriminator/checkpoint-80/config.json\n",
      "Model weights saved in rights_discriminator/checkpoint-80/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 294\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to rights_discriminator/checkpoint-90\n",
      "Configuration saved in rights_discriminator/checkpoint-90/config.json\n",
      "Model weights saved in rights_discriminator/checkpoint-90/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from rights_discriminator/checkpoint-80 (score: 0.26411500573158264).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=90, training_loss=0.33397502899169923, metrics={'train_runtime': 177.2207, 'train_samples_per_second': 66.302, 'train_steps_per_second': 0.508, 'total_flos': 999175038005760.0, 'train_loss': 0.33397502899169923, 'epoch': 4.97})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "EPOCHS = 5\n",
    "EVAL_STEPS = 10 #*8\n",
    "WARMUP_STEPS = 5 # *8\n",
    "LR = 3e-05\n",
    "BATCH_SIZE = 128//4 # \n",
    "GRAD_ACCUM_STEPS = 1*4\n",
    "\n",
    "discr_training_args = TrainingArguments(\n",
    "    output_dir=\"rights_discriminator\",\n",
    "    overwrite_output_dir=True, #overwrite the content of the output directory\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    logging_steps=EVAL_STEPS,\n",
    "    save_steps=EVAL_STEPS,\n",
    "    warmup_steps=WARMUP_STEPS,\n",
    "    learning_rate=LR,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    gradient_accumulation_steps=GRAD_ACCUM_STEPS,\n",
    "    report_to=\"none\",\n",
    "#     report_to=\"wandb\",  # enable logging to W&B\n",
    "#     run_name=\"newscausation_basetask\",\n",
    "    load_best_model_at_end=True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=rights_model,\n",
    "    args=discr_training_args,\n",
    "    train_dataset=rights_train_data,\n",
    "    eval_dataset=rights_val_data\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rights_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/DeepPavlov/rubert-base-cased/resolve/main/config.json from cache at /home/altsoph/.cache/huggingface/transformers/a43261a78bd9edbbf43584c6b00aa94c032301840e532839cb5989362562a5d5.e8f15c5aad2f4653e46ceeba0bb32c02a629d106a902c964bce60523d290ac8f\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/DeepPavlov/rubert-base-cased/resolve/main/vocab.txt from cache at /home/altsoph/.cache/huggingface/transformers/5dd198988cb85bc18d17f196ffae19788abc4fcff7fbe7f8ef02e1322c5ac3cc.018f85b6550237c27386c0ec90a1ff7bdcf74e56a9e2d32131e29c4689192eaa\n",
      "loading file https://huggingface.co/DeepPavlov/rubert-base-cased/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/DeepPavlov/rubert-base-cased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/DeepPavlov/rubert-base-cased/resolve/main/special_tokens_map.json from cache at /home/altsoph/.cache/huggingface/transformers/853440ef3f696efb168918bd6c8489323dfaad3a7b308974fa2669336a00d203.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n",
      "loading file https://huggingface.co/DeepPavlov/rubert-base-cased/resolve/main/tokenizer_config.json from cache at /home/altsoph/.cache/huggingface/transformers/d9e31304a406bb10bd448caf19da6f894350a8bf96f740aa84e6d291229de7b0.5cc6e825eb228a7a5cfd27cb4d7151e97a79fb962b31aaf1813aa102e746584b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 1 0 0 0 1 1 1 0 0 0 0 0 0 0 1 1 1 1 1 1 0 1 0 0 0 0 0 0 1 1 1 0 1 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 0 0 0 0 1 1 0 1\n",
      " 1 1 1 0 1 1 0 1 0 1 0 0 1 1 0 1 1 0 0 1 0 0 1 1 0 0 1 1 0 1 0 1 1 1 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 1 0 0 1 0 1 1 1 1 1 0 1 0 1 1 1 0 1 0 1 0 1 1 0 0 0 1 0\n",
      " 0 0 0 0 0 0 1 0 1 1 0 1 0 0 1 1 0 1 0 1 1 1 1 1 1 1 0 0 1 1 0 1 1 0 1 1 1\n",
      " 1 1 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 1 0 0 1 1 1 1 1 0 0 0 1 0 0 0 0 1 1 0 0\n",
      " 1 1 0 1 1 0 0 0 0 1 1 0 1 0 0 0 1 1 0 1 0 1 1 0 0 0 0 0 0 1 0 1 0 0 1 1 1\n",
      " 1 1 1 1 0 0 0 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 1 1 1 0 0 1 0 1 1 1 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "test_data = NewsSinglesDataset(rights_test_records, MAX_TOKENS, DISCR_TOKENIZER_NAME, 2)\n",
    "y_true = [item[\"labels\"].item() for item in test_data]\n",
    "y_true = np.array(y_true, dtype=np.int32)\n",
    "print(y_true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 1 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 1 1 1 1 1 1 1 0 0 0 0 0 1 1 1 0 0 1\n",
      " 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 1 0 1 1 1 0 1 0 0 0 1 1 0 1\n",
      " 0 1 1 0 1 1 0 0 0 1 0 0 1 1 1 1 1 0 0 1 0 0 0 1 0 0 1 1 0 1 0 1 1 1 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 1 1 1 0 1 0 1 0 1 0 1 1 1 0 1 1 0 0 1 1 0\n",
      " 0 0 0 0 0 0 1 0 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1\n",
      " 1 1 0 0 0 0 0 1 0 1 0 1 0 0 1 0 1 1 0 0 1 1 1 1 0 0 0 0 1 0 0 0 0 1 1 0 0\n",
      " 1 1 0 1 1 1 1 0 0 1 1 0 1 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 1 0 0 0 0 1 1 1\n",
      " 1 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 0 0 0 1 1 1 0 0 1 0 1 1 1 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "y_pred = []\n",
    "with torch.no_grad():\n",
    "    for item in test_data:\n",
    "        for key, value in item.items():\n",
    "            item[key] = value.unsqueeze_(0).cuda()\n",
    "        outputs = rights_model(**item, return_dict=True)\n",
    "        pred = torch.argmax(outputs.logits).item()\n",
    "        y_pred.append(pred)\n",
    "y_pred = np.array(y_pred)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.89      0.90       154\n",
      "           1       0.88      0.91      0.90       140\n",
      "\n",
      "    accuracy                           0.90       294\n",
      "   macro avg       0.90      0.90      0.90       294\n",
      "weighted avg       0.90      0.90      0.90       294\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[137,  17],\n",
       "       [ 12, 128]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(classification_report(y_true, y_pred))\n",
    "confusion_matrix(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/DeepPavlov/rubert-base-cased/resolve/main/config.json from cache at /home/altsoph/.cache/huggingface/transformers/a43261a78bd9edbbf43584c6b00aa94c032301840e532839cb5989362562a5d5.e8f15c5aad2f4653e46ceeba0bb32c02a629d106a902c964bce60523d290ac8f\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/DeepPavlov/rubert-base-cased/resolve/main/vocab.txt from cache at /home/altsoph/.cache/huggingface/transformers/5dd198988cb85bc18d17f196ffae19788abc4fcff7fbe7f8ef02e1322c5ac3cc.018f85b6550237c27386c0ec90a1ff7bdcf74e56a9e2d32131e29c4689192eaa\n",
      "loading file https://huggingface.co/DeepPavlov/rubert-base-cased/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/DeepPavlov/rubert-base-cased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/DeepPavlov/rubert-base-cased/resolve/main/special_tokens_map.json from cache at /home/altsoph/.cache/huggingface/transformers/853440ef3f696efb168918bd6c8489323dfaad3a7b308974fa2669336a00d203.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n",
      "loading file https://huggingface.co/DeepPavlov/rubert-base-cased/resolve/main/tokenizer_config.json from cache at /home/altsoph/.cache/huggingface/transformers/d9e31304a406bb10bd448caf19da6f894350a8bf96f740aa84e6d291229de7b0.5cc6e825eb228a7a5cfd27cb4d7151e97a79fb962b31aaf1813aa102e746584b\n"
     ]
    }
   ],
   "source": [
    "raw_pairs = []\n",
    "markup_inputs = []\n",
    "for line in open('gpt-gen-raw.tsv', encoding='utf-8'):\n",
    "    try:\n",
    "        left, right = line.strip('\\n').split('\\t')\n",
    "    except:\n",
    "        continue\n",
    "    raw_pairs.append( (left,right) )\n",
    "    markup_inputs.append( {'title':right.strip().strip('.'), 'label':0 }  )\n",
    "   \n",
    "\n",
    "infer_data = NewsSinglesDataset(markup_inputs, MAX_TOKENS, DISCR_TOKENIZER_NAME, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 ... 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "y_pred = []\n",
    "with torch.no_grad():\n",
    "    for item in infer_data:\n",
    "        for key, value in item.items():\n",
    "            item[key] = value.unsqueeze_(0).cuda()\n",
    "        outputs = rights_model(**item, return_dict=True)\n",
    "        pred = torch.argmax(outputs.logits).item()\n",
    "        y_pred.append(pred)\n",
    "y_pred = np.array(y_pred)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39327\n",
      "39327\n",
      "4118\n"
     ]
    }
   ],
   "source": [
    "print(len(raw_pairs))\n",
    "print(len(y_pred))\n",
    "print(np.sum(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('gpt-gen-filtered-rights.tsv', 'a', encoding='utf-8') as ofh:\n",
    "    for label,pair in zip(y_pred, raw_pairs):\n",
    "        if label:\n",
    "            print(f'{pair[0]}\\t{pair[1]}', file=ofh, flush=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check the generated pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/altsoph/Volume/_py37/lib/python3.7/site-packages/torchaudio/backend/utils.py:54: UserWarning: \"sox\" backend is being deprecated. The default backend will be changed to \"sox_io\" backend in 0.8.0 and \"sox\" backend will be removed in 0.9.0. Please migrate to \"sox_io\" backend. Please refer to https://github.com/pytorch/audio/issues/903 for the detail.\n",
      "  '\"sox\" backend is being deprecated. '\n",
      "2021-08-09 10:03:56.149129: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 2, 0, ..., 0, 0, 2])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "def set_random_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:2\"\n",
    "    os.environ[\"PL_GLOBAL_SEED\"] = str(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "def pipe_predict(data, batch_size=64):\n",
    "    raw_preds = pipe(data, batch_size=batch_size)\n",
    "    preds = np.array([int(max(labels, key=lambda x: x[\"score\"])[\"label\"][-1]) for labels in raw_preds])\n",
    "    pp = np.array([[l[\"score\"] for l in labels] for labels in raw_preds])\n",
    "    return preds, pp\n",
    "    \n",
    "set_random_seed(1337)\n",
    "\n",
    "# MODEL_NAME = \"DeepPavlov/rubert-base-cased\"\n",
    "MODEL_NAME = \"xlm-roberta-large\"\n",
    "TOKENIZER_NAME = MODEL_NAME\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, do_lower_case=False)\n",
    "MODEL_NAME = \"./bertcause-task0/checkpoint-192\"\n",
    "MAX_TOKENS = 80\n",
    "cache_dir = '/media/altsoph/Volume/_transformers_cache/'\n",
    "\n",
    "# train_records = ru_train_records # + en_train_records\n",
    "# val_records = ru_val_records #+ en_val_records\n",
    "# random.shuffle(train_records)\n",
    "\n",
    "# train_data = NewsPairsDataset(train_records, tokenizer, MAX_TOKENS, labels_count)\n",
    "# val_data = NewsPairsDataset(val_records, tokenizer, MAX_TOKENS, labels_count)\n",
    "3\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=3)\n",
    "model = model.to(\"cuda\")\n",
    "\n",
    "\n",
    "model.eval()\n",
    "pipe = pipeline(\"text-classification\", model=model, tokenizer=tokenizer, framework=\"pt\", device=0, return_all_scores=True)\n",
    "\n",
    "infer_records = []\n",
    "for line in open('gpt-gen-filtered-rights.tsv', encoding='utf-8'):\n",
    "    left, right = line.strip().split('\\t')\n",
    "    right = right.strip().strip('.')\n",
    "    infer_records.append( {'left_title': left, 'right_title': right, 'label':-1})\n",
    "# y_pred = pipe_predict()[0]\n",
    "# infer_data = NewsPairsDataset(infer_records, tokenizer, MAX_TOKENS, labels_count)\n",
    "# y_pred\n",
    "# infer_records\n",
    "# ru_test_pairs\n",
    "infer_pairs = [(r[\"left_title\"], r[\"right_title\"]) for r in infer_records]\n",
    "# infer_pairs\n",
    "ru_y_pred = pipe_predict(infer_pairs)[0]\n",
    "ru_y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({2: 2153, 0: 1823, 1: 142})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(ru_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "code2label = {0:'other',1:'right2left',2:'left2right'}\n",
    "with open('gpt-gen-filtered-rights-markup.tsv', 'a', encoding='utf-8') as ofh:\n",
    "    for label, pair in zip(ru_y_pred, infer_pairs):\n",
    "        print(f\"{pair[0]}\\t{pair[1]}\\t{code2label[label]}\", file=ofh, flush=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "XN_3krN3VNHl"
   ],
   "name": "DeprecatedTitles.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "317e3bf1475a4660936f1c8e0f8ad5da": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "678b99192bf34feaa3591281cf4c9385": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "7f1f5cb3c0d2463f8774b83bcf243822": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "85e64aedcbd44f7daba63e94a81c9e1f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9d4417c0e3584042a686d4c848d94f49",
       "IPY_MODEL_c2d8dd7540064898b8c142175786bf70"
      ],
      "layout": "IPY_MODEL_f958cec91e904d5c9caf315b42a388ed"
     }
    },
    "9d4417c0e3584042a686d4c848d94f49": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_317e3bf1475a4660936f1c8e0f8ad5da",
      "max": 55535,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_678b99192bf34feaa3591281cf4c9385",
      "value": 55535
     }
    },
    "b95d69cae6404d46963c015e18ebbbf9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c2d8dd7540064898b8c142175786bf70": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7f1f5cb3c0d2463f8774b83bcf243822",
      "placeholder": "​",
      "style": "IPY_MODEL_b95d69cae6404d46963c015e18ebbbf9",
      "value": " 55535/55535 [31:23&lt;00:00, 29.48it/s]"
     }
    },
    "f958cec91e904d5c9caf315b42a388ed": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
