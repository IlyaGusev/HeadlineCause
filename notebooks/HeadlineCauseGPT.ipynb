{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HeadlineCauseGPT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOZ1LW6mILfDeMOaNjbt9bh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "76f7d7a71fb44f139088213616cf126e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a4d571f30d7e43d987f2e94fa5c57a8e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ca0c7dbb1e254a019d1d3e535cef709f",
              "IPY_MODEL_63907f8bc10c49d3bd888651f693b475",
              "IPY_MODEL_faba69a0fb3241ff82e451a07458b818"
            ]
          }
        },
        "a4d571f30d7e43d987f2e94fa5c57a8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ca0c7dbb1e254a019d1d3e535cef709f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8d3e420e71684a45a93ad0b40d2da04a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7d5e2650a8f245f4960e798328376ad4"
          }
        },
        "63907f8bc10c49d3bd888651f693b475": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b490c8521f774d29a400c9ee3208700e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 665,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 665,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9ac949c8cfee42ee845b033e837e407f"
          }
        },
        "faba69a0fb3241ff82e451a07458b818": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1fc617df33ef4a17ac05bdef47e295d3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 665/665 [00:00&lt;00:00, 15.2kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cda532000b0d419f811bba3d92d41d2a"
          }
        },
        "8d3e420e71684a45a93ad0b40d2da04a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7d5e2650a8f245f4960e798328376ad4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b490c8521f774d29a400c9ee3208700e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9ac949c8cfee42ee845b033e837e407f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1fc617df33ef4a17ac05bdef47e295d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cda532000b0d419f811bba3d92d41d2a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "94d2f33d27da4aeda299d73e7100ba7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1b3df53314bc4bc0bfeba2a4dda4f637",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9122302038af461b9df401e60fe7e595",
              "IPY_MODEL_887a2f8e4eb24c55b5f946372deebd35",
              "IPY_MODEL_1930fa9598914bdcbc291d602afefefd"
            ]
          }
        },
        "1b3df53314bc4bc0bfeba2a4dda4f637": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9122302038af461b9df401e60fe7e595": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8cb174c54bdb4ecc8fa9439751cf3579",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_143912695d444fd3a2c60a0cc486a43f"
          }
        },
        "887a2f8e4eb24c55b5f946372deebd35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8b93ee47af6743c1b7039fc1da19c23e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 548118077,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 548118077,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c68731e8669c4369bfdf78365c61035b"
          }
        },
        "1930fa9598914bdcbc291d602afefefd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1a8d924280664cb8905c55e414703252",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 548M/548M [00:16&lt;00:00, 31.8MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b079501eb81b41b482d10dfa05ee3788"
          }
        },
        "8cb174c54bdb4ecc8fa9439751cf3579": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "143912695d444fd3a2c60a0cc486a43f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8b93ee47af6743c1b7039fc1da19c23e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c68731e8669c4369bfdf78365c61035b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1a8d924280664cb8905c55e414703252": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b079501eb81b41b482d10dfa05ee3788": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5bb3d9da0eb94fcf98f3281f42ba87b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_eec886b2be0644278e47516c45257328",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b290c982b41144bc918e065dfa4b74da",
              "IPY_MODEL_dd5df9d50fde4e37b4565e2be125f4a4",
              "IPY_MODEL_5cecfeb672c24024badfe717f3316d50"
            ]
          }
        },
        "eec886b2be0644278e47516c45257328": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b290c982b41144bc918e065dfa4b74da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b76624f3821e4a84adc683317f0d1381",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2ec6fd20e1d742b0bdd390d5fbf85fca"
          }
        },
        "dd5df9d50fde4e37b4565e2be125f4a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e93cde7e682a4e7d98f4d8867f141663",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1042301,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1042301,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a2c7f3d8cd284badb9aaaf477e4e3a96"
          }
        },
        "5cecfeb672c24024badfe717f3316d50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9137a0b2ceed4397ac5c1016614abb8f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.04M/1.04M [00:00&lt;00:00, 3.77MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_06720bafeb444921ae35203be6ff9e0a"
          }
        },
        "b76624f3821e4a84adc683317f0d1381": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2ec6fd20e1d742b0bdd390d5fbf85fca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e93cde7e682a4e7d98f4d8867f141663": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a2c7f3d8cd284badb9aaaf477e4e3a96": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9137a0b2ceed4397ac5c1016614abb8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "06720bafeb444921ae35203be6ff9e0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "26a966db41e9484fb4175e81e0b5b26b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f283bef89ace4ea38c85bea3836a0b57",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_71fae7da88f34521bd4176b0aa3102ce",
              "IPY_MODEL_1055634803e74b1d972b4dd1ff5cbd8c",
              "IPY_MODEL_240c7d25eb534f60a6e8577888c2b2a5"
            ]
          }
        },
        "f283bef89ace4ea38c85bea3836a0b57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "71fae7da88f34521bd4176b0aa3102ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ab3796ec882148f4b75ffd8c9e7500e9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9e7a47c648e8434786f177a90f120527"
          }
        },
        "1055634803e74b1d972b4dd1ff5cbd8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3d4730faed314abca3a5877de8f0804d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 456318,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 456318,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f557ffe217b14906971bcae582b9fa0d"
          }
        },
        "240c7d25eb534f60a6e8577888c2b2a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_20f88d4ee29e4c9a8835b9885a474841",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 456k/456k [00:00&lt;00:00, 1.56MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5b5f64978a96477aa16b72380eef5b49"
          }
        },
        "ab3796ec882148f4b75ffd8c9e7500e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9e7a47c648e8434786f177a90f120527": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3d4730faed314abca3a5877de8f0804d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f557ffe217b14906971bcae582b9fa0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "20f88d4ee29e4c9a8835b9885a474841": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5b5f64978a96477aa16b72380eef5b49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "433229ad3f204b389ce7b022c381e4d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_cbc838fca002458a8ddb087719c757ba",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3b84b6a1afbd472b96a6996024718bb2",
              "IPY_MODEL_084d857ec5604664a12341601ec20e4a",
              "IPY_MODEL_a69cc1c9891942ea982072295b69f3da"
            ]
          }
        },
        "cbc838fca002458a8ddb087719c757ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3b84b6a1afbd472b96a6996024718bb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_845187f117634c6db3be12f235dbd12f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_527f18e8b24348a7b6f2ad9632276d31"
          }
        },
        "084d857ec5604664a12341601ec20e4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_674aa83a255e4c79aaaf334bbca7ba6b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1355256,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1355256,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_553fcb4091524473b6b3482c1d466498"
          }
        },
        "a69cc1c9891942ea982072295b69f3da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_47c0f99ebdf34568883885e47047e201",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 2.73MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6220871117f441908541e788aa310424"
          }
        },
        "845187f117634c6db3be12f235dbd12f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "527f18e8b24348a7b6f2ad9632276d31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "674aa83a255e4c79aaaf334bbca7ba6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "553fcb4091524473b6b3482c1d466498": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "47c0f99ebdf34568883885e47047e201": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6220871117f441908541e788aa310424": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IlyaGusev/HeadlineCause/blob/main/notebooks/HeadlineCauseGPT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrTLZUszBWZG"
      },
      "source": [
        "# Requirements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwDTpIUWBNhn",
        "outputId": "f695f004-5a31-447d-86ff-26d3bf87d990"
      },
      "source": [
        "!git clone https://github.com/IlyaGusev/HeadlineCause"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'HeadlineCause'...\n",
            "remote: Enumerating objects: 524, done.\u001b[K\n",
            "remote: Counting objects: 100% (524/524), done.\u001b[K\n",
            "remote: Compressing objects: 100% (388/388), done.\u001b[K\n",
            "remote: Total 524 (delta 277), reused 313 (delta 126), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (524/524), 3.11 MiB | 16.15 MiB/s, done.\n",
            "Resolving deltas: 100% (277/277), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FOWT5Yc9BUKf",
        "outputId": "c3199535-0a5d-427a-81bb-42d38380ddb2"
      },
      "source": [
        "!pip install --upgrade -r HeadlineCause/requirements.txt"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from -r HeadlineCause/requirements.txt (line 1)) (2.6.0)\n",
            "Collecting tensorflow-text>=2.6.0\n",
            "  Downloading tensorflow_text-2.6.0-cp37-cp37m-manylinux1_x86_64.whl (4.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.4 MB 7.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from -r HeadlineCause/requirements.txt (line 3)) (1.9.0+cu102)\n",
            "Collecting transformers==4.9.2\n",
            "  Downloading transformers-4.9.2-py3-none-any.whl (2.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.6 MB 37.4 MB/s \n",
            "\u001b[?25hCollecting spacy==3.1.2\n",
            "  Downloading spacy-3.1.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 33.3 MB/s \n",
            "\u001b[?25hCollecting checklist==0.0.11\n",
            "  Downloading checklist-0.0.11.tar.gz (12.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.1 MB 39.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: networkx>=2.6.2 in /usr/local/lib/python3.7/dist-packages (from -r HeadlineCause/requirements.txt (line 8)) (2.6.2)\n",
            "Collecting hnswlib==0.5.2\n",
            "  Downloading hnswlib-0.5.2.tar.gz (29 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting catboost==0.26.1\n",
            "  Downloading catboost-0.26.1-cp37-none-manylinux1_x86_64.whl (67.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 67.4 MB 53 kB/s \n",
            "\u001b[?25hCollecting toloka-kit==0.1.10\n",
            "  Downloading toloka_kit-0.1.10-py3-none-any.whl (241 kB)\n",
            "\u001b[K     |████████████████████████████████| 241 kB 43.7 MB/s \n",
            "\u001b[?25hCollecting crowd-kit==0.0.5\n",
            "  Downloading crowd_kit-0.0.5-py3-none-any.whl (48 kB)\n",
            "\u001b[K     |████████████████████████████████| 48 kB 4.5 MB/s \n",
            "\u001b[?25hCollecting nltk==3.6.2\n",
            "  Downloading nltk-3.6.2-py3-none-any.whl (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 47.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.9.2->-r HeadlineCause/requirements.txt (line 4)) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.9.2->-r HeadlineCause/requirements.txt (line 4)) (21.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.9.2->-r HeadlineCause/requirements.txt (line 4)) (2019.12.20)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.9.2->-r HeadlineCause/requirements.txt (line 4)) (1.19.5)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 36.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.9.2->-r HeadlineCause/requirements.txt (line 4)) (4.6.4)\n",
            "Collecting huggingface-hub==0.0.12\n",
            "  Downloading huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 44.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.9.2->-r HeadlineCause/requirements.txt (line 4)) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.9.2->-r HeadlineCause/requirements.txt (line 4)) (4.62.0)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 30.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy==3.1.2->-r HeadlineCause/requirements.txt (line 5)) (57.4.0)\n",
            "Collecting catalogue<2.1.0,>=2.0.4\n",
            "  Downloading catalogue-2.0.6-py3-none-any.whl (17 kB)\n",
            "Collecting srsly<3.0.0,>=2.4.1\n",
            "  Downloading srsly-2.4.1-cp37-cp37m-manylinux2014_x86_64.whl (456 kB)\n",
            "\u001b[K     |████████████████████████████████| 456 kB 52.2 MB/s \n",
            "\u001b[?25hCollecting spacy-legacy<3.1.0,>=3.0.7\n",
            "  Downloading spacy_legacy-3.0.8-py2.py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy==3.1.2->-r HeadlineCause/requirements.txt (line 5)) (3.7.4.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy==3.1.2->-r HeadlineCause/requirements.txt (line 5)) (2.11.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy==3.1.2->-r HeadlineCause/requirements.txt (line 5)) (0.8.2)\n",
            "Collecting thinc<8.1.0,>=8.0.8\n",
            "  Downloading thinc-8.0.8-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (621 kB)\n",
            "\u001b[K     |████████████████████████████████| 621 kB 50.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==3.1.2->-r HeadlineCause/requirements.txt (line 5)) (2.0.5)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.1.2->-r HeadlineCause/requirements.txt (line 5)) (0.4.1)\n",
            "Collecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\n",
            "  Downloading pydantic-1.8.2-cp37-cp37m-manylinux2014_x86_64.whl (10.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1 MB 52.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.1.2->-r HeadlineCause/requirements.txt (line 5)) (1.0.5)\n",
            "Collecting pathy>=0.3.5\n",
            "  Downloading pathy-0.6.0-py3-none-any.whl (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 1.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==3.1.2->-r HeadlineCause/requirements.txt (line 5)) (3.0.5)\n",
            "Collecting typer<0.4.0,>=0.3.0\n",
            "  Downloading typer-0.3.2-py3-none-any.whl (21 kB)\n",
            "Collecting munch>=2.5\n",
            "  Downloading munch-2.5.0-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: dill>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from checklist==0.0.11->-r HeadlineCause/requirements.txt (line 6)) (0.3.4)\n",
            "Requirement already satisfied: jupyter>=1.0 in /usr/local/lib/python3.7/dist-packages (from checklist==0.0.11->-r HeadlineCause/requirements.txt (line 6)) (1.0.0)\n",
            "Requirement already satisfied: ipywidgets>=7.5 in /usr/local/lib/python3.7/dist-packages (from checklist==0.0.11->-r HeadlineCause/requirements.txt (line 6)) (7.6.3)\n",
            "Collecting patternfork-nosql\n",
            "  Downloading patternfork_nosql-3.6.tar.gz (22.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 22.3 MB 59.8 MB/s \n",
            "\u001b[?25hCollecting iso-639\n",
            "  Downloading iso-639-0.4.5.tar.gz (167 kB)\n",
            "\u001b[K     |████████████████████████████████| 167 kB 46.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from catboost==0.26.1->-r HeadlineCause/requirements.txt (line 10)) (1.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost==0.26.1->-r HeadlineCause/requirements.txt (line 10)) (1.15.0)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from catboost==0.26.1->-r HeadlineCause/requirements.txt (line 10)) (1.1.5)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost==0.26.1->-r HeadlineCause/requirements.txt (line 10)) (4.4.1)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from catboost==0.26.1->-r HeadlineCause/requirements.txt (line 10)) (0.10.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from catboost==0.26.1->-r HeadlineCause/requirements.txt (line 10)) (3.2.2)\n",
            "Requirement already satisfied: attrs>=21.2.0 in /usr/local/lib/python3.7/dist-packages (from toloka-kit==0.1.10->-r HeadlineCause/requirements.txt (line 12)) (21.2.0)\n",
            "Collecting simplejson\n",
            "  Downloading simplejson-3.17.5-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (129 kB)\n",
            "\u001b[K     |████████████████████████████████| 129 kB 51.5 MB/s \n",
            "\u001b[?25hCollecting cattrs>=1.1.1\n",
            "  Downloading cattrs-1.8.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from toloka-kit==0.1.10->-r HeadlineCause/requirements.txt (line 12)) (1.24.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from crowd-kit==0.0.5->-r HeadlineCause/requirements.txt (line 13)) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk==3.6.2->-r HeadlineCause/requirements.txt (line 14)) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk==3.6.2->-r HeadlineCause/requirements.txt (line 14)) (7.1.2)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.6.0->-r HeadlineCause/requirements.txt (line 1)) (1.12.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.37.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.6.0->-r HeadlineCause/requirements.txt (line 1)) (1.39.0)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.6.0->-r HeadlineCause/requirements.txt (line 1)) (3.1.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.6.0->-r HeadlineCause/requirements.txt (line 1)) (3.3.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.6.0->-r HeadlineCause/requirements.txt (line 1)) (3.17.3)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.6.0->-r HeadlineCause/requirements.txt (line 1)) (1.1.0)\n",
            "Requirement already satisfied: keras~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.6.0->-r HeadlineCause/requirements.txt (line 1)) (2.6.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.6.0->-r HeadlineCause/requirements.txt (line 1)) (1.12)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.6.0->-r HeadlineCause/requirements.txt (line 1)) (0.4.0)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.6.0->-r HeadlineCause/requirements.txt (line 1)) (2.6.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.6.0->-r HeadlineCause/requirements.txt (line 1)) (0.12.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.6.0->-r HeadlineCause/requirements.txt (line 1)) (1.1.2)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.6.0->-r HeadlineCause/requirements.txt (line 1)) (0.37.0)\n",
            "Requirement already satisfied: tensorflow-estimator~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.6.0->-r HeadlineCause/requirements.txt (line 1)) (2.6.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.6.0->-r HeadlineCause/requirements.txt (line 1)) (0.2.0)\n",
            "Requirement already satisfied: clang~=5.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.6.0->-r HeadlineCause/requirements.txt (line 1)) (5.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.6.0->-r HeadlineCause/requirements.txt (line 1)) (1.6.3)\n",
            "Requirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-text>=2.6.0->-r HeadlineCause/requirements.txt (line 2)) (0.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.4->spacy==3.1.2->-r HeadlineCause/requirements.txt (line 5)) (3.5.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow>=2.6.0->-r HeadlineCause/requirements.txt (line 1)) (1.5.2)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.5->checklist==0.0.11->-r HeadlineCause/requirements.txt (line 6)) (5.5.0)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.5->checklist==0.0.11->-r HeadlineCause/requirements.txt (line 6)) (4.10.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.5->checklist==0.0.11->-r HeadlineCause/requirements.txt (line 6)) (3.5.1)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.5->checklist==0.0.11->-r HeadlineCause/requirements.txt (line 6)) (5.0.5)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.5->checklist==0.0.11->-r HeadlineCause/requirements.txt (line 6)) (5.1.3)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.5->checklist==0.0.11->-r HeadlineCause/requirements.txt (line 6)) (1.0.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.5->checklist==0.0.11->-r HeadlineCause/requirements.txt (line 6)) (5.3.5)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.5->checklist==0.0.11->-r HeadlineCause/requirements.txt (line 6)) (5.1.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5->checklist==0.0.11->-r HeadlineCause/requirements.txt (line 6)) (0.7.5)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5->checklist==0.0.11->-r HeadlineCause/requirements.txt (line 6)) (2.6.1)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5->checklist==0.0.11->-r HeadlineCause/requirements.txt (line 6)) (0.8.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5->checklist==0.0.11->-r HeadlineCause/requirements.txt (line 6)) (4.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5->checklist==0.0.11->-r HeadlineCause/requirements.txt (line 6)) (4.4.2)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5->checklist==0.0.11->-r HeadlineCause/requirements.txt (line 6)) (1.0.18)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from jupyter>=1.0->checklist==0.0.11->-r HeadlineCause/requirements.txt (line 6)) (5.6.1)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.7/dist-packages (from jupyter>=1.0->checklist==0.0.11->-r HeadlineCause/requirements.txt (line 6)) (5.3.1)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.7/dist-packages (from jupyter>=1.0->checklist==0.0.11->-r HeadlineCause/requirements.txt (line 6)) (5.2.0)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.7/dist-packages (from jupyter>=1.0->checklist==0.0.11->-r HeadlineCause/requirements.txt (line 6)) (5.1.1)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets>=7.5->checklist==0.0.11->-r HeadlineCause/requirements.txt (line 6)) (4.7.1)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets>=7.5->checklist==0.0.11->-r HeadlineCause/requirements.txt (line 6)) (2.6.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets>=7.5->checklist==0.0.11->-r HeadlineCause/requirements.txt (line 6)) (0.2.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.9.2->-r HeadlineCause/requirements.txt (line 4)) (2.4.7)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost==0.26.1->-r HeadlineCause/requirements.txt (line 10)) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost==0.26.1->-r HeadlineCause/requirements.txt (line 10)) (2.8.2)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy==3.1.2->-r HeadlineCause/requirements.txt (line 5)) (5.1.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipywidgets>=7.5->checklist==0.0.11->-r HeadlineCause/requirements.txt (line 6)) (0.2.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.9.2->-r HeadlineCause/requirements.txt (line 4)) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.9.2->-r HeadlineCause/requirements.txt (line 4)) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.9.2->-r HeadlineCause/requirements.txt (line 4)) (2.10)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.6.0->-r HeadlineCause/requirements.txt (line 1)) (3.3.4)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.6.0->-r HeadlineCause/requirements.txt (line 1)) (0.4.5)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.6.0->-r HeadlineCause/requirements.txt (line 1)) (1.8.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.6.0->-r HeadlineCause/requirements.txt (line 1)) (1.34.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.6.0->-r HeadlineCause/requirements.txt (line 1)) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.6.0->-r HeadlineCause/requirements.txt (line 1)) (1.0.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow>=2.6.0->-r HeadlineCause/requirements.txt (line 1)) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow>=2.6.0->-r HeadlineCause/requirements.txt (line 1)) (4.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow>=2.6.0->-r HeadlineCause/requirements.txt (line 1)) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.6.0->-r HeadlineCause/requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow>=2.6.0->-r HeadlineCause/requirements.txt (line 1)) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.6.0->-r HeadlineCause/requirements.txt (line 1)) (3.1.1)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter>=1.0->checklist==0.0.11->-r HeadlineCause/requirements.txt (line 6)) (0.11.0)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter>=1.0->checklist==0.0.11->-r HeadlineCause/requirements.txt (line 6)) (1.8.0)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets>=7.5->checklist==0.0.11->-r HeadlineCause/requirements.txt (line 6)) (22.2.1)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook->jupyter>=1.0->checklist==0.0.11->-r HeadlineCause/requirements.txt (line 6)) (0.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy==3.1.2->-r HeadlineCause/requirements.txt (line 5)) (2.0.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost==0.26.1->-r HeadlineCause/requirements.txt (line 10)) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost==0.26.1->-r HeadlineCause/requirements.txt (line 10)) (1.3.1)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter>=1.0->checklist==0.0.11->-r HeadlineCause/requirements.txt (line 6)) (0.7.1)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter>=1.0->checklist==0.0.11->-r HeadlineCause/requirements.txt (line 6)) (0.8.4)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter>=1.0->checklist==0.0.11->-r HeadlineCause/requirements.txt (line 6)) (0.5.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter>=1.0->checklist==0.0.11->-r HeadlineCause/requirements.txt (line 6)) (4.0.0)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter>=1.0->checklist==0.0.11->-r HeadlineCause/requirements.txt (line 6)) (0.3)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter>=1.0->checklist==0.0.11->-r HeadlineCause/requirements.txt (line 6)) (1.4.3)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter>=1.0->checklist==0.0.11->-r HeadlineCause/requirements.txt (line 6)) (0.5.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from patternfork-nosql->checklist==0.0.11->-r HeadlineCause/requirements.txt (line 6)) (0.16.0)\n",
            "Collecting backports.csv\n",
            "  Downloading backports.csv-1.0.7-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from patternfork-nosql->checklist==0.0.11->-r HeadlineCause/requirements.txt (line 6)) (4.6.3)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from patternfork-nosql->checklist==0.0.11->-r HeadlineCause/requirements.txt (line 6)) (4.2.6)\n",
            "Collecting feedparser\n",
            "  Downloading feedparser-6.0.8-py3-none-any.whl (81 kB)\n",
            "\u001b[K     |████████████████████████████████| 81 kB 9.0 MB/s \n",
            "\u001b[?25hCollecting pdfminer.six\n",
            "  Downloading pdfminer.six-20201018-py3-none-any.whl (5.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 42.1 MB/s \n",
            "\u001b[?25hCollecting python-docx\n",
            "  Downloading python-docx-0.8.11.tar.gz (5.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 37.8 MB/s \n",
            "\u001b[?25hCollecting cherrypy\n",
            "  Downloading CherryPy-18.6.1-py2.py3-none-any.whl (419 kB)\n",
            "\u001b[K     |████████████████████████████████| 419 kB 49.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: more-itertools in /usr/local/lib/python3.7/dist-packages (from cherrypy->patternfork-nosql->checklist==0.0.11->-r HeadlineCause/requirements.txt (line 6)) (8.8.0)\n",
            "Collecting cheroot>=8.2.1\n",
            "  Downloading cheroot-8.5.2-py2.py3-none-any.whl (97 kB)\n",
            "\u001b[K     |████████████████████████████████| 97 kB 6.1 MB/s \n",
            "\u001b[?25hCollecting portend>=2.1.1\n",
            "  Downloading portend-2.7.1-py3-none-any.whl (5.3 kB)\n",
            "Collecting jaraco.collections\n",
            "  Downloading jaraco.collections-3.4.0-py3-none-any.whl (10 kB)\n",
            "Collecting zc.lockfile\n",
            "  Downloading zc.lockfile-2.0-py2.py3-none-any.whl (9.7 kB)\n",
            "Collecting jaraco.functools\n",
            "  Downloading jaraco.functools-3.3.0-py3-none-any.whl (6.8 kB)\n",
            "Collecting tempora>=1.8\n",
            "  Downloading tempora-4.1.1-py3-none-any.whl (15 kB)\n",
            "Collecting sgmllib3k\n",
            "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
            "Collecting jaraco.text\n",
            "  Downloading jaraco.text-3.5.1-py3-none-any.whl (8.1 kB)\n",
            "Collecting jaraco.classes\n",
            "  Downloading jaraco.classes-3.2.1-py3-none-any.whl (5.6 kB)\n",
            "Collecting cryptography\n",
            "  Downloading cryptography-3.4.8-cp36-abi3-manylinux_2_24_x86_64.whl (3.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0 MB 35.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: sortedcontainers in /usr/local/lib/python3.7/dist-packages (from pdfminer.six->patternfork-nosql->checklist==0.0.11->-r HeadlineCause/requirements.txt (line 6)) (2.4.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography->pdfminer.six->patternfork-nosql->checklist==0.0.11->-r HeadlineCause/requirements.txt (line 6)) (1.14.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography->pdfminer.six->patternfork-nosql->checklist==0.0.11->-r HeadlineCause/requirements.txt (line 6)) (2.20)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost==0.26.1->-r HeadlineCause/requirements.txt (line 10)) (1.3.3)\n",
            "Requirement already satisfied: qtpy in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter>=1.0->checklist==0.0.11->-r HeadlineCause/requirements.txt (line 6)) (1.10.0)\n",
            "\u001b[33mWARNING: The candidate selected for download or install is a yanked version: 'toloka-kit' candidate (version 0.1.10 at https://files.pythonhosted.org/packages/e2/70/4cef6a7890ede0c42f2a8a4f74f086c496217435daa7ef98a3c3861ad802/toloka_kit-0.1.10-py3-none-any.whl#sha256=9191c62a6cda10be2b3b086f2cd367e728a21d4de95441bc3095367c41907df1 (from https://pypi.org/simple/toloka-kit/) (requires-python:>=3.6.0))\n",
            "Reason for being yanked: Missing attributes in template builder View classes\u001b[0m\n",
            "Building wheels for collected packages: checklist, hnswlib, iso-639, patternfork-nosql, python-docx, sgmllib3k\n",
            "  Building wheel for checklist (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for checklist: filename=checklist-0.0.11-py3-none-any.whl size=12165633 sha256=7e738cada1cd67df2e00ee6e59e3d51b2e94ef5baf3a2ec61f6bd3cc07557d42\n",
            "  Stored in directory: /root/.cache/pip/wheels/6a/8a/07/6446879be434879c27671c83443727d74cecf6b630c8a24d03\n",
            "  Building wheel for hnswlib (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hnswlib: filename=hnswlib-0.5.2-cp37-cp37m-linux_x86_64.whl size=1298765 sha256=79dd35ed17192ff81f412390ae7c3e3227da33cd37e1d13204356e192256803d\n",
            "  Stored in directory: /root/.cache/pip/wheels/b4/11/b3/337c4a361b31217d62c3b420ad66fe20d381f1ebb29b046095\n",
            "  Building wheel for iso-639 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for iso-639: filename=iso_639-0.4.5-py3-none-any.whl size=169061 sha256=9df8122968a5b6e3d26820a349cacd3e3614af36a21936a167402b8ee349c6c8\n",
            "  Stored in directory: /root/.cache/pip/wheels/47/60/19/6d020fc92138ed1b113a18271e83ea4b5525fe770cb45b9a2e\n",
            "  Building wheel for patternfork-nosql (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for patternfork-nosql: filename=patternfork_nosql-3.6-py3-none-any.whl size=22332806 sha256=7c6e5c36a812999887f7c0741e5dbf577b682d91d7510f8125266257fe3d0a27\n",
            "  Stored in directory: /root/.cache/pip/wheels/97/72/8f/5305fe28168f93b658da9ed433b9a1d3ec90594faa0c9aaf4b\n",
            "  Building wheel for python-docx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-docx: filename=python_docx-0.8.11-py3-none-any.whl size=184508 sha256=88b245d9e06a9455dd9c0ef6471c4f7c5a5df9b71e9082358ae4877f4fd40c95\n",
            "  Stored in directory: /root/.cache/pip/wheels/f6/6f/b9/d798122a8b55b74ad30b5f52b01482169b445fbb84a11797a6\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6065 sha256=7b18347cc0dcbd418f54f62e759ee2aaea5dec1d4f18b48dc6064372a540d8de\n",
            "  Stored in directory: /root/.cache/pip/wheels/73/ad/a4/0dff4a6ef231fc0dfa12ffbac2a36cebfdddfe059f50e019aa\n",
            "Successfully built checklist hnswlib iso-639 patternfork-nosql python-docx sgmllib3k\n",
            "Installing collected packages: jaraco.functools, tempora, jaraco.text, jaraco.classes, catalogue, zc.lockfile, typer, srsly, sgmllib3k, pydantic, portend, jaraco.collections, cryptography, cheroot, tokenizers, thinc, spacy-legacy, sacremoses, pyyaml, python-docx, pdfminer.six, pathy, nltk, huggingface-hub, feedparser, cherrypy, backports.csv, transformers, spacy, simplejson, patternfork-nosql, munch, iso-639, cattrs, toloka-kit, tensorflow-text, hnswlib, crowd-kit, checklist, catboost\n",
            "  Attempting uninstall: catalogue\n",
            "    Found existing installation: catalogue 1.0.0\n",
            "    Uninstalling catalogue-1.0.0:\n",
            "      Successfully uninstalled catalogue-1.0.0\n",
            "  Attempting uninstall: srsly\n",
            "    Found existing installation: srsly 1.0.5\n",
            "    Uninstalling srsly-1.0.5:\n",
            "      Successfully uninstalled srsly-1.0.5\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 7.4.0\n",
            "    Uninstalling thinc-7.4.0:\n",
            "      Successfully uninstalled thinc-7.4.0\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 2.2.4\n",
            "    Uninstalling spacy-2.2.4:\n",
            "      Successfully uninstalled spacy-2.2.4\n",
            "Successfully installed backports.csv-1.0.7 catalogue-2.0.6 catboost-0.26.1 cattrs-1.8.0 checklist-0.0.11 cheroot-8.5.2 cherrypy-18.6.1 crowd-kit-0.0.5 cryptography-3.4.8 feedparser-6.0.8 hnswlib-0.5.2 huggingface-hub-0.0.12 iso-639-0.4.5 jaraco.classes-3.2.1 jaraco.collections-3.4.0 jaraco.functools-3.3.0 jaraco.text-3.5.1 munch-2.5.0 nltk-3.6.2 pathy-0.6.0 patternfork-nosql-3.6 pdfminer.six-20201018 portend-2.7.1 pydantic-1.8.2 python-docx-0.8.11 pyyaml-5.4.1 sacremoses-0.0.45 sgmllib3k-1.0.0 simplejson-3.17.5 spacy-3.1.2 spacy-legacy-3.0.8 srsly-2.4.1 tempora-4.1.1 tensorflow-text-2.6.0 thinc-8.0.8 tokenizers-0.10.3 toloka-kit-0.1.10 transformers-4.9.2 typer-0.3.2 zc.lockfile-2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HhRiRR0BeqD"
      },
      "source": [
        "# Data loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBcwS0QSBiX7",
        "outputId": "c56daa10-07cc-4cde-f3a8-4dfae3a7f20b"
      },
      "source": [
        "!wget https://github.com/IlyaGusev/HeadlineCause/releases/download/v0/headline_cause_v0.tar.gz\n",
        "!tar -xzvf headline_cause_v0.tar.gz"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-08-27 12:29:23--  https://github.com/IlyaGusev/HeadlineCause/releases/download/v0/headline_cause_v0.tar.gz\n",
            "Resolving github.com (github.com)... 192.30.255.113\n",
            "Connecting to github.com (github.com)|192.30.255.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-releases.githubusercontent.com/389190471/6b62c015-f209-4acb-92ca-e88d05df68a2?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210827%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210827T122923Z&X-Amz-Expires=300&X-Amz-Signature=e55dac05e1b273c0deb6144bd2699c70bf6a19f0641981784d50fc79dc93761a&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=389190471&response-content-disposition=attachment%3B%20filename%3Dheadline_cause_v0.tar.gz&response-content-type=application%2Foctet-stream [following]\n",
            "--2021-08-27 12:29:23--  https://github-releases.githubusercontent.com/389190471/6b62c015-f209-4acb-92ca-e88d05df68a2?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210827%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210827T122923Z&X-Amz-Expires=300&X-Amz-Signature=e55dac05e1b273c0deb6144bd2699c70bf6a19f0641981784d50fc79dc93761a&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=389190471&response-content-disposition=attachment%3B%20filename%3Dheadline_cause_v0.tar.gz&response-content-type=application%2Foctet-stream\n",
            "Resolving github-releases.githubusercontent.com (github-releases.githubusercontent.com)... 185.199.108.154, 185.199.109.154, 185.199.110.154, ...\n",
            "Connecting to github-releases.githubusercontent.com (github-releases.githubusercontent.com)|185.199.108.154|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 101375394 (97M) [application/octet-stream]\n",
            "Saving to: ‘headline_cause_v0.tar.gz’\n",
            "\n",
            "headline_cause_v0.t 100%[===================>]  96.68M  90.5MB/s    in 1.1s    \n",
            "\n",
            "2021-08-27 12:29:24 (90.5 MB/s) - ‘headline_cause_v0.tar.gz’ saved [101375394/101375394]\n",
            "\n",
            "headline_cause_ru.jsonl\n",
            "headline_cause_en.jsonl\n",
            "simple_en_test.jsonl\n",
            "simple_en_train.jsonl\n",
            "simple_en_val.jsonl\n",
            "simple_ru_test.jsonl\n",
            "simple_ru_train.jsonl\n",
            "simple_ru_val.jsonl\n",
            "full_en_test.jsonl\n",
            "full_en_train.jsonl\n",
            "full_en_val.jsonl\n",
            "full_ru_test.jsonl\n",
            "full_ru_train.jsonl\n",
            "full_ru_val.jsonl\n",
            "LICENSE.html\n",
            "META.html\n",
            "ru_docs.jsonl\n",
            "en_docs.jsonl\n",
            "ru_raw.jsonl\n",
            "en_raw.jsonl\n",
            "en_agg.jsonl\n",
            "ru_agg.jsonl\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFOQHIWDB-s4"
      },
      "source": [
        "import json\n",
        "\n",
        "def read_jsonl(file_name):\n",
        "    records = []\n",
        "    with open(file_name, \"r\") as r:\n",
        "        for line in r:\n",
        "            record = json.loads(line)\n",
        "            records.append(record)\n",
        "    return records\n",
        "\n",
        "def fix_records(records):\n",
        "    fixed_records = []\n",
        "    for r in records:\n",
        "        result = r[\"simple_result\"]\n",
        "        if not result.startswith(\"right\") and not result.startswith(\"left\"):\n",
        "            continue\n",
        "        if result.startswith(\"right\"):\n",
        "            r[\"left_title\"], r[\"right_title\"] = r[\"right_title\"], r[\"left_title\"]\n",
        "        fixed_records.append(r)\n",
        "    return fixed_records\n",
        "\n",
        "ru_train_records = fix_records(read_jsonl(\"simple_ru_train.jsonl\"))\n",
        "ru_val_records = fix_records(read_jsonl(\"simple_ru_val.jsonl\"))\n",
        "ru_test_records = fix_records(read_jsonl(\"simple_ru_test.jsonl\"))\n",
        "en_train_records = fix_records(read_jsonl(\"simple_en_train.jsonl\"))\n",
        "en_val_records = fix_records(read_jsonl(\"simple_en_val.jsonl\"))\n",
        "en_test_records = fix_records(read_jsonl(\"simple_en_test.jsonl\"))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6-MGFFtB6gE"
      },
      "source": [
        "import random\n",
        "import torch\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def set_random_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:2\"\n",
        "    os.environ[\"PL_GLOBAL_SEED\"] = str(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "set_random_seed(1337)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iu3ytDuCOY0"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class LineByLineTextDataset(Dataset):\n",
        "    def __init__(self, records, max_tokens, tokenizer):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_tokens = max_tokens\n",
        "        self.records = records\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.records)\n",
        "\n",
        "    def embed_record(self, record):\n",
        "        inputs = self.tokenizer(\n",
        "            text=record[\"left_title\"] +'. '+record[\"right_title\"]+'. <|endoftext|>',\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_tokens,\n",
        "            truncation=\"longest_first\",\n",
        "            padding=\"max_length\",\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        for key, value in inputs.items():\n",
        "            value.squeeze_(0)\n",
        "        return inputs\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        record = self.records[index]\n",
        "        output = self.embed_record(record)\n",
        "        return output"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWrD9WQ8B5Mb"
      },
      "source": [
        "# Russian"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FTzk-1Z0BVDp",
        "outputId": "0c966cb9-3e8a-4593-badf-abaf7eba98b2"
      },
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "model_name = \"sberbank-ai/rugpt3small_based_on_gpt2\"\n",
        "ru_model = AutoModelForCausalLM.from_pretrained(model_name).to(\"cuda\")\n",
        "ru_tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "ru_tokenizer.add_special_tokens({\n",
        "  \"eos_token\": \"<|endoftext|>\",\n",
        "  \"bos_token\": \"<|beginoftext|>\",\n",
        "  \"unk_token\": \"<|unk|>\",\n",
        "  'pad_token':'<|pad|>',\n",
        "  'sep_token':'<|sep|>'\n",
        "})"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V60_iFtGCT7f"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler\n",
        "\n",
        "MAX_TOKENS = 120\n",
        "\n",
        "ru_train_data = LineByLineTextDataset(ru_train_records, MAX_TOKENS, ru_tokenizer)\n",
        "ru_val_data = LineByLineTextDataset(ru_val_records, MAX_TOKENS, ru_tokenizer)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3khIJmHVCaye",
        "outputId": "ba08e34a-e302-4375-a8c4-cd733aa24452"
      },
      "source": [
        "from transformers import Trainer, TrainingArguments, DataCollatorForLanguageModeling \n",
        "\n",
        "EPOCHS = 6\n",
        "EVAL_STEPS = 8\n",
        "WARMUP_STEPS = 8\n",
        "LR = 6e-05\n",
        "BATCH_SIZE = 32\n",
        "GRAD_ACCUM_STEPS = 4\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./gpt2-gen1\",\n",
        "    overwrite_output_dir=True,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    save_strategy=\"steps\",\n",
        "    per_device_train_batch_size=BATCH_SIZE,\n",
        "    per_device_eval_batch_size=BATCH_SIZE,\n",
        "    logging_steps=EVAL_STEPS,\n",
        "    save_steps=EVAL_STEPS,\n",
        "    warmup_steps=WARMUP_STEPS,\n",
        "    learning_rate=LR,\n",
        "    num_train_epochs=EPOCHS,\n",
        "    gradient_accumulation_steps=GRAD_ACCUM_STEPS,\n",
        "    report_to=\"none\",\n",
        "    prediction_loss_only=True,\n",
        "    load_best_model_at_end=True,\n",
        "    save_total_limit=1\n",
        ")\n",
        "\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=ru_tokenizer, mlm=False,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=ru_model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,    \n",
        "    train_dataset=ru_train_data,\n",
        "    eval_dataset=ru_val_data\n",
        ")\n",
        "\n",
        "!rm -rf gpt2-gen1\n",
        "trainer.train()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 2045\n",
            "  Num Epochs = 6\n",
            "  Instantaneous batch size per device = 32\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
            "  Gradient Accumulation steps = 4\n",
            "  Total optimization steps = 96\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='96' max='96' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [96/96 07:36, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>5.617500</td>\n",
              "      <td>4.823387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>4.787100</td>\n",
              "      <td>4.115697</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>3.944600</td>\n",
              "      <td>3.437441</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>3.368400</td>\n",
              "      <td>3.035980</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>2.845400</td>\n",
              "      <td>2.829731</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>2.682100</td>\n",
              "      <td>2.736065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56</td>\n",
              "      <td>2.440100</td>\n",
              "      <td>2.699602</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>64</td>\n",
              "      <td>2.392000</td>\n",
              "      <td>2.683484</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>72</td>\n",
              "      <td>2.286500</td>\n",
              "      <td>2.671989</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>2.199300</td>\n",
              "      <td>2.673416</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>88</td>\n",
              "      <td>2.152300</td>\n",
              "      <td>2.674164</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>96</td>\n",
              "      <td>2.152100</td>\n",
              "      <td>2.673656</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 177\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to ./gpt2-gen1/checkpoint-8\n",
            "Configuration saved in ./gpt2-gen1/checkpoint-8/config.json\n",
            "Model weights saved in ./gpt2-gen1/checkpoint-8/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 177\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to ./gpt2-gen1/checkpoint-16\n",
            "Configuration saved in ./gpt2-gen1/checkpoint-16/config.json\n",
            "Model weights saved in ./gpt2-gen1/checkpoint-16/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 177\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to ./gpt2-gen1/checkpoint-24\n",
            "Configuration saved in ./gpt2-gen1/checkpoint-24/config.json\n",
            "Model weights saved in ./gpt2-gen1/checkpoint-24/pytorch_model.bin\n",
            "Deleting older checkpoint [gpt2-gen1/checkpoint-8] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 177\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to ./gpt2-gen1/checkpoint-32\n",
            "Configuration saved in ./gpt2-gen1/checkpoint-32/config.json\n",
            "Model weights saved in ./gpt2-gen1/checkpoint-32/pytorch_model.bin\n",
            "Deleting older checkpoint [gpt2-gen1/checkpoint-16] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 177\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to ./gpt2-gen1/checkpoint-40\n",
            "Configuration saved in ./gpt2-gen1/checkpoint-40/config.json\n",
            "Model weights saved in ./gpt2-gen1/checkpoint-40/pytorch_model.bin\n",
            "Deleting older checkpoint [gpt2-gen1/checkpoint-24] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 177\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to ./gpt2-gen1/checkpoint-48\n",
            "Configuration saved in ./gpt2-gen1/checkpoint-48/config.json\n",
            "Model weights saved in ./gpt2-gen1/checkpoint-48/pytorch_model.bin\n",
            "Deleting older checkpoint [gpt2-gen1/checkpoint-32] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 177\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to ./gpt2-gen1/checkpoint-56\n",
            "Configuration saved in ./gpt2-gen1/checkpoint-56/config.json\n",
            "Model weights saved in ./gpt2-gen1/checkpoint-56/pytorch_model.bin\n",
            "Deleting older checkpoint [gpt2-gen1/checkpoint-40] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 177\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to ./gpt2-gen1/checkpoint-64\n",
            "Configuration saved in ./gpt2-gen1/checkpoint-64/config.json\n",
            "Model weights saved in ./gpt2-gen1/checkpoint-64/pytorch_model.bin\n",
            "Deleting older checkpoint [gpt2-gen1/checkpoint-48] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 177\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to ./gpt2-gen1/checkpoint-72\n",
            "Configuration saved in ./gpt2-gen1/checkpoint-72/config.json\n",
            "Model weights saved in ./gpt2-gen1/checkpoint-72/pytorch_model.bin\n",
            "Deleting older checkpoint [gpt2-gen1/checkpoint-56] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 177\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to ./gpt2-gen1/checkpoint-80\n",
            "Configuration saved in ./gpt2-gen1/checkpoint-80/config.json\n",
            "Model weights saved in ./gpt2-gen1/checkpoint-80/pytorch_model.bin\n",
            "Deleting older checkpoint [gpt2-gen1/checkpoint-64] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 177\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to ./gpt2-gen1/checkpoint-88\n",
            "Configuration saved in ./gpt2-gen1/checkpoint-88/config.json\n",
            "Model weights saved in ./gpt2-gen1/checkpoint-88/pytorch_model.bin\n",
            "Deleting older checkpoint [gpt2-gen1/checkpoint-80] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 177\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to ./gpt2-gen1/checkpoint-96\n",
            "Configuration saved in ./gpt2-gen1/checkpoint-96/config.json\n",
            "Model weights saved in ./gpt2-gen1/checkpoint-96/pytorch_model.bin\n",
            "Deleting older checkpoint [gpt2-gen1/checkpoint-88] due to args.save_total_limit\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from ./gpt2-gen1/checkpoint-72 (score: 2.6719894409179688).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=96, training_loss=3.072284996509552, metrics={'train_runtime': 460.0882, 'train_samples_per_second': 26.669, 'train_steps_per_second': 0.209, 'total_flos': 751418726400000.0, 'train_loss': 3.072284996509552, 'epoch': 6.0})"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "cwUvaWd8FMOH",
        "outputId": "10b689b4-96b9-4767-fbdf-38b11c87e5d2"
      },
      "source": [
        "import transformers\n",
        "transformers.logging.set_verbosity_error()\n",
        "\n",
        "bad_word_ids = [\n",
        "    [203], # \\n\n",
        "    [225], # weird space 1\n",
        "    [28664], # weird space 2\n",
        "    [13298], # weird space 3\n",
        "    [206], # \\r\n",
        "    [49120], # html\n",
        "    [25872], # http\n",
        "    [3886], # amp\n",
        "    [38512], # nbsp\n",
        "    [10], # &\n",
        "    [5436], # & (another)\n",
        "    [5861], # http\n",
        "    [372], # yet another line break\n",
        "    [421, 4395], # МСК\n",
        "    [64], # \\\n",
        "    [33077], # https\n",
        "    [1572], # ru\n",
        "    [11101], # Источник\n",
        "]\n",
        "\n",
        "def sample(model, tokenizer, prefix, n):\n",
        "    input_ids = tokenizer.encode(prefix + '<|sep|> ', add_special_tokens=False, return_tensors=\"pt\").to(\"cuda\")\n",
        "    input_size = len(input_ids)\n",
        "    preds = model.generate(\n",
        "        input_ids,\n",
        "        top_p=0.95,\n",
        "        do_sample=True,\n",
        "        min_length=input_size + 10,\n",
        "        max_length=input_size + 100,\n",
        "        num_return_sequences=n,\n",
        "        temperature=1.0,\n",
        "        bad_words_ids=bad_word_ids,\n",
        "        no_repeat_ngram_size=4\n",
        "    )\n",
        "    return [tokenizer.decode(preds[r].cpu().numpy()).strip().split(\"<|sep|> \")[1].split(\"<|sep|>\")[0] for r in range(n)]\n",
        "\n",
        "ru_model.eval()\n",
        "for item in ru_test_records[:30]:\n",
        "    for _ in range(10):\n",
        "        res = sample(ru_model, ru_tokenizer, item[\"left_title\"], 10)\n",
        "        if res:\n",
        "            print(item[\"left_title\"])\n",
        "            for r in res:\n",
        "                print(f'    => {r}')\n",
        "            print()\n",
        "            break"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Трамп заявил о создании в США сверхбыстрой «супер-пупер-ракеты»\n",
            "    =>  Пентагон ответил на сообщения о создании в США сверхбольшого (до 12) сверхзвукового пассажирского лайнера\n",
            "    =>  Пентагон отреагировал на заявление Трампа о «супер-превентивной» атаке на Россию\n",
            "    =>  Пентагон отреагировал на заявление Трампа о создании сверхбыстрой «суперов-пупер-ракети»\n",
            "    =>  Трамп заявил о создании в США супербыстрой «супер–пупер-ракеты»: американцы не заметили утечку данных\n",
            "    =>  США пообещали США повторить рекорд скорости «супер-путлеров»\n",
            "    =>  В России подтвердили создание сверхбыстрой «суперной» ракеты\n",
            "    =>  Трамп отверг новость о создании сверхбыстрой «супертрансляционной» системы разведки\n",
            "    =>  Вашингтон готов дать ответ России по «супер-путлеру»\n",
            "    =>  Пентагон рассекретил данные о создании в США сверхбольшого космического корабля\n",
            "    =>  Пентагон не захотел считаться с мнением о «супер-прессе» в США\n",
            "\n",
            "Представитель Ирана в ОПЕК впал в кому\n",
            "    =>  Иран заявил, что его представитель в ОПЕК умер, и его состояние проверят\n",
            "    =>  Иран ответил на предложение США по ликвидации своего лидера\n",
            "    =>  Иран отреагировал на сообщение о смерти посла в США\n",
            "    =>  В России подтвердили смерть от инсульта лидера Ирана\n",
            "    =>  Иран выразил соболезнования по поводу смерти иранского представителя в ОПЕК\n",
            "    =>  Иран не намерен выступать против переговоров с ним\n",
            "    =>  Иран прокомментировал симптом своего состояния\n",
            "    =>  Иран отреагировал на слова о ком-то из погибших в Катаре\n",
            "    =>  Опекун РФ по борьбе с коронавирусом извинился за слова о причастности Ирана к аварии на Амуре\n",
            "    =>  Иран пригрозил опровержением доклада о крушении МЗЧС\n",
            "\n",
            "Грузинские оппозиционеры Ираклий Окруашвили и Георгий Угулава помилованы\n",
            "    =>  Абхазские оппозиционеры Гайдук и Цахирашвили объяснили свое решение покинуть Грузию\n",
            "    =>  Саакашвили отреагировал на назначение Окруашвили на должность главы государства\n",
            "    =>  Саакашвили, Окруашвили и Угулава опровергли обвинения в адрес Грузии\n",
            "    =>  Саакашвили осудил арестакашвили\n",
            "    =>  Саакашвили опроверг помилование Саакашвили\n",
            "    =>  Грузинские оппозиционеры ИраклийОкруашвили и Георгий Угулав попали под суд за убийство экс-главы МИД Абхазии\n",
            "    =>  Саакашвили рассказал о своем аресте после ареста\n",
            "    =>  Саакашвили и Окруашвили опровергли помилованиеакашвили\n",
            "    => ¦Слухи о помиловании грузинских оппозиционеров опровергли\n",
            "    =>  Саакашвили: Грузия отказалась извиняться перед осетинскими активистами\n",
            "\n",
            "В Сирии заметили признаки скорой отставки Асада\n",
            "    =>  Вашингтон отреагировал на смерть Асада\n",
            "    =>  В России прокомментировали слова Путина об отставке Асада\n",
            "    =>  Башар Асад ответил на критику в адрес США в адрес Асада\n",
            "    =>  В Сирии подтвердили данные о скорой отставке Асада\n",
            "    =>  Сирийские военные ответили на сообщения о скорой отставке Асада\n",
            "    =>  В Сирии отказались от помощи России из-за коронавируса\n",
            "    =>  Россия объяснила отсутствие у Асада реакции на смерть Асада\n",
            "    =>  В Госдуме оценили отставку Асада, который в одиночку выиграл выборы в Сирии\n",
            "    =>  ВВС США оценили информацию о скорой отставке Асада\n",
            "    =>  Башар Асад прокомментировал отставку своего правительства\n",
            "\n",
            "Представитель Ирана в ОПЕК впал в кому после кровоизлияния в мозг\n",
            "    =>  Иран объяснил инсульт после кровоизлияния\n",
            "    =>  Иран опроверг сообщение о госпитализации с коронавирусом\n",
            "    =>  Иран объяснил кровоизлияние во время заседания комитета Сената по нефти\n",
            "    =>  Иран ответил на сообщения о смерти главы ОПЕК после кровоизлияния\n",
            "    =>  Иран объяснил свою смерть после удара об голову в результате кровоизлияния\n",
            "    =>  Иран отреагировал на ухудшение состояния своего гостя после кровоизлияния\n",
            "    =>  Иран отреагировал на инсульт бывшего посла Ирана в ОПЕК\n",
            "    =>  Иран опровергнул визит делегации в ОАЭ\n",
            "    =>  Иран отреагировал на инсульт в себе\n",
            "    =>  Иран признал наличие у него COVID-19\n",
            "\n",
            "Зеленский расширил антироссийские санкции на Эрмитаж и Московский госуниверситет\n",
            "    =>  Кремль отверг расширение санкций против Эрмитажа и Московский госуниверситете\n",
            "    =>  Кремль отреагировал на расширение санкций против Эрмитажа и Московского госуниверситета\n",
            "    =>  Кремль отреагировал на расширение санкций Украины против Эрмитажа и МГУ\n",
            "    => Зеленский подтвердил, что Зеленский расширил санкции против Эрмитажа и МГИМО\n",
            "    =>  В МИД подтвердили расширение антироссийских санкций на Эрмитаж и Московский государственный университет\n",
            "    =>  Россия одобрила расширенный санкционный список на Эрмитаж и Московский государственный университет\n",
            "    =>  Зеленский отреагировал на расширение антироссийских санкций на Эрмитаж и Московский университет\n",
            "    =>  Зеленский распорядился ввести санкции на Эрмитаж и МГУ\n",
            "    =>  Зеленский объяснил расширение антироссийских санкций на Эрмитаж и Московский государственный университет\n",
            "    =>  Кремль отреагировал на расширение санкций на Эрмитаж и Московский государственный университет\n",
            "\n",
            "Зеленский продлил запрет российских соцсетей\n",
            "    =>  Зеленский заявил о продолжении запрета соцсетей\n",
            "    =>  Запрет на онлайн-общение продлен\n",
            "    =>  Зеленский подтвердил продление запрета на соцсети\n",
            "    =>  Зеленский: «Нового закона о запрете соцсетей нет». Зеленский ответил на отказ Зеленского изменить статус канала\n",
            "    =>  Тимошенко продлила запрет соцсетям\n",
            "    =>  Зеленский отказался продлевать запрет российской соцсетью\n",
            "    =>  Зеленский предложил отменять санкции в отношении соцсетей\n",
            "    =>  Роскомнадзор отреагировал на продление запрета соцсетей\n",
            "    =>  Зеленский отреагировал на новость о продлении запрета российских соцсетей\n",
            "    =>  Зеленский назвал условие отмены запрета на «ВКонтакте»\n",
            "\n",
            "В Омске в День Победы пропал молодой мужчина\n",
            "    =>  Трое взрослых погибли при пропаже 24-летнего мужчины\n",
            "    =>  В Омском комитете по труду и соцполитике ответили на вопрос, есть ли связь между пропажей молодого человека и пропажей матери из-за пожара\n",
            "    =>  Омские полицейские задержали мужчину, пропавшего в День Победы\n",
            "    =>  СМИ сообщили, что исчезновение пропавшего в Москве мужчины помогло сохранить жизнь семье\n",
            "    =>  В Омске на улице Байкальской пропала молодая женщина\n",
            "    =>  В Омске пропал молодой человек\n",
            "    =>  На месте пропажи мужчины, который пропал в День Победы, нашли тело женщины\n",
            "    =>  В Омске мужчина пропал с 9 мая\n",
            "    =>  В Омичеве нашли тело пропавшего при пожаре в жилом доме мужчины\n",
            "    =>  пропавшего в Омске молодого человека нашли в реке\n",
            "\n",
            "Зеленский расширил антироссийские санкции на Эрмитаж и Московский госуниверситет\n",
            "    =>  Зеленский ответил на расширение антироссийских санкций на Эрмитаж\n",
            "    =>  Путин ответил на предложение Зеленского расширить антироссийские санкции на Эрмитажем и Московский госуниверситете\n",
            "    =>  Зеленский отреагировал на расширение антироссийских санкций на Эрмитаж и Московский го¬судар­ский университет\n",
            "    => ​Министерство культуры РФ опровергло расширение антироссийских санкций на Эрмитаж и Московский государственный университет\n",
            "    =>  МИД отреагировал на продление антироссийских санкций на Эрмитаж и Московский государственный университет\n",
            "    => «У Зеленского нет полномочий наказывать Кремль за антироссийские санкции»\n",
            "    =>  Зеленский опроверг расширение санкций против Эрмитажа и Московского госуниверситета\n",
            "    =>  Зеленский отказался отвечать на санкции против Эрмитажа и Московского университета\n",
            "    =>  Россия отреагировала на ограничение на посещение Эрмитажа и Московский госуниверситете\n",
            "    =>  Зеленский не захотел расширять антироссийские санкции на Эрмитаже и Московском госуниверситете\n",
            "\n",
            "В Улан-Удэ семья с двумя тяжелобольными выживает на одну пенсию\n",
            "    => Участников группы из четырех человек в Уфе убили на фоне карантина\n",
            "    =>  В Бурятии из-за коронавируса закрыли движение по улице Седова\n",
            "    =>  СМИ сообщили о росте числа тяжелых заболеваний в семье экс-главы Улан-Удэнского района\n",
            "    =>  Бурятия ответила на жалобы Бурятии и выяснила подробности гибели женщины на двух работах\n",
            "    =>  Буряты пожаловались на состояние пострадавших в Улан-Удэн переселенцев\n",
            "    =>  На Улан-Удэнском заводе уволили главбуха и бухгалтера\n",
            "    =>  В Улан-Удэн пожаловались на недееспособность и невозможность работать с детьми из-за коронавируса\n",
            "    =>  В Улан-Удэнских школах устроили карантин\n",
            "    =>  В Бурятии медики заразились коронавирусом из-за карантина\n",
            "    =>  В Улан-Удине умер глава семьи с тремя тяжелобольными\n",
            "\n",
            "Украина ввела санкции против тульского вуза\n",
            "    => рое высокопоставленных тульских чиновников подтвердило решение о санкции против вуза\n",
            "    =>  На Украине заявили о готовности применить санкции к России\n",
            "    =>  Украина ответила на санкции Польши против Тулы\n",
            "    =>  Правительство Тульской области прокомментировало введенные санкции против тульского ВУЗа\n",
            "    => ukraina заподозрила в причастности России к ограничению доступа к закупкам из-за санкций\n",
            "    =>  Тульские власти ответили на критику в адрес тульского вуза\n",
            "    =>  При попытке введения санкций против тульского вуза пострадали десятки людей\n",
            "    =>  Татьяна Васильева выразила свое мнение по введенным санкциям в Твери\n",
            "    =>  Вредительство в Тульской области усилилось после обращения Владимира Путина по поводу санкции против тульского филиала\n",
            "    => ukraine предложила ввести санкции против Тульского университета\n",
            "\n",
            "Нюта Федермессер может пойти в Госдуму от Нижегородской области. Ее кандидатура нравится администрации президента\n",
            "    =>  «Если будет желание, то пойду» Федермессер прокомментировала уход Натальи Михеевой из КПРФ\n",
            "    =>  ФЕДЕРМЕССЕР пообещала взять ответственность за принятие законопроекта об Нюрнбергском трибунале\n",
            "    =>  Геннадий Гудков прокомментировал идею Нюты Федермессер о выдвижении ее в Думу\n",
            "    =>  Юлию Федермессер отпустили после трех туров, необходимых для голосования\n",
            "    =>  Матвиенко прокомментировала решение Нюты Федермессер о поправке к закону о выборах\n",
            "    =>  СМИ рассказали о возможной преемнице Федиермессер\n",
            "    =>  Федормессер объяснила свое решение выдвинуться от Нижегородской области\n",
            "    =>  Федерация Нижнего Новгорода ответила на слова Татьяны Федермессер о ее борьбе с Навальным\n",
            "    =>  «Единая Россия» назвала предложение Федермессер отказаться от депутатской мантии\n",
            "    =>  Матвиенко: «Яблоко поддержало идею Нюты»\n",
            "\n",
            "РПЦ выступила против мозаики со Сталиным в храме Минобороны\n",
            "    =>  РПЦ объяснила поступок мозаики с Путиным во время церемонии закрытия патриаршего дома\n",
            "    =>  Храм в Москве отказался освящать картину из мозаики со Сталиным    Раскрыты подробности отказа РПЦ от мозаики со Сталиным\n",
            "    =>  РПЦ отреагировала на установку мозаики с бывшим президентом СССР    В РПЦ объяснили установку мозаики с бывшим советским главой\n",
            "    =>  Поклонники советской мозаики в храме в Подольске объяснили свою позицию\n",
            "    =>  РПЦ опровергла выступление против мозаики со Сталининым\n",
            "    =>  Патриарх Кирилл прокомментировал мозаику со Сталиным в храме РПЦ\n",
            "    =>  РПЦ ответила на обвинения в адрес мозаики Сталина в Храме Минобороны\n",
            "    =>  Патриарх Кирилл ответил на слова о мозаике со Сталиным в храме РПЦ\n",
            "    =>  РПЦ в ответ на слова о мозаике в храме Минобороны с Путиным повела себя резко и назвала его «победителем в войне с коммунизмом»\n",
            "    =>  Патриарх Кирилл ответил на слова о мозаике со Сталиным в храме РПЦ\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-2ea21f643146>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mru_test_records\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mru_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mru_tokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"left_title\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"left_title\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-2ea21f643146>\u001b[0m in \u001b[0;36msample\u001b[0;34m(model, tokenizer, prefix, n)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mbad_words_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbad_word_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mno_repeat_ngram_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     )\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"<|sep|> \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"<|sep|>\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, input_ids, max_length, min_length, do_sample, early_stopping, num_beams, temperature, top_k, top_p, repetition_penalty, bad_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, max_new_tokens, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   1024\u001b[0m                 \u001b[0mreturn_dict_in_generate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict_in_generate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m                 \u001b[0msynced_gpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynced_gpus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m                 \u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m             )\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, logits_warper, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   1533\u001b[0m                 \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m                 \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1535\u001b[0;31m                 \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1536\u001b[0m             )\n\u001b[1;32m   1537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    954\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 956\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    957\u001b[0m         )\n\u001b[1;32m    958\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    797\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m                     \u001b[0muse_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 799\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    800\u001b[0m                 )\n\u001b[1;32m    801\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0muse_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m         )\n\u001b[1;32m    325\u001b[0m         \u001b[0mattn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattn_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# output_attn: a, present, (attentions)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    256\u001b[0m             \u001b[0mpresent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m         \u001b[0mattn_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0mattn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_merge_heads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36m_attn\u001b[0;34m(self, query, key, value, attention_mask, head_mask)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_attn_weights\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m             \u001b[0mattn_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattn_weights\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_cross_attention\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0kCAapAObRmt"
      },
      "source": [
        "# English"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177,
          "referenced_widgets": [
            "76f7d7a71fb44f139088213616cf126e",
            "a4d571f30d7e43d987f2e94fa5c57a8e",
            "ca0c7dbb1e254a019d1d3e535cef709f",
            "63907f8bc10c49d3bd888651f693b475",
            "faba69a0fb3241ff82e451a07458b818",
            "8d3e420e71684a45a93ad0b40d2da04a",
            "7d5e2650a8f245f4960e798328376ad4",
            "b490c8521f774d29a400c9ee3208700e",
            "9ac949c8cfee42ee845b033e837e407f",
            "1fc617df33ef4a17ac05bdef47e295d3",
            "cda532000b0d419f811bba3d92d41d2a",
            "94d2f33d27da4aeda299d73e7100ba7a",
            "1b3df53314bc4bc0bfeba2a4dda4f637",
            "9122302038af461b9df401e60fe7e595",
            "887a2f8e4eb24c55b5f946372deebd35",
            "1930fa9598914bdcbc291d602afefefd",
            "8cb174c54bdb4ecc8fa9439751cf3579",
            "143912695d444fd3a2c60a0cc486a43f",
            "8b93ee47af6743c1b7039fc1da19c23e",
            "c68731e8669c4369bfdf78365c61035b",
            "1a8d924280664cb8905c55e414703252",
            "b079501eb81b41b482d10dfa05ee3788",
            "5bb3d9da0eb94fcf98f3281f42ba87b4",
            "eec886b2be0644278e47516c45257328",
            "b290c982b41144bc918e065dfa4b74da",
            "dd5df9d50fde4e37b4565e2be125f4a4",
            "5cecfeb672c24024badfe717f3316d50",
            "b76624f3821e4a84adc683317f0d1381",
            "2ec6fd20e1d742b0bdd390d5fbf85fca",
            "e93cde7e682a4e7d98f4d8867f141663",
            "a2c7f3d8cd284badb9aaaf477e4e3a96",
            "9137a0b2ceed4397ac5c1016614abb8f",
            "06720bafeb444921ae35203be6ff9e0a",
            "26a966db41e9484fb4175e81e0b5b26b",
            "f283bef89ace4ea38c85bea3836a0b57",
            "71fae7da88f34521bd4176b0aa3102ce",
            "1055634803e74b1d972b4dd1ff5cbd8c",
            "240c7d25eb534f60a6e8577888c2b2a5",
            "ab3796ec882148f4b75ffd8c9e7500e9",
            "9e7a47c648e8434786f177a90f120527",
            "3d4730faed314abca3a5877de8f0804d",
            "f557ffe217b14906971bcae582b9fa0d",
            "20f88d4ee29e4c9a8835b9885a474841",
            "5b5f64978a96477aa16b72380eef5b49",
            "433229ad3f204b389ce7b022c381e4d1",
            "cbc838fca002458a8ddb087719c757ba",
            "3b84b6a1afbd472b96a6996024718bb2",
            "084d857ec5604664a12341601ec20e4a",
            "a69cc1c9891942ea982072295b69f3da",
            "845187f117634c6db3be12f235dbd12f",
            "527f18e8b24348a7b6f2ad9632276d31",
            "674aa83a255e4c79aaaf334bbca7ba6b",
            "553fcb4091524473b6b3482c1d466498",
            "47c0f99ebdf34568883885e47047e201",
            "6220871117f441908541e788aa310424"
          ]
        },
        "id": "YuyX7HrMGq8F",
        "outputId": "ed9ccac2-91a3-4a77-c9a3-42de323fed10"
      },
      "source": [
        "from transformers import GPT2LMHeadModel, AutoTokenizer\n",
        "\n",
        "model_name = \"gpt2\"\n",
        "en_model = GPT2LMHeadModel.from_pretrained(model_name).to(\"cuda\")\n",
        "en_tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "en_tokenizer.pad_token = en_tokenizer.eos_token"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "76f7d7a71fb44f139088213616cf126e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "94d2f33d27da4aeda299d73e7100ba7a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5bb3d9da0eb94fcf98f3281f42ba87b4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "26a966db41e9484fb4175e81e0b5b26b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "433229ad3f204b389ce7b022c381e4d1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yF59jeRE9pL"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler\n",
        "\n",
        "MAX_TOKENS = 100\n",
        "\n",
        "en_train_data = LineByLineTextDataset(en_train_records, MAX_TOKENS, en_tokenizer)\n",
        "en_val_data = LineByLineTextDataset(en_val_records, MAX_TOKENS, en_tokenizer)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-PFTixydbgn1",
        "outputId": "c3041e48-98f4-4d6d-a83f-bc8806448783"
      },
      "source": [
        "from transformers import Trainer, TrainingArguments, DataCollatorForLanguageModeling \n",
        "\n",
        "EPOCHS = 10\n",
        "EVAL_STEPS = 8\n",
        "WARMUP_STEPS = 8\n",
        "LR = 5e-05\n",
        "BATCH_SIZE = 16\n",
        "GRAD_ACCUM_STEPS = 8\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./en-gpt2-gen1\",\n",
        "    overwrite_output_dir=True,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    save_strategy=\"steps\",\n",
        "    per_device_train_batch_size=BATCH_SIZE,\n",
        "    per_device_eval_batch_size=BATCH_SIZE,\n",
        "    logging_steps=EVAL_STEPS,\n",
        "    save_steps=EVAL_STEPS,\n",
        "    warmup_steps=WARMUP_STEPS,\n",
        "    learning_rate=LR,\n",
        "    num_train_epochs=EPOCHS,\n",
        "    gradient_accumulation_steps=GRAD_ACCUM_STEPS,\n",
        "    report_to=\"none\",\n",
        "    prediction_loss_only=True,\n",
        "    load_best_model_at_end=True,\n",
        "    save_total_limit=1\n",
        ")\n",
        "\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=en_tokenizer, mlm=False,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=en_model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,    \n",
        "    train_dataset=en_train_data,\n",
        "    eval_dataset=en_val_data\n",
        ")\n",
        "\n",
        "!rm -rf en-gpt2-gen1\n",
        "trainer.train()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 1111\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
            "  Gradient Accumulation steps = 8\n",
            "  Total optimization steps = 80\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='80' max='80' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [80/80 03:37, Epoch 9/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>4.972300</td>\n",
              "      <td>4.325442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>4.704200</td>\n",
              "      <td>3.990811</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>4.266700</td>\n",
              "      <td>3.853289</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>3.998500</td>\n",
              "      <td>3.783504</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>3.811600</td>\n",
              "      <td>3.753164</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>3.669800</td>\n",
              "      <td>3.738491</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56</td>\n",
              "      <td>3.563700</td>\n",
              "      <td>3.733073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>64</td>\n",
              "      <td>3.471500</td>\n",
              "      <td>3.732033</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>72</td>\n",
              "      <td>3.454300</td>\n",
              "      <td>3.731657</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>3.427100</td>\n",
              "      <td>3.731004</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 98\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to ./en-gpt2-gen1/checkpoint-8\n",
            "Configuration saved in ./en-gpt2-gen1/checkpoint-8/config.json\n",
            "Model weights saved in ./en-gpt2-gen1/checkpoint-8/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 98\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to ./en-gpt2-gen1/checkpoint-16\n",
            "Configuration saved in ./en-gpt2-gen1/checkpoint-16/config.json\n",
            "Model weights saved in ./en-gpt2-gen1/checkpoint-16/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 98\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to ./en-gpt2-gen1/checkpoint-24\n",
            "Configuration saved in ./en-gpt2-gen1/checkpoint-24/config.json\n",
            "Model weights saved in ./en-gpt2-gen1/checkpoint-24/pytorch_model.bin\n",
            "Deleting older checkpoint [en-gpt2-gen1/checkpoint-8] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 98\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to ./en-gpt2-gen1/checkpoint-32\n",
            "Configuration saved in ./en-gpt2-gen1/checkpoint-32/config.json\n",
            "Model weights saved in ./en-gpt2-gen1/checkpoint-32/pytorch_model.bin\n",
            "Deleting older checkpoint [en-gpt2-gen1/checkpoint-16] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 98\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to ./en-gpt2-gen1/checkpoint-40\n",
            "Configuration saved in ./en-gpt2-gen1/checkpoint-40/config.json\n",
            "Model weights saved in ./en-gpt2-gen1/checkpoint-40/pytorch_model.bin\n",
            "Deleting older checkpoint [en-gpt2-gen1/checkpoint-24] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 98\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to ./en-gpt2-gen1/checkpoint-48\n",
            "Configuration saved in ./en-gpt2-gen1/checkpoint-48/config.json\n",
            "Model weights saved in ./en-gpt2-gen1/checkpoint-48/pytorch_model.bin\n",
            "Deleting older checkpoint [en-gpt2-gen1/checkpoint-32] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 98\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to ./en-gpt2-gen1/checkpoint-56\n",
            "Configuration saved in ./en-gpt2-gen1/checkpoint-56/config.json\n",
            "Model weights saved in ./en-gpt2-gen1/checkpoint-56/pytorch_model.bin\n",
            "Deleting older checkpoint [en-gpt2-gen1/checkpoint-40] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 98\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to ./en-gpt2-gen1/checkpoint-64\n",
            "Configuration saved in ./en-gpt2-gen1/checkpoint-64/config.json\n",
            "Model weights saved in ./en-gpt2-gen1/checkpoint-64/pytorch_model.bin\n",
            "Deleting older checkpoint [en-gpt2-gen1/checkpoint-48] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 98\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to ./en-gpt2-gen1/checkpoint-72\n",
            "Configuration saved in ./en-gpt2-gen1/checkpoint-72/config.json\n",
            "Model weights saved in ./en-gpt2-gen1/checkpoint-72/pytorch_model.bin\n",
            "Deleting older checkpoint [en-gpt2-gen1/checkpoint-56] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 98\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to ./en-gpt2-gen1/checkpoint-80\n",
            "Configuration saved in ./en-gpt2-gen1/checkpoint-80/config.json\n",
            "Model weights saved in ./en-gpt2-gen1/checkpoint-80/pytorch_model.bin\n",
            "Deleting older checkpoint [en-gpt2-gen1/checkpoint-64] due to args.save_total_limit\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from ./en-gpt2-gen1/checkpoint-80 (score: 3.731003761291504).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=80, training_loss=3.933984327316284, metrics={'train_runtime': 219.7809, 'train_samples_per_second': 50.55, 'train_steps_per_second': 0.364, 'total_flos': 562543372800000.0, 'train_loss': 3.933984327316284, 'epoch': 9.91})"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NK2NdYqnbuRg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cca9c08d-5afe-46e7-bdd5-75d4809daf56"
      },
      "source": [
        "import transformers\n",
        "transformers.logging.set_verbosity_error()\n",
        "\n",
        "\n",
        "def sample(model, tokenizer, prefix, n):\n",
        "    input_ids = tokenizer.encode(prefix + '. ', add_special_tokens=False, return_tensors=\"pt\").to(\"cuda\")\n",
        "    input_size = len(input_ids)\n",
        "    preds = model.generate(\n",
        "        input_ids,\n",
        "        num_return_sequences=n, \n",
        "        do_sample=True, \n",
        "        top_k=0,\n",
        "        temperature=0.7,\n",
        "        top_p=0.92,\n",
        "        min_length=input_size + 10,\n",
        "        max_length=input_size + 100,\n",
        "    )\n",
        "    samples = [tokenizer.decode(preds[r].cpu().numpy()).strip() for r in range(n)]\n",
        "    return samples\n",
        "\n",
        "def simple_filter(items):\n",
        "    res = []\n",
        "    for item in list(set([item.split('.')[1]+'.' for item in items if item.count('.')>1 and item.split('.')[1].count(' ')>4])):\n",
        "      if 'ㅋ' in item: continue\n",
        "      if 'ㅜ' in item: continue\n",
        "      if '' in item: continue\n",
        "      if 'ㅠ' in item: continue\n",
        "      if 'Â' in item: continue\n",
        "      if 'ㅆ' in item: continue\n",
        "      if item.strip()[0] not in 'ABCDEFGHIJKLMNOPQRSTUVWXYZ': continue\n",
        "      \n",
        "      res.append(item.strip())\n",
        "    return res\n",
        "\n",
        "en_model.eval()\n",
        "for item in en_test_records[:30]:\n",
        "    if '.' in item: continue  \n",
        "    for _ in range(10):\n",
        "        res = sample(en_model, en_tokenizer, item[\"left_title\"], 10)\n",
        "        res = simple_filter(res)\n",
        "        if res and res != item:\n",
        "            print(item[\"left_title\"])\n",
        "            for r in res:\n",
        "                print(f'    => {r}')\n",
        "            print()\n",
        "            break"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "She-Ra creator Noelle Stevenson on what’s at stake in the final season\n",
            "    => Noelle Stevenson shares her thoughts on Noelle Stevenson’s demise.\n",
            "    => Noelle Stevenson ‘not afraid’ to make a statement, says she’s ‘trying to make a difference’ in the future of Noelle Stevenson's life.\n",
            "    => Noelle Stevenson’s final season on Twitter.\n",
            "    => Fellow Noelle Stevenson fans react to Noelle Stevenson’s farewell to 'The People's Show'.\n",
            "    => Noelle Stevenson ‘the’n’st person who makes sure all fans feel like they have a say on the final season of Noelle Stevenson’s series.\n",
            "\n",
            "Mary-Kate Olsen And Her Much Older Husband Olivier Sarkozy Divorce After 5 Years\n",
            "    => Shay Naikwe’s Wife Tributes After Karen Olsen Divorce:  Vive La France’s Greatest Moments From the 2010 Couple.\n",
            "    => Olivier Sarkozy: I Have Told Him My Story  But I Didn't Know How Much I Had to Pay for Him to Stop Divorce.\n",
            "    => HBO’s Melissa McCarthy Mourns Carrie Coronavirus’s ‘Truly Motherly’ Coronavirus Victim, Reacts To Her Husband's Divorce.\n",
            "    => Grieving Couple Remains Missing For 5 Years.\n",
            "    => What Happened To Their Baby?  Vivek Ahuja’s Wife,  Tilda Swinton, Exposed In Her Husband's Womb of a Life.\n",
            "    => Gibraltar Is Now Being Pushed Into Another Ritz-Carlton.\n",
            "\n",
            "Jerry Stiller, Legendary Comedian and ‘Seinfeld’ Co-Star, Has Died at 92\n",
            "    => He Was a Distant Star for 15 Years.\n",
            "    => Stiller's death is the latest in a string of tragic deaths of legendary New York comedy stars, including Stephen Colbert, Jerry Seinfeld, and Seth MacFarlane.\n",
            "    => He Was Dead for 23 Years, But  He Was A Funny Man.\n",
            "    => He Was’t Wounded by Toxin-19 in Death of Actor.\n",
            "    => Stiller's funeral was attended by Dr.\n",
            "    => Gloria Steinem, Kristin Chenoweth, and Seth Rogen's Most Famous Fans Are All Dead At 92.\n",
            "    => The Tonight Show Star Died in a Car Crash.\n",
            "    => Stiller, who was buried in California, has announced he is leaving the show.\n",
            "    => Stiller’s Death:  Cough Up, Shake, and Scream  He Wasn’t Leaving His Wife, 43 Years After Leaving the TV Show.\n",
            "\n",
            "Pompeo says ‘enormous evidence’ shows coronavirus began in Wuhan lab\n",
            "    => Tests: Laminated lab test results’ ‘no good’.\n",
            "    => Update: Ompeo’s office says coronavirus ‘had’n’t begun in Wuhan lab.\n",
            "    => Incredible ‘evidence’ shows coronavirus began in Wuhan lab.\n",
            "\n",
            "Two more Auckland cell towers set on fire amid 5G, COVID-19 conspiracies\n",
            "    => Pioneering 5G coverage, new updates to the trial.\n",
            "    => Cops chase down 5G conspirators after coronavirus claims.\n",
            "    => Tire Safety: New Zealand Police Explains Why The Government Is Excusing Local Police From Using 5G.\n",
            "    => Tens of thousands of homes, businesses set on fire.\n",
            "    => Nigeria's new coronavirus trial tops up to $3 million.\n",
            "    => It's no secret that Auckland cell towers are not working well, says NZT chief.\n",
            "    => The coronavirus is still on the rise, says coronavirus expert.\n",
            "    => The city's top coronavirus investigator warns New Zealanders to be vigilant.\n",
            "    => It's no secret that COVID-19 is a conspiracy theory.\n",
            "    => The Auckland cell towers have been torched after 5G conspiracies.\n",
            "\n",
            "US government moves to block Huawei's international chip supply, China could retaliate\n",
            "    => Huawei wants to block supply of US government's foreign chip supply in retaliation for Chinese government's decision to block Huawei's global chip supply.\n",
            "    => Huawei in talks with the US to block Chinese global chip supply.\n",
            "    => The Chinese government argues that Huawei's Chinese supply is not in dispute, but instead just a matter of supply chain.\n",
            "    => India slams US for blocking Huawei Global supply.\n",
            "    => India's Huawei Group ‘should ‘move to block global supply’’:  Shao Jia’s response.\n",
            "    => The US government is blocking Huawei's global supply, with US tech firms saying the government is blocking them’s own international supply.\n",
            "    => Russia moves to block Huawei supply to US.\n",
            "    => Huawei’s international chip supply agreement expires in September, Chinese state media says  in response to US decision to block Huawei's import deal.\n",
            "    => What happens to Huawei in China?  The government in Beijing’s defense of its Huawei business  should help us know what to expect next.\n",
            "    => China 'will not allow Huawei to import its own chips,' warns US government.\n",
            "\n",
            "US moves to cut Huawei off from global chip suppliers\n",
            "    => The Chinese smartphone maker, Huawei, says it will comply with US orders to 'get back on the map'.\n",
            "    => Huawei announces 'unbreakable' $99 price cut.\n",
            "    => The government of China calls Huawei off from global chip supply chain.\n",
            "    => Huawei officially announces cuts to its supply chain.\n",
            "    => Huawei announced its first official support for global chip suppliers.\n",
            "    => India wants to cut Huawei off from global chip suppliers.\n",
            "    => Huawei drops Huawei support from its official app store  in China, says it wants to'step back' from China app store.\n",
            "    => Huawei vows to stop selling its Huawei phones.\n",
            "\n",
            "Armed protesters demonstrate inside Michigan state capitol\n",
            "    => The Michigan capitol clashes with armed protesters.\n",
            "    => How Michigan capitol protesters reacted to lockdown.\n",
            "    => Govt defends lockdown in Michigan state capitol.\n",
            "    => State capitol protesters demand lockdown of state capitol, condemn lockdown.\n",
            "    => They're protesting Michigan capitol after lockdown.\n",
            "    => The Michigan capitol is already carrying armed protesters.\n",
            "    => More arrests as protesters protest state capitol.\n",
            "    => The Michigan capitol is being shut down, protesters march in defiance of state law.\n",
            "\n",
            "Ashley Benson And G-Eazy Confirmed To Be Dating Following The Actress’ Split From Cara Delevingne – They Were Caught Kissing!\n",
            "    => Benson’s Instagram Remains Of Her From The Celebrity Couple That Just Aged 41.\n",
            "    => G-Eazy Confirms Reunion With Amanda Bynes After Wishing They Had A Baby Together.\n",
            "    => G-Eazy's’s 'What Happened To Us’s 'High School' Cast Reveals.\n",
            "\n",
            "James Harrison says Steelers head coach Mike Tomlin handed him an envelope after violent hit in 2010\n",
            "    => Tomlin says Harrison dropped the envelope in a rage.\n",
            "    => That's how I feel about Tomlin after receiving the Steelers head coach's envelope.\n",
            "    => Harrison: Mike Tomlin did not hand me an envelope when he hit me in 2010.\n",
            "    => He told reporters he has no intention of returning to football.\n",
            "    => He admits he hit Harrison in the face.\n",
            "    => The Steelers head coach says he handed Harrison an envelope after violent hit in 2010.\n",
            "    => Tomlin apologises after NFL players hit Steelers head coach Mike Tomlin during the 2010 season.\n",
            "\n",
            "Tesla not allowed to reopen Fremont, California factory [Update]\n",
            "    => Tesla denies 'worrying' state panel's decision to reopen Fremont factory.\n",
            "    => Tesla 'lacks control' over Fremont factory.\n",
            "    => Tesla’s Fremont factory closed on Monday due to factory closure.\n",
            "    => Fremont opens factory on Monday.\n",
            "    => Fremont workers are still protesting:  Fremont workers ask Tesla to reopen.\n",
            "    => Fremont factory opens as California factory shuts.\n",
            "    => Tesla says Fremont will reopen after lockdown.\n",
            "    => Fremont opens new factory in California, after lockdown.\n",
            "    => California factory closed due to Tesla lockdown.\n",
            "\n",
            "Rwanda's most-wanted genocide suspect Felicien Kabuga arrested in France\n",
            "    => He's being held on $40 million bond.\n",
            "    => He's back in prison after extradition granted  for a murder-for-hire case.\n",
            "    => He's released from prison after 28 years.\n",
            "    => The Wuhan-based Wuhan-based journalist who helped Wuhan's lead prosecutor in the case is now facing extradition.\n",
            "\n",
            "UPDATE: 19 miners test positive for COVID-19 at Implats Marula mine in Limpopo\n",
            "    => Seen miners testing positive for COVID-19 at Implats Marula mine in Limpopo.\n",
            "    => Seventy miners tested positive for COVID-19 at Implats Marula mine in Limpopo.\n",
            "    => The Coronavirus Outbreak in Coronavirus Cases in Coronavirus Cases in Limpopo:  Prosecutor.\n",
            "    => COVID-19 tests positive for COVID-19 in Imphal.\n",
            "    => Netherlands' COVID-19 tests positive for COVID-19 in Implats Marula mine.\n",
            "    => Fully operational, COVID-19 is now a priority.\n",
            "    => Workers testing positive for COVID-19 at Implats Marula mine in Limpopo.\n",
            "    => FEE:  Seoul Mining says they tested positive for COVID-19 in their miners.\n",
            "\n",
            "Mary-Kate Olsen Files For Divorce From Pierre Olivier Sarkozy, Seeks Emergency Order — Report\n",
            "    => He Just Sued Over Divorce Report.\n",
            "    => They Are Leaving My Kids, A New York Times  Report  Dies Of  Nurse Who Sealed Up The  Teenage Daughter Of  Jean-Claude Ponce.\n",
            "    => What Happened To  Kate Olsen  After  She Rejected  Her Divorce Order  From Pierre-Bertrand Aristide?  How  Kate Olsen  May Be Seduced From  The  POTUS  Career.\n",
            "\n",
            "EU ministers to discuss Israeli sovereignty - Middle East\n",
            "    => Sending Netanyahu to talks over Israeli sovereignty - Middle East.\n",
            "    => Secretary-General urges Netanyahu to postpone Israeli-Arab talks until after the elections.\n",
            "    => I hope that Israel will be allowed to exercise its sovereignty over the West Bank, despite Israeli claims.\n",
            "    => Cabinet ministers discuss Israeli sovereignty.\n",
            "    => The Israeli government will not allow Netanyahu to return to power, says Netanyahu’s'resignation’.\n",
            "    => Seeking to 'concentrate' Israeli military power in Lebanon.\n",
            "    => Palestinians demand Israeli sovereignty over Israel.\n",
            "    => Cabinet’s decision on Israeli sovereignty is not clear - Middle East.\n",
            "    => Israel ‘should’not be allowed to occupy or occupy Palestinian territory’ - Middle East.\n",
            "    => Prime Minister Benjamin Netanyahu shares Netanyahu's perspective on Israeli sovereignty.\n",
            "\n",
            "House Democrats unveil $3 trillion coronavirus relief package\n",
            "    => GOP will call for $3 trillion in coronavirus relief package in Senate.\n",
            "    => No one wants to pay for that $3 trillion  contribution to the global  prevention fund.\n",
            "    => Democrats unveil $3 trillion coronavirus relief package in exchange for $3 trillion in tax relief.\n",
            "    => Trump's attacks on Democrats' coronavirus relief package are 'far from being over'.\n",
            "    => The Democrats unveil $3 trillion coronavirus relief package  for  the entire United States.\n",
            "    => Tough on drug addiction  and health, Democrats unveil $3 trillion coronavirus relief package.\n",
            "    => GOP Senate Democrats plan to unveil $3 trillion coronavirus relief package  in 2 weeks.\n",
            "    => GOP apologizes for Democrats' $3 trillion coronavirus relief package.\n",
            "    => The Democrats' $3 trillion coronavirus relief package is just a drop in the bucket.\n",
            "\n",
            "Progressive lawmakers want Pelosi to postpone vote on $3T relief package\n",
            "    => Senator Rand Paul says Pelosi should delay vote on $3T relief package.\n",
            "    => What the Democrats want Pelosi to do:  She should postpone vote.\n",
            "    => Dems worry Pelosi is delaying vote on $3T relief package.\n",
            "    => Obamacare aide defends Pelosi saying ‘it ‘is not a mandate’’.\n",
            "    => What will Pelosi say about Democrats' Senate filibusters?  In case you missed it, here's a break down.\n",
            "    => Pelosi wants Pelosi to delay vote on $3T relief package until after the Senate approves it.\n",
            "    => Republicans pushing to block Pelosi vote on $3T relief package want her to postpone vote until after the Senate approves it.\n",
            "    => It's time for Pelosi to go, says conservative lawmaker.\n",
            "    => Why Pelosi delay votes on $3T relief package?  I want Pelosi to postpone vote on $3T relief package.\n",
            "\n",
            "Giants’ DeAndre Baker, Seahawks’ Quinton Dunbar charged with armed robbery\n",
            "    => Baker’s arrest: Worry not, fans, as Giants arrest DeAndre Baker, Seahawks’’’ armed robbery suspect charged.\n",
            "\n",
            "Facebook scoops up Giphy for $400M, Instagram integration to be primary focus\n",
            "    => So much for Instagram integration.\n",
            "    => Giphy scoops up $400M in business data by 2020.\n",
            "    => Giphy: ‘No way ’’, Google is ignoring Giphy and its social network data.\n",
            "    => They're testing out Android Nougat  and Android Nougat  on Instagram.\n",
            "    => Why Snapchat is getting a boost.\n",
            "    => Giphy gets $400M from Instagram integration, Instagram pays $400M in cash.\n",
            "    => Facebook to announce new Instagram integration for $400M.\n",
            "    => It's all good news for Instagram, Instagram's  non-profit’s mission.\n",
            "\n",
            "House passes plan for proxy voting, despite GOP objections\n",
            "    => GOP to repeal Obamacare, Senate Democrats pass a resolution to allow proxies to vote.\n",
            "    => GOP backs move to use proxy vote to block President Obama's healthcare reform plan.\n",
            "    => GOP says it's done for the primary.\n",
            "    => GOP backlash: Senate passes proxy vote for presidential ballot in California.\n",
            "    => GOP insists 'no one will believe' voter fraud charges against Obama.\n",
            "    => Trump on Obama 'hiding' Obama's plan for proxy voting:  Trump’s 'disgusting' speech.\n",
            "    => GOP slams Democrats for postponing vote on COVID-19 proxy voting.\n",
            "\n",
            "24 Migrants Killed as Truck Collides With Another in UP's Auraiya, Over 30 Injured; CM Yogi Orders Probe\n",
            "    => Why India Should Close Its Roads to 5 Million Indians  ’’’s ‘No-Fly Zone’’’.\n",
            "\n",
            "Chris Gayle rips apart Ramnaresh Sarwan, calls him a ‘snake’ & worse than ‘coronavirus’\n",
            "    => Troy Williams ‘Dies at 67’ after battling cancer.\n",
            "\n",
            "Ex-Yankees World Series title-winning GM Bob Watson dead at 74\n",
            "    => Bob Watson’s death, his wife, son, brother-in-law, and some close friends are among those who mourn.\n",
            "    => The Yankees have sold their World Series title-winning GM Bob Watson to a private company.\n",
            "    => Bob Watson's death: Who is he?  No one knows, but  Bob Watson fans know.\n",
            "    => Tribute to Joe Girardi, Ray Parnell, and the rest of the GMs who helped to make the World Series.\n",
            "    => The Yankees were in a tailspin after GM Bob Watson passed away, but they took to Twitter to slam the rumors.\n",
            "    => Bob Watson, who led the Yankees to a World Series title, passed away in Texas on May 1.\n",
            "    => The Yankees won a World Series with a 'wonderful' GM.\n",
            "    => Yankees World Series MVP Bob Watson dies at 53, the last person to know.\n",
            "    => Hall of Fame GM Joe Torre dies at 82.\n",
            "    => Bob Watson,  Hernandez, and  Roy Halladay have reunited for  the first time since  their talks to leave MLB.\n",
            "\n",
            "Maha logs record 1,602 new COVID-19 cases; deaths top 1,000\n",
            "    => Tinnitus group calls for coronavirus isolation in hospitals, health authorities.\n",
            "\n",
            "Facebook Buys Animated Image Library Giphy for $400 Million\n",
            "    => Giphy Goes Public After Buying The Image Library.\n",
            "    => The First Gallery of Giphy Shows Off Its Facial Design.\n",
            "    => Google and Facebook Are Going After Epic Video Entertainment, Betrayed Their Businesses, and Will Pay $400 Million.\n",
            "    => It Launches ‘Live’ ‘On Demand’’ On July 30.\n",
            "    => It Looks Like Google Gets a Deal On $400 Million In Animated Image Library Giphy,  Tiger Business Insider  Insiders Say.\n",
            "    => Giphy Cancelled After Massive Crowd Browsing Gallery Of The Art Of Animation.\n",
            "    => It's Time for Disney to Stop Selling Its Video Games.\n",
            "    => Disney's Animated Image Library  is Now Buying  Giphy  for $400 Million.\n",
            "    => It's Time for New Media to Stop Telling Us Why  We Shouldn't Buy  Images.\n",
            "\n",
            "Gautam Buddh Nagar reports first death due to Covid-19\n",
            "    => KUALA LUMPUR:  KUALA LUMPUR:  Bengaluru CM says death toll in Covid-19 coronavirus cases 'could be as high as 80%'.\n",
            "    => Tributes pour in on Covid-19 coronavirus death toll in PM Modi’s'state of the nation' speech.\n",
            "    => The Indian health ministry says Covid-19 death toll: 32.\n",
            "    => Thames coronavirus coronavirus deaths in Madhya Pradesh spike to 67 in May.\n",
            "    => Buddhists protest against Covid-19 death tolls in Bollywood  movie.\n",
            "    => Gautam Buddh Nagar:  We are confident we have confirmed the death of ‘Gautam Buddh Nagar’.\n",
            "\n",
            "US Will Donate Ventilators To India, Stand With PM Modi: Donald Trump\n",
            "    => He Said He Will Not Be Giving Help To India, Giving In 30 Days.\n",
            "    => India Will Donate Ventilators To US, Stand With PM Modi, Say  Neutrality.\n",
            "    => India Will Donate Ventilators To PM Modi, Spread Migrant Concerns Over 'Greater Concerns' of US Giving Ventilators To India.\n",
            "    => Trump Praises India For Using Ventilators On Its Own.\n",
            "    => India Will Donate Ventilators To India, Stand With PM Modi.\n",
            "    => India Will Donate Ventilators To India, Stand With PM Modi:  Trump’s Top Advisor’s Defense.\n",
            "\n",
            "Advocates jeopardising measures to save lives after they question NCCC, says Presidency\n",
            "    => Why the NCCC should take a stand against the coronavirus ‘an ongoing issue’.\n",
            "    => Groups seek ‘restrictive’ response to Gopinath ‘invasion’ after Gopinath questions NCCC.\n",
            "    => It's time for the NCCC to re-open its doors to ensure that it stays open to all.\n",
            "    => Chief Cabinet Secretary, NCC chairmen'shocked' by ‘confirmation’ of COVID-19 ‘inclusive’ treatment.\n",
            "    => The office of the Presidency says they have no problem with the NCCC.\n",
            "    => Why  couldn't  the  NCCC  do  more to save lives?  Senator Joe Biden’s son ‘a cause célèbre’ dies at 53, as  the Senate’s  POTUS’s son’s  shaming and intimidation go unanswered.\n",
            "    => NCCC admits  the tragic death of  Steve Simeone.\n",
            "    => What are the implications for the NCCC and their members in this crucial election?  I know the NCCC are doing very well, but I don't want to see them go into hiding.\n",
            "    => Why is the NCCC 'not' backing a new policy on deadly coronavirus warnings?  U.\n",
            "\n",
            "Number of overseas Filipinos with coronavirus now at 2,331\n",
            "    => Seventy-one foreign nationals infected with coronavirus, nearly one in three.\n",
            "    => More than 200 foreign patients in hospital as coronavirus cases rise.\n",
            "    => Tens of thousands more have tested positive for coronavirus.\n",
            "    => The number of coronavirus cases among Filipinos with coronavirus in 2016 was 1,043.\n",
            "    => Virus cases now exceed 2,000.\n",
            "    => Bureau of Statistics figures on coronavirus infection in the Philippines, says 1,692 deaths.\n",
            "\n",
            "From 1000 Coronavirus Cases A Month Ago, Delhi Crosses 7000\n",
            "    => How does Delhi feel about COVID-19 cases?  India’s'very happy' coronavirus outbreak will not go unnoticed  ’.\n",
            "    => India's Coronavirus Outbreak Will Be Much More Likely After Mumbai ‘Shops’ Closed.\n",
            "    => Shaykh’s Mumbai’s Health Commissioner Says ‘It’s Time To Re-open Coronavirus Cases.\n",
            "    => India's Coronavirus Outbreak Number Fills Again.\n",
            "    => Health Officials Are Giving Out A Million Coronavirus Cases  In A Month.\n",
            "    => The Delhi High Court has reportedly cleared 3 lakh cases of coronavirus in the past two months.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXESOu-AsbcD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}